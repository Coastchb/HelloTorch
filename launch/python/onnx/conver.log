/root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:86: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert x.shape[0] == x_lengths.shape[0]
/root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:133: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert t_s == t_t, "Relative attention is only available for self-attention."
/root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  pad_length = max(length - (self.rel_attn_window_size + 1), 0)
/root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:200: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  slice_start_position = max((self.rel_attn_window_size + 1) - length, 0)
/root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:202: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if pad_length > 0:
/root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:111: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if torch.min(inputs) < left or torch.max(inputs) > right:
/root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:116: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if min_bin_width * num_bins > 1.0:
/root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:118: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if min_bin_height * num_bins > 1.0:
/root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:168: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert (discriminant >= 0).all()
/usr/local/lib64/python3.11/site-packages/torch/onnx/_internal/jit_utils.py:314: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)
  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)
/usr/local/lib64/python3.11/site-packages/torch/onnx/symbolic_opset10.py:523: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  return g.op("Constant", value_t=torch.tensor(list_or_value))
/usr/local/lib64/python3.11/site-packages/torch/onnx/utils.py:739: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)
  _C._jit_pass_onnx_graph_shape_type_inference(
/usr/local/lib64/python3.11/site-packages/torch/onnx/utils.py:1244: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at ../torch/csrc/jit/passes/onnx/constant_fold.cpp:179.)
  _C._jit_pass_onnx_graph_shape_type_inference(
Exported graph: graph(%input : Long(*, *, strides=[100, 1], requires_grad=0, device=cpu),
      %input_lengths : Long(*, strides=[1], requires_grad=0, device=cpu),
      %scales : Float(3, strides=[1], requires_grad=0, device=cpu),
      %sid : Long(1, strides=[1], requires_grad=0, device=cpu),
      %emb_g.weight : Float(1, 256, strides=[256, 1], requires_grad=1, device=cpu),
      %text_encoder.emb.weight : Float(179, 192, strides=[192, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.emb_rel_k : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.emb_rel_v : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.conv_q.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.conv_q.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.conv_k.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.conv_k.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.conv_v.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.conv_v.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.conv_o.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.0.conv_o.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.emb_rel_k : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.emb_rel_v : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.conv_q.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.conv_q.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.conv_k.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.conv_k.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.conv_v.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.conv_v.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.conv_o.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.1.conv_o.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.emb_rel_k : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.emb_rel_v : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.conv_q.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.conv_q.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.conv_k.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.conv_k.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.conv_v.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.conv_v.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.conv_o.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.2.conv_o.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.emb_rel_k : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.emb_rel_v : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.conv_q.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.conv_q.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.conv_k.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.conv_k.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.conv_v.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.conv_v.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.conv_o.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.3.conv_o.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.emb_rel_k : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.emb_rel_v : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.conv_q.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.conv_q.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.conv_k.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.conv_k.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.conv_v.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.conv_v.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.conv_o.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.4.conv_o.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.emb_rel_k : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.emb_rel_v : Float(1, 9, 96, strides=[864, 96, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.conv_q.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.conv_q.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.conv_k.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.conv_k.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.conv_v.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.conv_v.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.conv_o.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.attn_layers.5.conv_o.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.norm_layers_1.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.norm_layers_1.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.0.conv_1.weight : Float(768, 192, 3, strides=[576, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.0.conv_1.bias : Float(768, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.0.conv_2.weight : Float(192, 768, 3, strides=[2304, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.0.conv_2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.1.conv_1.weight : Float(768, 192, 3, strides=[576, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.1.conv_1.bias : Float(768, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.1.conv_2.weight : Float(192, 768, 3, strides=[2304, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.1.conv_2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.2.conv_1.weight : Float(768, 192, 3, strides=[576, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.2.conv_1.bias : Float(768, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.2.conv_2.weight : Float(192, 768, 3, strides=[2304, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.2.conv_2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.3.conv_1.weight : Float(768, 192, 3, strides=[576, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.3.conv_1.bias : Float(768, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.3.conv_2.weight : Float(192, 768, 3, strides=[2304, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.3.conv_2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.4.conv_1.weight : Float(768, 192, 3, strides=[576, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.4.conv_1.bias : Float(768, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.4.conv_2.weight : Float(192, 768, 3, strides=[2304, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.4.conv_2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.5.conv_1.weight : Float(768, 192, 3, strides=[576, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.5.conv_1.bias : Float(768, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.5.conv_2.weight : Float(192, 768, 3, strides=[2304, 3, 1], requires_grad=1, device=cpu),
      %text_encoder.encoder.ffn_layers.5.conv_2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %text_encoder.proj.weight : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %text_encoder.proj.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.pre.weight : Float(192, 96, 1, strides=[96, 1, 1], requires_grad=1, device=cpu),
      %flow.flows.0.pre.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.enc.in_layers.0.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.enc.in_layers.1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.enc.in_layers.2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.enc.in_layers.3.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.enc.res_skip_layers.0.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.enc.res_skip_layers.1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.enc.res_skip_layers.2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.enc.res_skip_layers.3.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.enc.cond_layer.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.0.post.weight : Float(96, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %flow.flows.0.post.bias : Float(96, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.pre.weight : Float(192, 96, 1, strides=[96, 1, 1], requires_grad=1, device=cpu),
      %flow.flows.1.pre.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.enc.in_layers.0.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.enc.in_layers.1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.enc.in_layers.2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.enc.in_layers.3.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.enc.res_skip_layers.0.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.enc.res_skip_layers.1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.enc.res_skip_layers.2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.enc.res_skip_layers.3.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.1.enc.cond_layer.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.pre.weight : Float(192, 96, 1, strides=[96, 1, 1], requires_grad=1, device=cpu),
      %flow.flows.2.pre.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.enc.in_layers.0.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.enc.in_layers.1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.enc.in_layers.2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.enc.in_layers.3.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.enc.res_skip_layers.0.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.enc.res_skip_layers.1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.enc.res_skip_layers.2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.enc.res_skip_layers.3.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.2.enc.cond_layer.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.pre.weight : Float(192, 96, 1, strides=[96, 1, 1], requires_grad=1, device=cpu),
      %flow.flows.3.pre.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.enc.in_layers.0.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.enc.in_layers.1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.enc.in_layers.2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.enc.in_layers.3.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.enc.res_skip_layers.0.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.enc.res_skip_layers.1.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.enc.res_skip_layers.2.bias : Float(384, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.enc.res_skip_layers.3.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %flow.flows.3.enc.cond_layer.bias : Float(1536, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.pre.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.pre.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_sep.0.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_sep.0.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_sep.1.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_sep.1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_sep.2.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_sep.2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_1x1.0.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_1x1.0.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_1x1.1.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_1x1.1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_1x1.2.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.convs.convs_1x1.2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.proj.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.proj.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.0.translation : Float(2, 1, strides=[1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.pre.weight : Float(192, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.pre.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_sep.0.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_sep.0.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_sep.1.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_sep.1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_sep.2.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_sep.2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_1x1.0.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_1x1.0.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_1x1.1.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_1x1.1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_1x1.2.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.convs.convs_1x1.2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.proj.weight : Float(29, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.2.proj.bias : Float(29, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.pre.weight : Float(192, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.pre.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_sep.0.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_sep.0.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_sep.1.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_sep.1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_sep.2.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_sep.2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_1x1.0.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_1x1.0.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_1x1.1.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_1x1.1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_1x1.2.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.3.convs.convs_1x1.2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.pre.weight : Float(192, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.pre.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_sep.0.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_sep.0.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_sep.1.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_sep.1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_sep.2.weight : Float(192, 1, 3, strides=[3, 3, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_sep.2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_1x1.0.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_1x1.0.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_1x1.1.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_1x1.1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_1x1.2.weight : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.flows.4.convs.convs_1x1.2.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %duration_predictor.cond.weight : Float(192, 256, 1, strides=[256, 1, 1], requires_grad=1, device=cpu),
      %duration_predictor.cond.bias : Float(192, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.conv_pre.bias : Float(512, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.conv_pre.weight : Float(512, 192, 7, strides=[1344, 7, 1], requires_grad=1, device=cpu),
      %waveform_decoder.ups.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.ups.1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.ups.2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.ups.3.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.0.convs1.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.0.convs1.1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.0.convs1.2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.0.convs2.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.0.convs2.1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.0.convs2.2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.1.convs1.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.1.convs1.1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.1.convs1.2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.1.convs2.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.1.convs2.1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.1.convs2.2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.2.convs1.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.2.convs1.1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.2.convs1.2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.2.convs2.0.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.2.convs2.1.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.2.convs2.2.bias : Float(256, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.3.convs1.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.3.convs1.1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.3.convs1.2.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.3.convs2.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.3.convs2.1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.3.convs2.2.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.4.convs1.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.4.convs1.1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.4.convs1.2.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.4.convs2.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.4.convs2.1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.4.convs2.2.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.5.convs1.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.5.convs1.1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.5.convs1.2.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.5.convs2.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.5.convs2.1.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.5.convs2.2.bias : Float(128, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.6.convs1.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.6.convs1.1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.6.convs1.2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.6.convs2.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.6.convs2.1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.6.convs2.2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.7.convs1.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.7.convs1.1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.7.convs1.2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.7.convs2.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.7.convs2.1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.7.convs2.2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.8.convs1.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.8.convs1.1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.8.convs1.2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.8.convs2.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.8.convs2.1.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.8.convs2.2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.9.convs1.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.9.convs1.1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.9.convs1.2.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.9.convs2.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.9.convs2.1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.9.convs2.2.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.10.convs1.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.10.convs1.1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.10.convs1.2.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.10.convs2.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.10.convs2.1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.10.convs2.2.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.11.convs1.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.11.convs1.1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.11.convs1.2.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.11.convs2.0.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.11.convs2.1.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.resblocks.11.convs2.2.bias : Float(32, strides=[1], requires_grad=1, device=cpu),
      %waveform_decoder.conv_post.weight : Float(1, 32, 7, strides=[224, 7, 1], requires_grad=1, device=cpu),
      %waveform_decoder.cond_layer.weight : Float(512, 256, 1, strides=[256, 1, 1], requires_grad=1, device=cpu),
      %waveform_decoder.cond_layer.bias : Float(512, strides=[1], requires_grad=1, device=cpu),
      %onnx::Conv_9573 : Float(1536, 256, 1, strides=[256, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9576 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9595 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9606 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9625 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9636 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9655 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9666 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9685 : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9688 : Float(1536, 256, 1, strides=[256, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9691 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9710 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9721 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9740 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9751 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9770 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9781 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9800 : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9803 : Float(1536, 256, 1, strides=[256, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9806 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9825 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9836 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9855 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9866 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9885 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9896 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9915 : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9918 : Float(1536, 256, 1, strides=[256, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9921 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9940 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9951 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9970 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_9981 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10000 : Float(384, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10011 : Float(384, 192, 5, strides=[960, 5, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10030 : Float(192, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu),
      %onnx::ConvTranspose_10033 : Float(512, 256, 16, strides=[4096, 16, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10036 : Float(256, 256, 3, strides=[768, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10039 : Float(256, 256, 3, strides=[768, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10042 : Float(256, 256, 3, strides=[768, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10045 : Float(256, 256, 3, strides=[768, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10048 : Float(256, 256, 3, strides=[768, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10051 : Float(256, 256, 3, strides=[768, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10054 : Float(256, 256, 7, strides=[1792, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10057 : Float(256, 256, 7, strides=[1792, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10060 : Float(256, 256, 7, strides=[1792, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10063 : Float(256, 256, 7, strides=[1792, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10066 : Float(256, 256, 7, strides=[1792, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10069 : Float(256, 256, 7, strides=[1792, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10072 : Float(256, 256, 11, strides=[2816, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10075 : Float(256, 256, 11, strides=[2816, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10078 : Float(256, 256, 11, strides=[2816, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10081 : Float(256, 256, 11, strides=[2816, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10084 : Float(256, 256, 11, strides=[2816, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10087 : Float(256, 256, 11, strides=[2816, 11, 1], requires_grad=0, device=cpu),
      %onnx::ConvTranspose_10090 : Float(256, 128, 16, strides=[2048, 16, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10093 : Float(128, 128, 3, strides=[384, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10096 : Float(128, 128, 3, strides=[384, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10099 : Float(128, 128, 3, strides=[384, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10102 : Float(128, 128, 3, strides=[384, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10105 : Float(128, 128, 3, strides=[384, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10108 : Float(128, 128, 3, strides=[384, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10111 : Float(128, 128, 7, strides=[896, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10114 : Float(128, 128, 7, strides=[896, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10117 : Float(128, 128, 7, strides=[896, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10120 : Float(128, 128, 7, strides=[896, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10123 : Float(128, 128, 7, strides=[896, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10126 : Float(128, 128, 7, strides=[896, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10129 : Float(128, 128, 11, strides=[1408, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10132 : Float(128, 128, 11, strides=[1408, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10135 : Float(128, 128, 11, strides=[1408, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10138 : Float(128, 128, 11, strides=[1408, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10141 : Float(128, 128, 11, strides=[1408, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10144 : Float(128, 128, 11, strides=[1408, 11, 1], requires_grad=0, device=cpu),
      %onnx::ConvTranspose_10147 : Float(128, 64, 4, strides=[256, 4, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10150 : Float(64, 64, 3, strides=[192, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10153 : Float(64, 64, 3, strides=[192, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10156 : Float(64, 64, 3, strides=[192, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10159 : Float(64, 64, 3, strides=[192, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10162 : Float(64, 64, 3, strides=[192, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10165 : Float(64, 64, 3, strides=[192, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10168 : Float(64, 64, 7, strides=[448, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10171 : Float(64, 64, 7, strides=[448, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10174 : Float(64, 64, 7, strides=[448, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10177 : Float(64, 64, 7, strides=[448, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10180 : Float(64, 64, 7, strides=[448, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10183 : Float(64, 64, 7, strides=[448, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10186 : Float(64, 64, 11, strides=[704, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10189 : Float(64, 64, 11, strides=[704, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10192 : Float(64, 64, 11, strides=[704, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10195 : Float(64, 64, 11, strides=[704, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10198 : Float(64, 64, 11, strides=[704, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10201 : Float(64, 64, 11, strides=[704, 11, 1], requires_grad=0, device=cpu),
      %onnx::ConvTranspose_10204 : Float(64, 32, 4, strides=[128, 4, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10207 : Float(32, 32, 3, strides=[96, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10210 : Float(32, 32, 3, strides=[96, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10213 : Float(32, 32, 3, strides=[96, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10216 : Float(32, 32, 3, strides=[96, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10219 : Float(32, 32, 3, strides=[96, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10222 : Float(32, 32, 3, strides=[96, 3, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10225 : Float(32, 32, 7, strides=[224, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10228 : Float(32, 32, 7, strides=[224, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10231 : Float(32, 32, 7, strides=[224, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10234 : Float(32, 32, 7, strides=[224, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10237 : Float(32, 32, 7, strides=[224, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10240 : Float(32, 32, 7, strides=[224, 7, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10243 : Float(32, 32, 11, strides=[352, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10246 : Float(32, 32, 11, strides=[352, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10249 : Float(32, 32, 11, strides=[352, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10252 : Float(32, 32, 11, strides=[352, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10255 : Float(32, 32, 11, strides=[352, 11, 1], requires_grad=0, device=cpu),
      %onnx::Conv_10258 : Float(32, 32, 11, strides=[352, 11, 1], requires_grad=0, device=cpu)):
  %onnx::Exp_9560 : Float(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Identity(%duration_predictor.flows.0.translation)
  %duration_predictor.flows.4.proj.bias : Float(29, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%duration_predictor.flows.2.proj.bias)
  %duration_predictor.flows.4.proj.weight : Float(29, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu) = onnx::Identity(%duration_predictor.flows.2.proj.weight)
  %duration_predictor.flows.4.convs.norms_2.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.4.convs.norms_2.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.4.convs.norms_2.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.4.convs.norms_2.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.4.convs.norms_2.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.4.convs.norms_2.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.4.convs.norms_1.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.4.convs.norms_1.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.4.convs.norms_1.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.4.convs.norms_1.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.4.convs.norms_1.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.4.convs.norms_1.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.3.proj.bias : Float(29, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%duration_predictor.flows.2.proj.bias)
  %duration_predictor.flows.3.proj.weight : Float(29, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu) = onnx::Identity(%duration_predictor.flows.2.proj.weight)
  %duration_predictor.flows.3.convs.norms_2.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.3.convs.norms_2.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.3.convs.norms_2.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.3.convs.norms_2.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.3.convs.norms_2.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.3.convs.norms_2.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.3.convs.norms_1.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.3.convs.norms_1.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.3.convs.norms_1.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.3.convs.norms_1.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.3.convs.norms_1.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.3.convs.norms_1.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.2.convs.norms_2.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.2.convs.norms_2.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.2.convs.norms_2.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.2.convs.norms_2.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.2.convs.norms_2.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.2.convs.norms_2.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.2.convs.norms_1.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.2.convs.norms_1.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.2.convs.norms_1.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.2.convs.norms_1.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.flows.2.convs.norms_1.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.flows.2.convs.norms_1.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.convs.norms_2.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.convs.norms_2.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.convs.norms_2.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.convs.norms_2.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.convs.norms_2.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.convs.norms_2.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.convs.norms_1.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.convs.norms_1.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.convs.norms_1.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.convs.norms_1.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %duration_predictor.convs.norms_1.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %duration_predictor.convs.norms_1.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %flow.flows.3.post.bias : Float(96, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%flow.flows.0.post.bias)
  %flow.flows.3.post.weight : Float(96, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu) = onnx::Identity(%flow.flows.0.post.weight)
  %flow.flows.2.post.bias : Float(96, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%flow.flows.0.post.bias)
  %flow.flows.2.post.weight : Float(96, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu) = onnx::Identity(%flow.flows.0.post.weight)
  %flow.flows.1.post.bias : Float(96, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%flow.flows.0.post.bias)
  %flow.flows.1.post.weight : Float(96, 192, 1, strides=[192, 1, 1], requires_grad=1, device=cpu) = onnx::Identity(%flow.flows.0.post.weight)
  %text_encoder.encoder.norm_layers_2.5.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_2.5.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_2.4.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_2.4.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_2.3.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_2.3.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_2.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_2.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_2.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_2.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_2.0.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_2.0.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_1.5.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_1.5.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_1.4.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_1.4.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_1.3.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_1.3.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_1.2.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_1.2.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %text_encoder.encoder.norm_layers_1.1.beta : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.beta)
  %text_encoder.encoder.norm_layers_1.1.gamma : Float(192, strides=[1], requires_grad=1, device=cpu) = onnx::Identity(%text_encoder.encoder.norm_layers_1.0.gamma)
  %/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant"](), scope: TTS.tts.models.vits.Vits::
  %/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_1"](), scope: TTS.tts.models.vits.Vits::
  %/Gather_output_0 : Float(requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name="/Gather"](%scales, %/Constant_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1827:0
  %/emb_g/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={-1}, onnx_name="/emb_g/Constant"](), scope: TTS.tts.models.vits.Vits::/torch.nn.modules.sparse.Embedding::emb_g
  %/emb_g/Gather_output_0 : Float(1, 256, strides=[256, 1], requires_grad=0, device=cpu) = onnx::Gather[onnx_name="/emb_g/Gather"](%emb_g.weight, %sid), scope: TTS.tts.models.vits.Vits::/torch.nn.modules.sparse.Embedding::emb_g # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2267:0
  %/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/Constant_2"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1117:0
  %/Unsqueeze_output_0 : Float(1, 256, 1, strides=[256, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze"](%/emb_g/Gather_output_0, %/Constant_2_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1117:0
  %/text_encoder/emb/Gather_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Gather[onnx_name="/text_encoder/emb/Gather"](%text_encoder.emb.weight, %input), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/torch.nn.modules.sparse.Embedding::emb # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2267:0
  %/text_encoder/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={13.8564}, onnx_name="/text_encoder/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:87:0
  %/text_encoder/Mul_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/Mul"](%/text_encoder/emb/Gather_output_0, %/text_encoder/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:87:0
  %/text_encoder/Transpose_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/Transpose"](%/text_encoder/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:93:0
  %/text_encoder/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/Shape"](%/text_encoder/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:94:0
  %/text_encoder/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:94:0
  %/text_encoder/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/Gather"](%/text_encoder/Shape_output_0, %/text_encoder/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:94:0
  %onnx::Pad_877 : NoneType = prim::Constant(), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder
  %/text_encoder/Cast_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/Cast"](%/text_encoder/Gather_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/text_encoder/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/text_encoder/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/text_encoder/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name="/text_encoder/Range"](%/text_encoder/Constant_2_output_0, %/text_encoder/Cast_output_0, %/text_encoder/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/text_encoder/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/text_encoder/Unsqueeze_output_0 : Long(1, *, strides=[100, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/Unsqueeze"](%/text_encoder/Range_output_0, %/text_encoder/Constant_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/text_encoder/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/text_encoder/Unsqueeze_1_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/Unsqueeze_1"](%input_lengths, %/text_encoder/Constant_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/text_encoder/Less_output_0 : Bool(*, *, strides=[100, 1], requires_grad=0, device=cpu) = onnx::Less[onnx_name="/text_encoder/Less"](%/text_encoder/Unsqueeze_output_0, %/text_encoder/Unsqueeze_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/text_encoder/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:94:0
  %/text_encoder/Unsqueeze_2_output_0 : Bool(*, 1, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/Unsqueeze_2"](%/text_encoder/Less_output_0, %/text_encoder/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:94:0
  %/text_encoder/Cast_1_output_0 : Float(*, 1, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name="/text_encoder/Cast_1"](%/text_encoder/Unsqueeze_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:94:0
  %/text_encoder/Mul_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/Mul_1"](%/text_encoder/Transpose_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:96:0
  %/text_encoder/encoder/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:417:0
  %/text_encoder/encoder/Unsqueeze_output_0 : Float(*, 1, 1, *, strides=[100, 100, 100, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/Unsqueeze"](%/text_encoder/Cast_1_output_0, %/text_encoder/encoder/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:417:0
  %/text_encoder/encoder/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:417:0
  %/text_encoder/encoder/Unsqueeze_1_output_0 : Float(*, 1, *, 1, strides=[100, 100, 1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/Unsqueeze_1"](%/text_encoder/Cast_1_output_0, %/text_encoder/encoder/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:417:0
  %/text_encoder/encoder/Mul_output_0 : Float(*, 1, *, *, strides=[10000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/Mul"](%/text_encoder/encoder/Unsqueeze_output_0, %/text_encoder/encoder/Unsqueeze_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:417:0
  %/text_encoder/encoder/Mul_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/Mul_1"](%/text_encoder/Mul_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:419:0
  %/text_encoder/encoder/attn_layers.0/conv_q/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.0/conv_q/Conv"](%/text_encoder/encoder/Mul_1_output_0, %text_encoder.encoder.attn_layers.0.conv_q.weight, %text_encoder.encoder.attn_layers.0.conv_q.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0/torch.nn.modules.conv.Conv1d::conv_q # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.0/conv_k/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.0/conv_k/Conv"](%/text_encoder/encoder/Mul_1_output_0, %text_encoder.encoder.attn_layers.0.conv_k.weight, %text_encoder.encoder.attn_layers.0.conv_k.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0/torch.nn.modules.conv.Conv1d::conv_k # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.0/conv_v/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.0/conv_v/Conv"](%/text_encoder/encoder/Mul_1_output_0, %text_encoder.encoder.attn_layers.0.conv_v.weight, %text_encoder.encoder.attn_layers.0.conv_v.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0/torch.nn.modules.conv.Conv1d::conv_v # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.0/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape"](%/text_encoder/encoder/attn_layers.0/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather"](%/text_encoder/encoder/attn_layers.0/Shape_output_0, %/text_encoder/encoder/attn_layers.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_1"](%/text_encoder/encoder/attn_layers.0/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_1"](%/text_encoder/encoder/attn_layers.0/Shape_1_output_0, %/text_encoder/encoder/attn_layers.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_2"](%/text_encoder/encoder/attn_layers.0/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_2"](%/text_encoder/encoder/attn_layers.0/Shape_2_output_0, %/text_encoder/encoder/attn_layers.0/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_3"](%/text_encoder/encoder/attn_layers.0/conv_q/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.0/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_3"](%/text_encoder/encoder/attn_layers.0/Shape_3_output_0, %/text_encoder/encoder/attn_layers.0/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %onnx::Unsqueeze_913 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze"](%/text_encoder/encoder/attn_layers.0/Gather_output_0, %onnx::Unsqueeze_913), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_919 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_1"](%/text_encoder/encoder/attn_layers.0/Gather_3_output_0, %onnx::Unsqueeze_919), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_output_0, %/text_encoder/encoder/attn_layers.0/Constant_4_output_0, %/text_encoder/encoder/attn_layers.0/Constant_5_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.0/Reshape_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape"](%/text_encoder/encoder/attn_layers.0/conv_q/Conv_output_0, %/text_encoder/encoder/attn_layers.0/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.0/Transpose_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose"](%/text_encoder/encoder/attn_layers.0/Reshape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %onnx::Unsqueeze_925 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_2"](%/text_encoder/encoder/attn_layers.0/Gather_output_0, %onnx::Unsqueeze_925), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_931 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_3"](%/text_encoder/encoder/attn_layers.0/Gather_2_output_0, %onnx::Unsqueeze_931), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_1"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_2_output_0, %/text_encoder/encoder/attn_layers.0/Constant_6_output_0, %/text_encoder/encoder/attn_layers.0/Constant_7_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %onnx::Unsqueeze_934 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_4"](%/text_encoder/encoder/attn_layers.0/Gather_output_0, %onnx::Unsqueeze_934), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_940 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_5"](%/text_encoder/encoder/attn_layers.0/Gather_2_output_0, %onnx::Unsqueeze_940), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_2"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_4_output_0, %/text_encoder/encoder/attn_layers.0/Constant_8_output_0, %/text_encoder/encoder/attn_layers.0/Constant_9_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.0/Reshape_1_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_1"](%/text_encoder/encoder/attn_layers.0/conv_k/Conv_output_0, %/text_encoder/encoder/attn_layers.0/Concat_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %/text_encoder/encoder/attn_layers.0/Reshape_2_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_2"](%/text_encoder/encoder/attn_layers.0/conv_v/Conv_output_0, %/text_encoder/encoder/attn_layers.0/Concat_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.0/Transpose_1_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose_1"](%/text_encoder/encoder/attn_layers.0/Reshape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.0/MatMul_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.0/MatMul"](%/text_encoder/encoder/attn_layers.0/Transpose_output_0, %/text_encoder/encoder/attn_layers.0/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.0/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.0/Div_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.0/Div"](%/text_encoder/encoder/attn_layers.0/MatMul_output_0, %/text_encoder/encoder/attn_layers.0/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.0/Constant_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.0/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub"](%/text_encoder/encoder/attn_layers.0/Gather_2_output_0, %/text_encoder/encoder/attn_layers.0/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.0/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.0/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.0/Mul"](%/text_encoder/encoder/attn_layers.0/Gather_2_output_0, %/text_encoder/encoder/attn_layers.0/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.0/Constant_13_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.0/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub_1"](%/text_encoder/encoder/attn_layers.0/Mul_output_0, %/text_encoder/encoder/attn_layers.0/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.0/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_959 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_6"](%/text_encoder/encoder/attn_layers.0/Sub_output_0, %onnx::Unsqueeze_959), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_961 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_7"](%/text_encoder/encoder/attn_layers.0/Sub_output_0, %onnx::Unsqueeze_961), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_3"](%/text_encoder/encoder/attn_layers.0/Constant_14_output_0, %/text_encoder/encoder/attn_layers.0/Constant_15_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_6_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_7_output_0, %/text_encoder/encoder/attn_layers.0/Constant_16_output_0, %/text_encoder/encoder/attn_layers.0/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_972 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_8"](%/text_encoder/encoder/attn_layers.0/Sub_output_0, %onnx::Unsqueeze_972), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_974 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_9"](%/text_encoder/encoder/attn_layers.0/Sub_output_0, %onnx::Unsqueeze_974), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_4"](%/text_encoder/encoder/attn_layers.0/Constant_18_output_0, %/text_encoder/encoder/attn_layers.0/Constant_19_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_8_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_9_output_0, %/text_encoder/encoder/attn_layers.0/Constant_20_output_0, %/text_encoder/encoder/attn_layers.0/Constant_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_985 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_10"](%/text_encoder/encoder/attn_layers.0/Sub_output_0, %onnx::Unsqueeze_985), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_987 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_11"](%/text_encoder/encoder/attn_layers.0/Sub_output_0, %onnx::Unsqueeze_987), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_5"](%/text_encoder/encoder/attn_layers.0/Constant_22_output_0, %/text_encoder/encoder/attn_layers.0/Constant_23_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_10_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_11_output_0, %/text_encoder/encoder/attn_layers.0/Constant_24_output_0, %/text_encoder/encoder/attn_layers.0/Constant_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_998 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_12"](%/text_encoder/encoder/attn_layers.0/Sub_output_0, %onnx::Unsqueeze_998), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1000 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_13"](%/text_encoder/encoder/attn_layers.0/Sub_output_0, %onnx::Unsqueeze_1000), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_6"](%/text_encoder/encoder/attn_layers.0/Constant_26_output_0, %/text_encoder/encoder/attn_layers.0/Constant_27_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_12_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_13_output_0, %/text_encoder/encoder/attn_layers.0/Constant_28_output_0, %/text_encoder/encoder/attn_layers.0/Constant_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_4"](%/text_encoder/encoder/attn_layers.0/Concat_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_4"](%/text_encoder/encoder/attn_layers.0/Shape_4_output_0, %/text_encoder/encoder/attn_layers.0/Constant_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub_2"](%/text_encoder/encoder/attn_layers.0/Constant_31_output_0, %/text_encoder/encoder/attn_layers.0/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast"](%/text_encoder/encoder/attn_layers.0/Concat_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/ConstantOfShape"](%/text_encoder/encoder/attn_layers.0/Sub_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Concat_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_7"](%/text_encoder/encoder/attn_layers.0/Cast_output_0, %/text_encoder/encoder/attn_layers.0/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_32_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.0/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_3"](%/text_encoder/encoder/attn_layers.0/Concat_7_output_0, %/text_encoder/encoder/attn_layers.0/Constant_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice"](%/text_encoder/encoder/attn_layers.0/Reshape_3_output_0, %/text_encoder/encoder/attn_layers.0/Constant_34_output_0, %/text_encoder/encoder/attn_layers.0/Constant_35_output_0, %/text_encoder/encoder/attn_layers.0/Constant_33_output_0, %/text_encoder/encoder/attn_layers.0/Constant_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Transpose_2_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose_2"](%/text_encoder/encoder/attn_layers.0/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_4"](%/text_encoder/encoder/attn_layers.0/Transpose_2_output_0, %/text_encoder/encoder/attn_layers.0/Constant_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_1"](%/text_encoder/encoder/attn_layers.0/Reshape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Pad_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.0/Pad"](%text_encoder.encoder.attn_layers.0.emb_rel_k, %/text_encoder/encoder/attn_layers.0/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_40"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_14"](%/text_encoder/encoder/attn_layers.0/Sub_1_output_0, %/text_encoder/encoder/attn_layers.0/Constant_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_41"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Slice_1_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_1"](%/text_encoder/encoder/attn_layers.0/Pad_output_0, %/text_encoder/encoder/attn_layers.0/Constant_39_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_14_output_0, %/text_encoder/encoder/attn_layers.0/Constant_38_output_0, %/text_encoder/encoder/attn_layers.0/Constant_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_42"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_15_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_15"](%/text_encoder/encoder/attn_layers.0/Slice_1_output_0, %/text_encoder/encoder/attn_layers.0/Constant_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.0/Transpose_3_output_0 : Float(1, *, *, *, strides=[19104, 19104, 1, 96], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose_3"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.0/MatMul_1_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.0/MatMul_1"](%/text_encoder/encoder/attn_layers.0/Transpose_output_0, %/text_encoder/encoder/attn_layers.0/Transpose_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.0/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_5"](%/text_encoder/encoder/attn_layers.0/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.0/Constant_43_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_43"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.0/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_5"](%/text_encoder/encoder/attn_layers.0/Shape_5_output_0, %/text_encoder/encoder/attn_layers.0/Constant_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.0/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_6"](%/text_encoder/encoder/attn_layers.0/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.0/Constant_44_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_44"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.0/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_6"](%/text_encoder/encoder/attn_layers.0/Shape_6_output_0, %/text_encoder/encoder/attn_layers.0/Constant_44_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.0/Shape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_7"](%/text_encoder/encoder/attn_layers.0/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.0/Constant_45_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_45"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.0/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_7"](%/text_encoder/encoder/attn_layers.0/Shape_7_output_0, %/text_encoder/encoder/attn_layers.0/Constant_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.0/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_46"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_47_output_0 : Long(8, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  0  0  0  0  0  0 [ CPULongType{8} ], onnx_name="/text_encoder/encoder/attn_layers.0/Constant_47"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/ConstantOfShape_1"](%/text_encoder/encoder/attn_layers.0/Constant_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Concat_8_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_8"](%/text_encoder/encoder/attn_layers.0/Constant_47_output_0, %/text_encoder/encoder/attn_layers.0/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_48_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.0/Constant_48"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_5_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_5"](%/text_encoder/encoder/attn_layers.0/Concat_8_output_0, %/text_encoder/encoder/attn_layers.0/Constant_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_49"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_50"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_51"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_52"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Slice_2_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_2"](%/text_encoder/encoder/attn_layers.0/Reshape_5_output_0, %/text_encoder/encoder/attn_layers.0/Constant_50_output_0, %/text_encoder/encoder/attn_layers.0/Constant_51_output_0, %/text_encoder/encoder/attn_layers.0/Constant_49_output_0, %/text_encoder/encoder/attn_layers.0/Constant_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Transpose_4_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose_4"](%/text_encoder/encoder/attn_layers.0/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_53"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_6"](%/text_encoder/encoder/attn_layers.0/Transpose_4_output_0, %/text_encoder/encoder/attn_layers.0/Constant_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_2"](%/text_encoder/encoder/attn_layers.0/Reshape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Pad_1_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.0/Pad_1"](%/text_encoder/encoder/attn_layers.0/MatMul_1_output_0, %/text_encoder/encoder/attn_layers.0/Cast_2_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_54_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_54"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.0/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.0/Mul_1"](%/text_encoder/encoder/attn_layers.0/Gather_7_output_0, %/text_encoder/encoder/attn_layers.0/Constant_54_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.0/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.0/Mul_2"](%/text_encoder/encoder/attn_layers.0/Mul_1_output_0, %/text_encoder/encoder/attn_layers.0/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %onnx::Unsqueeze_1078 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_16"](%/text_encoder/encoder/attn_layers.0/Gather_5_output_0, %onnx::Unsqueeze_1078), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1080 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_17"](%/text_encoder/encoder/attn_layers.0/Gather_6_output_0, %onnx::Unsqueeze_1080), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1082 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_18"](%/text_encoder/encoder/attn_layers.0/Mul_2_output_0, %onnx::Unsqueeze_1082), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_9"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_16_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_17_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.0/Reshape_7_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_7"](%/text_encoder/encoder/attn_layers.0/Pad_1_output_0, %/text_encoder/encoder/attn_layers.0/Concat_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.0/Constant_55_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_55"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.0/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub_3"](%/text_encoder/encoder/attn_layers.0/Gather_7_output_0, %/text_encoder/encoder/attn_layers.0/Constant_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.0/Constant_56_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_56"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1090 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_19"](%/text_encoder/encoder/attn_layers.0/Sub_3_output_0, %onnx::Unsqueeze_1090), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_57"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_58"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_59_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_59"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_60_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_60"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_10"](%/text_encoder/encoder/attn_layers.0/Constant_56_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_19_output_0, %/text_encoder/encoder/attn_layers.0/Constant_57_output_0, %/text_encoder/encoder/attn_layers.0/Constant_58_output_0, %/text_encoder/encoder/attn_layers.0/Constant_59_output_0, %/text_encoder/encoder/attn_layers.0/Constant_60_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_61_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_61"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1103 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_20"](%/text_encoder/encoder/attn_layers.0/Sub_3_output_0, %onnx::Unsqueeze_1103), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_62_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_62"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_63_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_63"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_64_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_64"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_65_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_65"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_11"](%/text_encoder/encoder/attn_layers.0/Constant_61_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_20_output_0, %/text_encoder/encoder/attn_layers.0/Constant_62_output_0, %/text_encoder/encoder/attn_layers.0/Constant_63_output_0, %/text_encoder/encoder/attn_layers.0/Constant_64_output_0, %/text_encoder/encoder/attn_layers.0/Constant_65_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_66_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_66"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Shape_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_8"](%/text_encoder/encoder/attn_layers.0/Concat_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Gather_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_8"](%/text_encoder/encoder/attn_layers.0/Shape_8_output_0, %/text_encoder/encoder/attn_layers.0/Constant_66_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_67_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_67"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Sub_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub_4"](%/text_encoder/encoder/attn_layers.0/Constant_67_output_0, %/text_encoder/encoder/attn_layers.0/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_3"](%/text_encoder/encoder/attn_layers.0/Concat_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/ConstantOfShape_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/ConstantOfShape_2"](%/text_encoder/encoder/attn_layers.0/Sub_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Concat_12_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_12"](%/text_encoder/encoder/attn_layers.0/Cast_3_output_0, %/text_encoder/encoder/attn_layers.0/ConstantOfShape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_68_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.0/Constant_68"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_8_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_8"](%/text_encoder/encoder/attn_layers.0/Concat_12_output_0, %/text_encoder/encoder/attn_layers.0/Constant_68_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_69_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_69"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_70"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_71_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_71"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_72"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Slice_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_3"](%/text_encoder/encoder/attn_layers.0/Reshape_8_output_0, %/text_encoder/encoder/attn_layers.0/Constant_70_output_0, %/text_encoder/encoder/attn_layers.0/Constant_71_output_0, %/text_encoder/encoder/attn_layers.0/Constant_69_output_0, %/text_encoder/encoder/attn_layers.0/Constant_72_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Transpose_5_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose_5"](%/text_encoder/encoder/attn_layers.0/Slice_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_73_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_73"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_9"](%/text_encoder/encoder/attn_layers.0/Transpose_5_output_0, %/text_encoder/encoder/attn_layers.0/Constant_73_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_4"](%/text_encoder/encoder/attn_layers.0/Reshape_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Pad_2_output_0 : Float(*, *, *, strides=[40198, 20099, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.0/Pad_2"](%/text_encoder/encoder/attn_layers.0/Reshape_7_output_0, %/text_encoder/encoder/attn_layers.0/Cast_4_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_74_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_74"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.0/Add"](%/text_encoder/encoder/attn_layers.0/Gather_7_output_0, %/text_encoder/encoder/attn_layers.0/Constant_74_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_75_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_75"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Sub_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub_5"](%/text_encoder/encoder/attn_layers.0/Mul_1_output_0, %/text_encoder/encoder/attn_layers.0/Constant_75_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %onnx::Unsqueeze_1140 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_21"](%/text_encoder/encoder/attn_layers.0/Gather_5_output_0, %onnx::Unsqueeze_1140), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1142 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_22"](%/text_encoder/encoder/attn_layers.0/Gather_6_output_0, %onnx::Unsqueeze_1142), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1144 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_23"](%/text_encoder/encoder/attn_layers.0/Add_output_0, %onnx::Unsqueeze_1144), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1146 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_24"](%/text_encoder/encoder/attn_layers.0/Sub_5_output_0, %onnx::Unsqueeze_1146), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_13"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_21_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_22_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_23_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Reshape_10_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_10"](%/text_encoder/encoder/attn_layers.0/Pad_2_output_0, %/text_encoder/encoder/attn_layers.0/Concat_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_76"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_77_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_77"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_78"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_25"](%/text_encoder/encoder/attn_layers.0/Gather_7_output_0, %/text_encoder/encoder/attn_layers.0/Constant_78_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_79_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_79"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Slice_4_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_4"](%/text_encoder/encoder/attn_layers.0/Reshape_10_output_0, %/text_encoder/encoder/attn_layers.0/Constant_77_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_25_output_0, %/text_encoder/encoder/attn_layers.0/Constant_76_output_0, %/text_encoder/encoder/attn_layers.0/Constant_79_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_80_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_80"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_81"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_26"](%/text_encoder/encoder/attn_layers.0/Sub_3_output_0, %/text_encoder/encoder/attn_layers.0/Constant_81_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_82_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_82"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_83_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_83"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Slice_5_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_5"](%/text_encoder/encoder/attn_layers.0/Slice_4_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_26_output_0, %/text_encoder/encoder/attn_layers.0/Constant_82_output_0, %/text_encoder/encoder/attn_layers.0/Constant_80_output_0, %/text_encoder/encoder/attn_layers.0/Constant_83_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.0/Constant_84_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_84"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.0/Div_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.0/Div_1"](%/text_encoder/encoder/attn_layers.0/Slice_5_output_0, %/text_encoder/encoder/attn_layers.0/Constant_84_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.0/Add_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.0/Add_1"](%/text_encoder/encoder/attn_layers.0/Div_output_0, %/text_encoder/encoder/attn_layers.0/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:139:0
  %/text_encoder/encoder/attn_layers.0/Constant_85_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_85"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.0/Equal_output_0 : Bool(*, 1, *, *, strides=[10000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Equal[onnx_name="/text_encoder/encoder/attn_layers.0/Equal"](%/text_encoder/encoder/Mul_output_0, %/text_encoder/encoder/attn_layers.0/Constant_85_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.0/Cast_5_output_0 : Bool(*, 1, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_5"](%/text_encoder/encoder/attn_layers.0/Equal_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.0/Constant_86_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_86"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.0/Where_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/text_encoder/encoder/attn_layers.0/Where"](%/text_encoder/encoder/attn_layers.0/Cast_5_output_0, %/text_encoder/encoder/attn_layers.0/Constant_86_output_0, %/text_encoder/encoder/attn_layers.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.0/Softmax_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/text_encoder/encoder/attn_layers.0/Softmax"](%/text_encoder/encoder/attn_layers.0/Where_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/text_encoder/encoder/attn_layers.0/MatMul_2_output_0 : Float(*, *, *, 96, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.0/MatMul_2"](%/text_encoder/encoder/attn_layers.0/Softmax_output_0, %/text_encoder/encoder/attn_layers.0/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:156:0
  %/text_encoder/encoder/attn_layers.0/Shape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_9"](%/text_encoder/encoder/attn_layers.0/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.0/Constant_87_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_87"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.0/Gather_9_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_9"](%/text_encoder/encoder/attn_layers.0/Shape_9_output_0, %/text_encoder/encoder/attn_layers.0/Constant_87_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.0/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_10"](%/text_encoder/encoder/attn_layers.0/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.0/Constant_88_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_88"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.0/Gather_10_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_10"](%/text_encoder/encoder/attn_layers.0/Shape_10_output_0, %/text_encoder/encoder/attn_layers.0/Constant_88_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.0/Shape_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_11"](%/text_encoder/encoder/attn_layers.0/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.0/Constant_89_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_89"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.0/Gather_11_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_11"](%/text_encoder/encoder/attn_layers.0/Shape_11_output_0, %/text_encoder/encoder/attn_layers.0/Constant_89_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.0/Constant_90_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_90"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.0/Sub_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub_6"](%/text_encoder/encoder/attn_layers.0/Gather_11_output_0, %/text_encoder/encoder/attn_layers.0/Constant_90_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.0/Constant_91_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_91"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_27"](%/text_encoder/encoder/attn_layers.0/Sub_6_output_0, %onnx::Unsqueeze_1191), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_92_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_92"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_93_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_93"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_94_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_94"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_95_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_95"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_96_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_96"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_97_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_97"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_14_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_14"](%/text_encoder/encoder/attn_layers.0/Constant_91_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_27_output_0, %/text_encoder/encoder/attn_layers.0/Constant_92_output_0, %/text_encoder/encoder/attn_layers.0/Constant_93_output_0, %/text_encoder/encoder/attn_layers.0/Constant_94_output_0, %/text_encoder/encoder/attn_layers.0/Constant_95_output_0, %/text_encoder/encoder/attn_layers.0/Constant_96_output_0, %/text_encoder/encoder/attn_layers.0/Constant_97_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_98_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_98"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1208 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_28"](%/text_encoder/encoder/attn_layers.0/Sub_6_output_0, %onnx::Unsqueeze_1208), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_99_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_99"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_100_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_100"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_101_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_101"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_102_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_102"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_103_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_103"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_104_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_104"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_15_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_15"](%/text_encoder/encoder/attn_layers.0/Constant_98_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_28_output_0, %/text_encoder/encoder/attn_layers.0/Constant_99_output_0, %/text_encoder/encoder/attn_layers.0/Constant_100_output_0, %/text_encoder/encoder/attn_layers.0/Constant_101_output_0, %/text_encoder/encoder/attn_layers.0/Constant_102_output_0, %/text_encoder/encoder/attn_layers.0/Constant_103_output_0, %/text_encoder/encoder/attn_layers.0/Constant_104_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_105_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_105"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Shape_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_12"](%/text_encoder/encoder/attn_layers.0/Concat_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Gather_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_12"](%/text_encoder/encoder/attn_layers.0/Shape_12_output_0, %/text_encoder/encoder/attn_layers.0/Constant_105_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_106_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_106"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Sub_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub_7"](%/text_encoder/encoder/attn_layers.0/Constant_106_output_0, %/text_encoder/encoder/attn_layers.0/Gather_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_6"](%/text_encoder/encoder/attn_layers.0/Concat_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/ConstantOfShape_3_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/ConstantOfShape_3"](%/text_encoder/encoder/attn_layers.0/Sub_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Concat_16_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_16"](%/text_encoder/encoder/attn_layers.0/Cast_6_output_0, %/text_encoder/encoder/attn_layers.0/ConstantOfShape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_107_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.0/Constant_107"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_11_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_11"](%/text_encoder/encoder/attn_layers.0/Concat_16_output_0, %/text_encoder/encoder/attn_layers.0/Constant_107_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_108"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_109_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_109"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_110"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_111_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_111"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Slice_6_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_6"](%/text_encoder/encoder/attn_layers.0/Reshape_11_output_0, %/text_encoder/encoder/attn_layers.0/Constant_109_output_0, %/text_encoder/encoder/attn_layers.0/Constant_110_output_0, %/text_encoder/encoder/attn_layers.0/Constant_108_output_0, %/text_encoder/encoder/attn_layers.0/Constant_111_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Transpose_6_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose_6"](%/text_encoder/encoder/attn_layers.0/Slice_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_112_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_112"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_12_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_12"](%/text_encoder/encoder/attn_layers.0/Transpose_6_output_0, %/text_encoder/encoder/attn_layers.0/Constant_112_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_7_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_7"](%/text_encoder/encoder/attn_layers.0/Reshape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Pad_3_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.0/Pad_3"](%/text_encoder/encoder/attn_layers.0/Softmax_output_0, %/text_encoder/encoder/attn_layers.0/Cast_7_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_113_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_113"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.0/Pow_output_0 : Long(requires_grad=0, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/attn_layers.0/Pow"](%/text_encoder/encoder/attn_layers.0/Gather_11_output_0, %/text_encoder/encoder/attn_layers.0/Constant_113_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.0/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.0/Mul_3"](%/text_encoder/encoder/attn_layers.0/Gather_11_output_0, %/text_encoder/encoder/attn_layers.0/Sub_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.0/Add_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.0/Add_2"](%/text_encoder/encoder/attn_layers.0/Pow_output_0, %/text_encoder/encoder/attn_layers.0/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_1249 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_29"](%/text_encoder/encoder/attn_layers.0/Gather_9_output_0, %onnx::Unsqueeze_1249), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1251 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_30"](%/text_encoder/encoder/attn_layers.0/Gather_10_output_0, %onnx::Unsqueeze_1251), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1253 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_31"](%/text_encoder/encoder/attn_layers.0/Add_2_output_0, %onnx::Unsqueeze_1253), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_17_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_17"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_29_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_30_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.0/Reshape_13_output_0 : Float(*, *, *, strides=[39800, 19900, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_13"](%/text_encoder/encoder/attn_layers.0/Pad_3_output_0, %/text_encoder/encoder/attn_layers.0/Concat_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_1257 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_32"](%/text_encoder/encoder/attn_layers.0/Gather_11_output_0, %onnx::Unsqueeze_1257), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_114_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_114"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_115_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_115"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_116_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_116"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_117_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_117"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_118_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_118"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_18"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_32_output_0, %/text_encoder/encoder/attn_layers.0/Constant_114_output_0, %/text_encoder/encoder/attn_layers.0/Constant_115_output_0, %/text_encoder/encoder/attn_layers.0/Constant_116_output_0, %/text_encoder/encoder/attn_layers.0/Constant_117_output_0, %/text_encoder/encoder/attn_layers.0/Constant_118_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %onnx::Unsqueeze_1270 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_33"](%/text_encoder/encoder/attn_layers.0/Gather_11_output_0, %onnx::Unsqueeze_1270), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_119_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_119"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_120_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_120"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_121_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_121"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_122_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_122"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Constant_123_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_123"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_19_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_19"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_33_output_0, %/text_encoder/encoder/attn_layers.0/Constant_119_output_0, %/text_encoder/encoder/attn_layers.0/Constant_120_output_0, %/text_encoder/encoder/attn_layers.0/Constant_121_output_0, %/text_encoder/encoder/attn_layers.0/Constant_122_output_0, %/text_encoder/encoder/attn_layers.0/Constant_123_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_124_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_124"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Shape_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_13"](%/text_encoder/encoder/attn_layers.0/Concat_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Gather_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_13"](%/text_encoder/encoder/attn_layers.0/Shape_13_output_0, %/text_encoder/encoder/attn_layers.0/Constant_124_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_125_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_125"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Sub_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub_8"](%/text_encoder/encoder/attn_layers.0/Constant_125_output_0, %/text_encoder/encoder/attn_layers.0/Gather_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_8"](%/text_encoder/encoder/attn_layers.0/Concat_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/ConstantOfShape_4_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/ConstantOfShape_4"](%/text_encoder/encoder/attn_layers.0/Sub_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Concat_20_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_20"](%/text_encoder/encoder/attn_layers.0/Cast_8_output_0, %/text_encoder/encoder/attn_layers.0/ConstantOfShape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_126_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.0/Constant_126"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_14_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_14"](%/text_encoder/encoder/attn_layers.0/Concat_20_output_0, %/text_encoder/encoder/attn_layers.0/Constant_126_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_127_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_127"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_128_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_128"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_129_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_129"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_130_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_130"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Slice_7_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_7"](%/text_encoder/encoder/attn_layers.0/Reshape_14_output_0, %/text_encoder/encoder/attn_layers.0/Constant_128_output_0, %/text_encoder/encoder/attn_layers.0/Constant_129_output_0, %/text_encoder/encoder/attn_layers.0/Constant_127_output_0, %/text_encoder/encoder/attn_layers.0/Constant_130_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Transpose_7_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose_7"](%/text_encoder/encoder/attn_layers.0/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_131_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_131"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_15_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_15"](%/text_encoder/encoder/attn_layers.0/Transpose_7_output_0, %/text_encoder/encoder/attn_layers.0/Constant_131_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_9"](%/text_encoder/encoder/attn_layers.0/Reshape_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Pad_4_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.0/Pad_4"](%/text_encoder/encoder/attn_layers.0/Reshape_13_output_0, %/text_encoder/encoder/attn_layers.0/Cast_9_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_132_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_132"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.0/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.0/Mul_4"](%/text_encoder/encoder/attn_layers.0/Gather_11_output_0, %/text_encoder/encoder/attn_layers.0/Constant_132_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %onnx::Unsqueeze_1307 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_34"](%/text_encoder/encoder/attn_layers.0/Gather_9_output_0, %onnx::Unsqueeze_1307), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1309 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_35"](%/text_encoder/encoder/attn_layers.0/Gather_10_output_0, %onnx::Unsqueeze_1309), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1311 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_36"](%/text_encoder/encoder/attn_layers.0/Gather_11_output_0, %onnx::Unsqueeze_1311), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1313 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_37"](%/text_encoder/encoder/attn_layers.0/Mul_4_output_0, %onnx::Unsqueeze_1313), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_21_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_21"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_34_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_35_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_36_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.0/Reshape_16_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_16"](%/text_encoder/encoder/attn_layers.0/Pad_4_output_0, %/text_encoder/encoder/attn_layers.0/Concat_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.0/Constant_133_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_133"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.0/Constant_134_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_134"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.0/Constant_135_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_135"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.0/Constant_136_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_136"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.0/Slice_8_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_8"](%/text_encoder/encoder/attn_layers.0/Reshape_16_output_0, %/text_encoder/encoder/attn_layers.0/Constant_134_output_0, %/text_encoder/encoder/attn_layers.0/Constant_135_output_0, %/text_encoder/encoder/attn_layers.0/Constant_133_output_0, %/text_encoder/encoder/attn_layers.0/Constant_136_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.0/Constant_137_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_137"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.0/Shape_14"](%/text_encoder/encoder/attn_layers.0/Concat_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Gather_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Gather_14"](%/text_encoder/encoder/attn_layers.0/Shape_14_output_0, %/text_encoder/encoder/attn_layers.0/Constant_137_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_138_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_138"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Sub_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.0/Sub_9"](%/text_encoder/encoder/attn_layers.0/Constant_138_output_0, %/text_encoder/encoder/attn_layers.0/Gather_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_10"](%/text_encoder/encoder/attn_layers.0/Concat_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/ConstantOfShape_5_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/ConstantOfShape_5"](%/text_encoder/encoder/attn_layers.0/Sub_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Concat_22_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_22"](%/text_encoder/encoder/attn_layers.0/Cast_10_output_0, %/text_encoder/encoder/attn_layers.0/ConstantOfShape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_139_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.0/Constant_139"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_17_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_17"](%/text_encoder/encoder/attn_layers.0/Concat_22_output_0, %/text_encoder/encoder/attn_layers.0/Constant_139_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_140_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_140"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_141"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_142_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_142"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_143"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Slice_9_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_9"](%/text_encoder/encoder/attn_layers.0/Reshape_17_output_0, %/text_encoder/encoder/attn_layers.0/Constant_141_output_0, %/text_encoder/encoder/attn_layers.0/Constant_142_output_0, %/text_encoder/encoder/attn_layers.0/Constant_140_output_0, %/text_encoder/encoder/attn_layers.0/Constant_143_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Transpose_8_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose_8"](%/text_encoder/encoder/attn_layers.0/Slice_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_144_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_144"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Reshape_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_18"](%/text_encoder/encoder/attn_layers.0/Transpose_8_output_0, %/text_encoder/encoder/attn_layers.0/Constant_144_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Cast_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.0/Cast_11"](%/text_encoder/encoder/attn_layers.0/Reshape_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Pad_5_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.0/Pad_5"](%text_encoder.encoder.attn_layers.0.emb_rel_v, %/text_encoder/encoder/attn_layers.0/Cast_11_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.0/Constant_145_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_145"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Constant_146_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_146"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Constant_147_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_147"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_38"](%/text_encoder/encoder/attn_layers.0/Sub_1_output_0, %/text_encoder/encoder/attn_layers.0/Constant_147_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Constant_148_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_148"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Slice_10_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.0/Slice_10"](%/text_encoder/encoder/attn_layers.0/Pad_5_output_0, %/text_encoder/encoder/attn_layers.0/Constant_146_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_38_output_0, %/text_encoder/encoder/attn_layers.0/Constant_145_output_0, %/text_encoder/encoder/attn_layers.0/Constant_148_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.0/Constant_149_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.0/Constant_149"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_39_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_39"](%/text_encoder/encoder/attn_layers.0/Slice_10_output_0, %/text_encoder/encoder/attn_layers.0/Constant_149_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.0/MatMul_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.0/MatMul_3"](%/text_encoder/encoder/attn_layers.0/Slice_8_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.0/Add_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.0/Add_3"](%/text_encoder/encoder/attn_layers.0/MatMul_2_output_0, %/text_encoder/encoder/attn_layers.0/MatMul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:161:0
  %/text_encoder/encoder/attn_layers.0/Transpose_9_output_0 : Float(*, *, *, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.0/Transpose_9"](%/text_encoder/encoder/attn_layers.0/Add_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %onnx::Unsqueeze_1362 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_40"](%/text_encoder/encoder/attn_layers.0/Gather_output_0, %onnx::Unsqueeze_1362), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1364 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_41"](%/text_encoder/encoder/attn_layers.0/Gather_1_output_0, %onnx::Unsqueeze_1364), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %onnx::Unsqueeze_1366 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.0/Unsqueeze_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.0/Unsqueeze_42"](%/text_encoder/encoder/attn_layers.0/Gather_3_output_0, %onnx::Unsqueeze_1366), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0
  %/text_encoder/encoder/attn_layers.0/Concat_23_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.0/Concat_23"](%/text_encoder/encoder/attn_layers.0/Unsqueeze_40_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_41_output_0, %/text_encoder/encoder/attn_layers.0/Unsqueeze_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.0/Reshape_19_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.0/Reshape_19"](%/text_encoder/encoder/attn_layers.0/Transpose_9_output_0, %/text_encoder/encoder/attn_layers.0/Concat_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.0/conv_o/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.0/conv_o/Conv"](%/text_encoder/encoder/attn_layers.0/Reshape_19_output_0, %text_encoder.encoder.attn_layers.0.conv_o.weight, %text_encoder.encoder.attn_layers.0.conv_o.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.0/torch.nn.modules.conv.Conv1d::conv_o # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/Add_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add"](%/text_encoder/encoder/Mul_1_output_0, %/text_encoder/encoder/attn_layers.0/conv_o/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:422:0
  %/text_encoder/encoder/norm_layers_1.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.0/Transpose"](%/text_encoder/encoder/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_1.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.0/ReduceMean"](%/text_encoder/encoder/norm_layers_1.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_1.0/Sub"](%/text_encoder/encoder/norm_layers_1.0/Transpose_output_0, %/text_encoder/encoder/norm_layers_1.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_1.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_1.0/Pow"](%/text_encoder/encoder/norm_layers_1.0/Sub_output_0, %/text_encoder/encoder/norm_layers_1.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.0/ReduceMean_1"](%/text_encoder/encoder/norm_layers_1.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_1.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.0/Add"](%/text_encoder/encoder/norm_layers_1.0/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_1.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_1.0/Sqrt"](%/text_encoder/encoder/norm_layers_1.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_1.0/Div"](%/text_encoder/encoder/norm_layers_1.0/Sub_output_0, %/text_encoder/encoder/norm_layers_1.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_1.0/Mul"](%/text_encoder/encoder/norm_layers_1.0/Div_output_0, %text_encoder.encoder.norm_layers_1.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.0/Add_1"](%/text_encoder/encoder/norm_layers_1.0/Mul_output_0, %text_encoder.encoder.norm_layers_1.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.0/Transpose_1"](%/text_encoder/encoder/norm_layers_1.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/ffn_layers.0/Mul_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.0/Mul"](%/text_encoder/encoder/norm_layers_1.0/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:291:0
  %/text_encoder/encoder/ffn_layers.0/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_1_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.0/ConstantOfShape"](%/text_encoder/encoder/ffn_layers.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.0/Concat"](%/text_encoder/encoder/ffn_layers.0/Constant_1_output_0, %/text_encoder/encoder/ffn_layers.0/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Reshape_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.0/Reshape"](%/text_encoder/encoder/ffn_layers.0/Concat_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.0/Slice"](%/text_encoder/encoder/ffn_layers.0/Reshape_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_4_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_5_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_3_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Transpose_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.0/Transpose"](%/text_encoder/encoder/ffn_layers.0/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Reshape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.0/Reshape_1"](%/text_encoder/encoder/ffn_layers.0/Transpose_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.0/Cast"](%/text_encoder/encoder/ffn_layers.0/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Pad_output_0 : Float(*, *, *, strides=[19584, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.0/Pad"](%/text_encoder/encoder/ffn_layers.0/Mul_output_0, %/text_encoder/encoder/ffn_layers.0/Cast_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/conv_1/Conv_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.0/conv_1/Conv"](%/text_encoder/encoder/ffn_layers.0/Pad_output_0, %text_encoder.encoder.ffn_layers.0.conv_1.weight, %text_encoder.encoder.ffn_layers.0.conv_1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0/torch.nn.modules.conv.Conv1d::conv_1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.0/Relu_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name="/text_encoder/encoder/ffn_layers.0/Relu"](%/text_encoder/encoder/ffn_layers.0/conv_1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:292:0
  %/text_encoder/encoder/ffn_layers.0/Mul_1_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.0/Mul_1"](%/text_encoder/encoder/ffn_layers.0/Relu_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:294:0
  %/text_encoder/encoder/ffn_layers.0/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_9_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.0/ConstantOfShape_1"](%/text_encoder/encoder/ffn_layers.0/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.0/Concat_1"](%/text_encoder/encoder/ffn_layers.0/Constant_9_output_0, %/text_encoder/encoder/ffn_layers.0/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Reshape_2_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.0/Reshape_2"](%/text_encoder/encoder/ffn_layers.0/Concat_1_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Slice_1_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.0/Slice_1"](%/text_encoder/encoder/ffn_layers.0/Reshape_2_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_12_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_13_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_11_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Transpose_1_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.0/Transpose_1"](%/text_encoder/encoder/ffn_layers.0/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.0/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Reshape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.0/Reshape_3"](%/text_encoder/encoder/ffn_layers.0/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.0/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.0/Cast_1"](%/text_encoder/encoder/ffn_layers.0/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/Pad_1_output_0 : Float(*, *, *, strides=[78336, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.0/Pad_1"](%/text_encoder/encoder/ffn_layers.0/Mul_1_output_0, %/text_encoder/encoder/ffn_layers.0/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.0/conv_2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.0/conv_2/Conv"](%/text_encoder/encoder/ffn_layers.0/Pad_1_output_0, %text_encoder.encoder.ffn_layers.0.conv_2.weight, %text_encoder.encoder.ffn_layers.0.conv_2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0/torch.nn.modules.conv.Conv1d::conv_2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.0/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.0/Mul_2"](%/text_encoder/encoder/ffn_layers.0/conv_2/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:295:0
  %/text_encoder/encoder/Add_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_1"](%/text_encoder/encoder/norm_layers_1.0/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.0/Mul_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:430:0
  %/text_encoder/encoder/norm_layers_2.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.0/Transpose"](%/text_encoder/encoder/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_2.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.0/ReduceMean"](%/text_encoder/encoder/norm_layers_2.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_2.0/Sub"](%/text_encoder/encoder/norm_layers_2.0/Transpose_output_0, %/text_encoder/encoder/norm_layers_2.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_2.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_2.0/Pow"](%/text_encoder/encoder/norm_layers_2.0/Sub_output_0, %/text_encoder/encoder/norm_layers_2.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.0/ReduceMean_1"](%/text_encoder/encoder/norm_layers_2.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_2.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.0/Add"](%/text_encoder/encoder/norm_layers_2.0/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_2.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_2.0/Sqrt"](%/text_encoder/encoder/norm_layers_2.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_2.0/Div"](%/text_encoder/encoder/norm_layers_2.0/Sub_output_0, %/text_encoder/encoder/norm_layers_2.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_2.0/Mul"](%/text_encoder/encoder/norm_layers_2.0/Div_output_0, %text_encoder.encoder.norm_layers_2.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.0/Add_1"](%/text_encoder/encoder/norm_layers_2.0/Mul_output_0, %text_encoder.encoder.norm_layers_2.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.0/Transpose_1"](%/text_encoder/encoder/norm_layers_2.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/Mul_2"](%/text_encoder/encoder/norm_layers_2.0/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:419:0
  %/text_encoder/encoder/attn_layers.1/conv_q/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.1/conv_q/Conv"](%/text_encoder/encoder/Mul_2_output_0, %text_encoder.encoder.attn_layers.1.conv_q.weight, %text_encoder.encoder.attn_layers.1.conv_q.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1/torch.nn.modules.conv.Conv1d::conv_q # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.1/conv_k/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.1/conv_k/Conv"](%/text_encoder/encoder/Mul_2_output_0, %text_encoder.encoder.attn_layers.1.conv_k.weight, %text_encoder.encoder.attn_layers.1.conv_k.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1/torch.nn.modules.conv.Conv1d::conv_k # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.1/conv_v/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.1/conv_v/Conv"](%/text_encoder/encoder/Mul_2_output_0, %text_encoder.encoder.attn_layers.1.conv_v.weight, %text_encoder.encoder.attn_layers.1.conv_v.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1/torch.nn.modules.conv.Conv1d::conv_v # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.1/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape"](%/text_encoder/encoder/attn_layers.1/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather"](%/text_encoder/encoder/attn_layers.1/Shape_output_0, %/text_encoder/encoder/attn_layers.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_1"](%/text_encoder/encoder/attn_layers.1/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_1"](%/text_encoder/encoder/attn_layers.1/Shape_1_output_0, %/text_encoder/encoder/attn_layers.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_2"](%/text_encoder/encoder/attn_layers.1/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_2"](%/text_encoder/encoder/attn_layers.1/Shape_2_output_0, %/text_encoder/encoder/attn_layers.1/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_3"](%/text_encoder/encoder/attn_layers.1/conv_q/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.1/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_3"](%/text_encoder/encoder/attn_layers.1/Shape_3_output_0, %/text_encoder/encoder/attn_layers.1/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %onnx::Unsqueeze_1466 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze"](%/text_encoder/encoder/attn_layers.1/Gather_output_0, %onnx::Unsqueeze_1466), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1472 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_1"](%/text_encoder/encoder/attn_layers.1/Gather_3_output_0, %onnx::Unsqueeze_1472), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_output_0, %/text_encoder/encoder/attn_layers.1/Constant_4_output_0, %/text_encoder/encoder/attn_layers.1/Constant_5_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.1/Reshape_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape"](%/text_encoder/encoder/attn_layers.1/conv_q/Conv_output_0, %/text_encoder/encoder/attn_layers.1/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.1/Transpose_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose"](%/text_encoder/encoder/attn_layers.1/Reshape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %onnx::Unsqueeze_1477 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_2"](%/text_encoder/encoder/attn_layers.1/Gather_output_0, %onnx::Unsqueeze_1477), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1483 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_3"](%/text_encoder/encoder/attn_layers.1/Gather_2_output_0, %onnx::Unsqueeze_1483), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_1"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_2_output_0, %/text_encoder/encoder/attn_layers.1/Constant_6_output_0, %/text_encoder/encoder/attn_layers.1/Constant_7_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %onnx::Unsqueeze_1486 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_4"](%/text_encoder/encoder/attn_layers.1/Gather_output_0, %onnx::Unsqueeze_1486), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1492 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_5"](%/text_encoder/encoder/attn_layers.1/Gather_2_output_0, %onnx::Unsqueeze_1492), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_2"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_4_output_0, %/text_encoder/encoder/attn_layers.1/Constant_8_output_0, %/text_encoder/encoder/attn_layers.1/Constant_9_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.1/Reshape_1_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_1"](%/text_encoder/encoder/attn_layers.1/conv_k/Conv_output_0, %/text_encoder/encoder/attn_layers.1/Concat_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %/text_encoder/encoder/attn_layers.1/Reshape_2_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_2"](%/text_encoder/encoder/attn_layers.1/conv_v/Conv_output_0, %/text_encoder/encoder/attn_layers.1/Concat_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.1/Transpose_1_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose_1"](%/text_encoder/encoder/attn_layers.1/Reshape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.1/MatMul_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.1/MatMul"](%/text_encoder/encoder/attn_layers.1/Transpose_output_0, %/text_encoder/encoder/attn_layers.1/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.1/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.1/Div_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.1/Div"](%/text_encoder/encoder/attn_layers.1/MatMul_output_0, %/text_encoder/encoder/attn_layers.1/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.1/Constant_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.1/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub"](%/text_encoder/encoder/attn_layers.1/Gather_2_output_0, %/text_encoder/encoder/attn_layers.1/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.1/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.1/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.1/Mul"](%/text_encoder/encoder/attn_layers.1/Gather_2_output_0, %/text_encoder/encoder/attn_layers.1/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.1/Constant_13_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.1/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub_1"](%/text_encoder/encoder/attn_layers.1/Mul_output_0, %/text_encoder/encoder/attn_layers.1/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.1/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1511 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_6"](%/text_encoder/encoder/attn_layers.1/Sub_output_0, %onnx::Unsqueeze_1511), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1513 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_7"](%/text_encoder/encoder/attn_layers.1/Sub_output_0, %onnx::Unsqueeze_1513), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_3"](%/text_encoder/encoder/attn_layers.1/Constant_14_output_0, %/text_encoder/encoder/attn_layers.1/Constant_15_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_6_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_7_output_0, %/text_encoder/encoder/attn_layers.1/Constant_16_output_0, %/text_encoder/encoder/attn_layers.1/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1524 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_8"](%/text_encoder/encoder/attn_layers.1/Sub_output_0, %onnx::Unsqueeze_1524), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1526 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_9"](%/text_encoder/encoder/attn_layers.1/Sub_output_0, %onnx::Unsqueeze_1526), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_4"](%/text_encoder/encoder/attn_layers.1/Constant_18_output_0, %/text_encoder/encoder/attn_layers.1/Constant_19_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_8_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_9_output_0, %/text_encoder/encoder/attn_layers.1/Constant_20_output_0, %/text_encoder/encoder/attn_layers.1/Constant_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1537 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_10"](%/text_encoder/encoder/attn_layers.1/Sub_output_0, %onnx::Unsqueeze_1537), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1539 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_11"](%/text_encoder/encoder/attn_layers.1/Sub_output_0, %onnx::Unsqueeze_1539), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_5"](%/text_encoder/encoder/attn_layers.1/Constant_22_output_0, %/text_encoder/encoder/attn_layers.1/Constant_23_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_10_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_11_output_0, %/text_encoder/encoder/attn_layers.1/Constant_24_output_0, %/text_encoder/encoder/attn_layers.1/Constant_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1550 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_12"](%/text_encoder/encoder/attn_layers.1/Sub_output_0, %onnx::Unsqueeze_1550), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1552 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_13"](%/text_encoder/encoder/attn_layers.1/Sub_output_0, %onnx::Unsqueeze_1552), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_6"](%/text_encoder/encoder/attn_layers.1/Constant_26_output_0, %/text_encoder/encoder/attn_layers.1/Constant_27_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_12_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_13_output_0, %/text_encoder/encoder/attn_layers.1/Constant_28_output_0, %/text_encoder/encoder/attn_layers.1/Constant_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_4"](%/text_encoder/encoder/attn_layers.1/Concat_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_4"](%/text_encoder/encoder/attn_layers.1/Shape_4_output_0, %/text_encoder/encoder/attn_layers.1/Constant_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub_2"](%/text_encoder/encoder/attn_layers.1/Constant_31_output_0, %/text_encoder/encoder/attn_layers.1/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast"](%/text_encoder/encoder/attn_layers.1/Concat_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/ConstantOfShape"](%/text_encoder/encoder/attn_layers.1/Sub_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Concat_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_7"](%/text_encoder/encoder/attn_layers.1/Cast_output_0, %/text_encoder/encoder/attn_layers.1/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_32_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.1/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_3"](%/text_encoder/encoder/attn_layers.1/Concat_7_output_0, %/text_encoder/encoder/attn_layers.1/Constant_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice"](%/text_encoder/encoder/attn_layers.1/Reshape_3_output_0, %/text_encoder/encoder/attn_layers.1/Constant_34_output_0, %/text_encoder/encoder/attn_layers.1/Constant_35_output_0, %/text_encoder/encoder/attn_layers.1/Constant_33_output_0, %/text_encoder/encoder/attn_layers.1/Constant_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Transpose_2_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose_2"](%/text_encoder/encoder/attn_layers.1/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_4"](%/text_encoder/encoder/attn_layers.1/Transpose_2_output_0, %/text_encoder/encoder/attn_layers.1/Constant_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_1"](%/text_encoder/encoder/attn_layers.1/Reshape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Pad_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.1/Pad"](%text_encoder.encoder.attn_layers.1.emb_rel_k, %/text_encoder/encoder/attn_layers.1/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_40"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_14"](%/text_encoder/encoder/attn_layers.1/Sub_1_output_0, %/text_encoder/encoder/attn_layers.1/Constant_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_41"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Slice_1_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_1"](%/text_encoder/encoder/attn_layers.1/Pad_output_0, %/text_encoder/encoder/attn_layers.1/Constant_39_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_14_output_0, %/text_encoder/encoder/attn_layers.1/Constant_38_output_0, %/text_encoder/encoder/attn_layers.1/Constant_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_42"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_15_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_15"](%/text_encoder/encoder/attn_layers.1/Slice_1_output_0, %/text_encoder/encoder/attn_layers.1/Constant_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.1/Transpose_3_output_0 : Float(1, *, *, *, strides=[19104, 19104, 1, 96], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose_3"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.1/MatMul_1_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.1/MatMul_1"](%/text_encoder/encoder/attn_layers.1/Transpose_output_0, %/text_encoder/encoder/attn_layers.1/Transpose_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.1/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_5"](%/text_encoder/encoder/attn_layers.1/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.1/Constant_43_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_43"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.1/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_5"](%/text_encoder/encoder/attn_layers.1/Shape_5_output_0, %/text_encoder/encoder/attn_layers.1/Constant_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.1/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_6"](%/text_encoder/encoder/attn_layers.1/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.1/Constant_44_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_44"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.1/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_6"](%/text_encoder/encoder/attn_layers.1/Shape_6_output_0, %/text_encoder/encoder/attn_layers.1/Constant_44_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.1/Shape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_7"](%/text_encoder/encoder/attn_layers.1/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.1/Constant_45_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_45"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.1/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_7"](%/text_encoder/encoder/attn_layers.1/Shape_7_output_0, %/text_encoder/encoder/attn_layers.1/Constant_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.1/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_46"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_47_output_0 : Long(8, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  0  0  0  0  0  0 [ CPULongType{8} ], onnx_name="/text_encoder/encoder/attn_layers.1/Constant_47"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/ConstantOfShape_1"](%/text_encoder/encoder/attn_layers.1/Constant_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Concat_8_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_8"](%/text_encoder/encoder/attn_layers.1/Constant_47_output_0, %/text_encoder/encoder/attn_layers.1/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_48_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.1/Constant_48"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_5_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_5"](%/text_encoder/encoder/attn_layers.1/Concat_8_output_0, %/text_encoder/encoder/attn_layers.1/Constant_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_49"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_50"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_51"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_52"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Slice_2_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_2"](%/text_encoder/encoder/attn_layers.1/Reshape_5_output_0, %/text_encoder/encoder/attn_layers.1/Constant_50_output_0, %/text_encoder/encoder/attn_layers.1/Constant_51_output_0, %/text_encoder/encoder/attn_layers.1/Constant_49_output_0, %/text_encoder/encoder/attn_layers.1/Constant_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Transpose_4_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose_4"](%/text_encoder/encoder/attn_layers.1/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_53"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_6"](%/text_encoder/encoder/attn_layers.1/Transpose_4_output_0, %/text_encoder/encoder/attn_layers.1/Constant_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_2"](%/text_encoder/encoder/attn_layers.1/Reshape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Pad_1_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.1/Pad_1"](%/text_encoder/encoder/attn_layers.1/MatMul_1_output_0, %/text_encoder/encoder/attn_layers.1/Cast_2_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_54_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_54"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.1/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.1/Mul_1"](%/text_encoder/encoder/attn_layers.1/Gather_7_output_0, %/text_encoder/encoder/attn_layers.1/Constant_54_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.1/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.1/Mul_2"](%/text_encoder/encoder/attn_layers.1/Mul_1_output_0, %/text_encoder/encoder/attn_layers.1/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %onnx::Unsqueeze_1628 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_16"](%/text_encoder/encoder/attn_layers.1/Gather_5_output_0, %onnx::Unsqueeze_1628), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1630 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_17"](%/text_encoder/encoder/attn_layers.1/Gather_6_output_0, %onnx::Unsqueeze_1630), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1632 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_18"](%/text_encoder/encoder/attn_layers.1/Mul_2_output_0, %onnx::Unsqueeze_1632), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_9"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_16_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_17_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.1/Reshape_7_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_7"](%/text_encoder/encoder/attn_layers.1/Pad_1_output_0, %/text_encoder/encoder/attn_layers.1/Concat_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.1/Constant_55_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_55"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.1/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub_3"](%/text_encoder/encoder/attn_layers.1/Gather_7_output_0, %/text_encoder/encoder/attn_layers.1/Constant_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.1/Constant_56_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_56"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1640 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_19"](%/text_encoder/encoder/attn_layers.1/Sub_3_output_0, %onnx::Unsqueeze_1640), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_57"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_58"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_59_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_59"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_60_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_60"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_10"](%/text_encoder/encoder/attn_layers.1/Constant_56_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_19_output_0, %/text_encoder/encoder/attn_layers.1/Constant_57_output_0, %/text_encoder/encoder/attn_layers.1/Constant_58_output_0, %/text_encoder/encoder/attn_layers.1/Constant_59_output_0, %/text_encoder/encoder/attn_layers.1/Constant_60_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_61_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_61"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1653 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_20"](%/text_encoder/encoder/attn_layers.1/Sub_3_output_0, %onnx::Unsqueeze_1653), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_62_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_62"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_63_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_63"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_64_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_64"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_65_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_65"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_11"](%/text_encoder/encoder/attn_layers.1/Constant_61_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_20_output_0, %/text_encoder/encoder/attn_layers.1/Constant_62_output_0, %/text_encoder/encoder/attn_layers.1/Constant_63_output_0, %/text_encoder/encoder/attn_layers.1/Constant_64_output_0, %/text_encoder/encoder/attn_layers.1/Constant_65_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_66_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_66"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Shape_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_8"](%/text_encoder/encoder/attn_layers.1/Concat_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Gather_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_8"](%/text_encoder/encoder/attn_layers.1/Shape_8_output_0, %/text_encoder/encoder/attn_layers.1/Constant_66_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_67_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_67"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Sub_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub_4"](%/text_encoder/encoder/attn_layers.1/Constant_67_output_0, %/text_encoder/encoder/attn_layers.1/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_3"](%/text_encoder/encoder/attn_layers.1/Concat_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/ConstantOfShape_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/ConstantOfShape_2"](%/text_encoder/encoder/attn_layers.1/Sub_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Concat_12_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_12"](%/text_encoder/encoder/attn_layers.1/Cast_3_output_0, %/text_encoder/encoder/attn_layers.1/ConstantOfShape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_68_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.1/Constant_68"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_8_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_8"](%/text_encoder/encoder/attn_layers.1/Concat_12_output_0, %/text_encoder/encoder/attn_layers.1/Constant_68_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_69_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_69"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_70"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_71_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_71"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_72"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Slice_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_3"](%/text_encoder/encoder/attn_layers.1/Reshape_8_output_0, %/text_encoder/encoder/attn_layers.1/Constant_70_output_0, %/text_encoder/encoder/attn_layers.1/Constant_71_output_0, %/text_encoder/encoder/attn_layers.1/Constant_69_output_0, %/text_encoder/encoder/attn_layers.1/Constant_72_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Transpose_5_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose_5"](%/text_encoder/encoder/attn_layers.1/Slice_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_73_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_73"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_9"](%/text_encoder/encoder/attn_layers.1/Transpose_5_output_0, %/text_encoder/encoder/attn_layers.1/Constant_73_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_4"](%/text_encoder/encoder/attn_layers.1/Reshape_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Pad_2_output_0 : Float(*, *, *, strides=[40198, 20099, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.1/Pad_2"](%/text_encoder/encoder/attn_layers.1/Reshape_7_output_0, %/text_encoder/encoder/attn_layers.1/Cast_4_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_74_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_74"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.1/Add"](%/text_encoder/encoder/attn_layers.1/Gather_7_output_0, %/text_encoder/encoder/attn_layers.1/Constant_74_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_75_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_75"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Sub_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub_5"](%/text_encoder/encoder/attn_layers.1/Mul_1_output_0, %/text_encoder/encoder/attn_layers.1/Constant_75_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %onnx::Unsqueeze_1690 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_21"](%/text_encoder/encoder/attn_layers.1/Gather_5_output_0, %onnx::Unsqueeze_1690), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1692 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_22"](%/text_encoder/encoder/attn_layers.1/Gather_6_output_0, %onnx::Unsqueeze_1692), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1694 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_23"](%/text_encoder/encoder/attn_layers.1/Add_output_0, %onnx::Unsqueeze_1694), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1696 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_24"](%/text_encoder/encoder/attn_layers.1/Sub_5_output_0, %onnx::Unsqueeze_1696), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_13"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_21_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_22_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_23_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Reshape_10_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_10"](%/text_encoder/encoder/attn_layers.1/Pad_2_output_0, %/text_encoder/encoder/attn_layers.1/Concat_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_76"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_77_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_77"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_78"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_25"](%/text_encoder/encoder/attn_layers.1/Gather_7_output_0, %/text_encoder/encoder/attn_layers.1/Constant_78_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_79_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_79"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Slice_4_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_4"](%/text_encoder/encoder/attn_layers.1/Reshape_10_output_0, %/text_encoder/encoder/attn_layers.1/Constant_77_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_25_output_0, %/text_encoder/encoder/attn_layers.1/Constant_76_output_0, %/text_encoder/encoder/attn_layers.1/Constant_79_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_80_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_80"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_81"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_26"](%/text_encoder/encoder/attn_layers.1/Sub_3_output_0, %/text_encoder/encoder/attn_layers.1/Constant_81_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_82_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_82"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_83_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_83"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Slice_5_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_5"](%/text_encoder/encoder/attn_layers.1/Slice_4_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_26_output_0, %/text_encoder/encoder/attn_layers.1/Constant_82_output_0, %/text_encoder/encoder/attn_layers.1/Constant_80_output_0, %/text_encoder/encoder/attn_layers.1/Constant_83_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.1/Constant_84_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_84"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.1/Div_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.1/Div_1"](%/text_encoder/encoder/attn_layers.1/Slice_5_output_0, %/text_encoder/encoder/attn_layers.1/Constant_84_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.1/Add_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.1/Add_1"](%/text_encoder/encoder/attn_layers.1/Div_output_0, %/text_encoder/encoder/attn_layers.1/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:139:0
  %/text_encoder/encoder/attn_layers.1/Cast_5_output_0 : Bool(*, 1, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_5"](%/text_encoder/encoder/attn_layers.0/Equal_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.1/Constant_85_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_85"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.1/Where_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/text_encoder/encoder/attn_layers.1/Where"](%/text_encoder/encoder/attn_layers.1/Cast_5_output_0, %/text_encoder/encoder/attn_layers.1/Constant_85_output_0, %/text_encoder/encoder/attn_layers.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.1/Softmax_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/text_encoder/encoder/attn_layers.1/Softmax"](%/text_encoder/encoder/attn_layers.1/Where_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/text_encoder/encoder/attn_layers.1/MatMul_2_output_0 : Float(*, *, *, 96, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.1/MatMul_2"](%/text_encoder/encoder/attn_layers.1/Softmax_output_0, %/text_encoder/encoder/attn_layers.1/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:156:0
  %/text_encoder/encoder/attn_layers.1/Shape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_9"](%/text_encoder/encoder/attn_layers.1/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.1/Constant_86_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_86"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.1/Gather_9_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_9"](%/text_encoder/encoder/attn_layers.1/Shape_9_output_0, %/text_encoder/encoder/attn_layers.1/Constant_86_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.1/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_10"](%/text_encoder/encoder/attn_layers.1/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.1/Constant_87_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_87"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.1/Gather_10_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_10"](%/text_encoder/encoder/attn_layers.1/Shape_10_output_0, %/text_encoder/encoder/attn_layers.1/Constant_87_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.1/Shape_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_11"](%/text_encoder/encoder/attn_layers.1/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.1/Constant_88_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_88"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.1/Gather_11_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_11"](%/text_encoder/encoder/attn_layers.1/Shape_11_output_0, %/text_encoder/encoder/attn_layers.1/Constant_88_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.1/Constant_89_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_89"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.1/Sub_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub_6"](%/text_encoder/encoder/attn_layers.1/Gather_11_output_0, %/text_encoder/encoder/attn_layers.1/Constant_89_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.1/Constant_90_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_90"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1739 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_27"](%/text_encoder/encoder/attn_layers.1/Sub_6_output_0, %onnx::Unsqueeze_1739), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_91_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_91"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_92_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_92"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_93_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_93"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_94_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_94"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_95_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_95"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_96_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_96"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_14_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_14"](%/text_encoder/encoder/attn_layers.1/Constant_90_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_27_output_0, %/text_encoder/encoder/attn_layers.1/Constant_91_output_0, %/text_encoder/encoder/attn_layers.1/Constant_92_output_0, %/text_encoder/encoder/attn_layers.1/Constant_93_output_0, %/text_encoder/encoder/attn_layers.1/Constant_94_output_0, %/text_encoder/encoder/attn_layers.1/Constant_95_output_0, %/text_encoder/encoder/attn_layers.1/Constant_96_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_97_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_97"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1756 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_28"](%/text_encoder/encoder/attn_layers.1/Sub_6_output_0, %onnx::Unsqueeze_1756), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_98_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_98"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_99_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_99"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_100_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_100"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_101_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_101"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_102_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_102"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_103_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_103"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_15_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_15"](%/text_encoder/encoder/attn_layers.1/Constant_97_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_28_output_0, %/text_encoder/encoder/attn_layers.1/Constant_98_output_0, %/text_encoder/encoder/attn_layers.1/Constant_99_output_0, %/text_encoder/encoder/attn_layers.1/Constant_100_output_0, %/text_encoder/encoder/attn_layers.1/Constant_101_output_0, %/text_encoder/encoder/attn_layers.1/Constant_102_output_0, %/text_encoder/encoder/attn_layers.1/Constant_103_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_104_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_104"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Shape_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_12"](%/text_encoder/encoder/attn_layers.1/Concat_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Gather_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_12"](%/text_encoder/encoder/attn_layers.1/Shape_12_output_0, %/text_encoder/encoder/attn_layers.1/Constant_104_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_105_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_105"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Sub_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub_7"](%/text_encoder/encoder/attn_layers.1/Constant_105_output_0, %/text_encoder/encoder/attn_layers.1/Gather_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_6"](%/text_encoder/encoder/attn_layers.1/Concat_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/ConstantOfShape_3_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/ConstantOfShape_3"](%/text_encoder/encoder/attn_layers.1/Sub_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Concat_16_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_16"](%/text_encoder/encoder/attn_layers.1/Cast_6_output_0, %/text_encoder/encoder/attn_layers.1/ConstantOfShape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_106_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.1/Constant_106"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_11_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_11"](%/text_encoder/encoder/attn_layers.1/Concat_16_output_0, %/text_encoder/encoder/attn_layers.1/Constant_106_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_107_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_107"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_108"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_109_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_109"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_110"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Slice_6_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_6"](%/text_encoder/encoder/attn_layers.1/Reshape_11_output_0, %/text_encoder/encoder/attn_layers.1/Constant_108_output_0, %/text_encoder/encoder/attn_layers.1/Constant_109_output_0, %/text_encoder/encoder/attn_layers.1/Constant_107_output_0, %/text_encoder/encoder/attn_layers.1/Constant_110_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Transpose_6_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose_6"](%/text_encoder/encoder/attn_layers.1/Slice_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_111_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_111"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_12_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_12"](%/text_encoder/encoder/attn_layers.1/Transpose_6_output_0, %/text_encoder/encoder/attn_layers.1/Constant_111_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_7_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_7"](%/text_encoder/encoder/attn_layers.1/Reshape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Pad_3_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.1/Pad_3"](%/text_encoder/encoder/attn_layers.1/Softmax_output_0, %/text_encoder/encoder/attn_layers.1/Cast_7_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_112_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_112"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.1/Pow_output_0 : Long(requires_grad=0, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/attn_layers.1/Pow"](%/text_encoder/encoder/attn_layers.1/Gather_11_output_0, %/text_encoder/encoder/attn_layers.1/Constant_112_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.1/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.1/Mul_3"](%/text_encoder/encoder/attn_layers.1/Gather_11_output_0, %/text_encoder/encoder/attn_layers.1/Sub_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.1/Add_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.1/Add_2"](%/text_encoder/encoder/attn_layers.1/Pow_output_0, %/text_encoder/encoder/attn_layers.1/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_1797 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_29"](%/text_encoder/encoder/attn_layers.1/Gather_9_output_0, %onnx::Unsqueeze_1797), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1799 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_30"](%/text_encoder/encoder/attn_layers.1/Gather_10_output_0, %onnx::Unsqueeze_1799), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1801 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_31"](%/text_encoder/encoder/attn_layers.1/Add_2_output_0, %onnx::Unsqueeze_1801), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_17_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_17"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_29_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_30_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.1/Reshape_13_output_0 : Float(*, *, *, strides=[39800, 19900, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_13"](%/text_encoder/encoder/attn_layers.1/Pad_3_output_0, %/text_encoder/encoder/attn_layers.1/Concat_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_1805 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_32"](%/text_encoder/encoder/attn_layers.1/Gather_11_output_0, %onnx::Unsqueeze_1805), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_113_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_113"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_114_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_114"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_115_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_115"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_116_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_116"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_117_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_117"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_18"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_32_output_0, %/text_encoder/encoder/attn_layers.1/Constant_113_output_0, %/text_encoder/encoder/attn_layers.1/Constant_114_output_0, %/text_encoder/encoder/attn_layers.1/Constant_115_output_0, %/text_encoder/encoder/attn_layers.1/Constant_116_output_0, %/text_encoder/encoder/attn_layers.1/Constant_117_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %onnx::Unsqueeze_1818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_33"](%/text_encoder/encoder/attn_layers.1/Gather_11_output_0, %onnx::Unsqueeze_1818), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_118_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_118"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_119_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_119"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_120_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_120"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_121_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_121"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Constant_122_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_122"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_19_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_19"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_33_output_0, %/text_encoder/encoder/attn_layers.1/Constant_118_output_0, %/text_encoder/encoder/attn_layers.1/Constant_119_output_0, %/text_encoder/encoder/attn_layers.1/Constant_120_output_0, %/text_encoder/encoder/attn_layers.1/Constant_121_output_0, %/text_encoder/encoder/attn_layers.1/Constant_122_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_123_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_123"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Shape_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_13"](%/text_encoder/encoder/attn_layers.1/Concat_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Gather_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_13"](%/text_encoder/encoder/attn_layers.1/Shape_13_output_0, %/text_encoder/encoder/attn_layers.1/Constant_123_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_124_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_124"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Sub_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub_8"](%/text_encoder/encoder/attn_layers.1/Constant_124_output_0, %/text_encoder/encoder/attn_layers.1/Gather_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_8"](%/text_encoder/encoder/attn_layers.1/Concat_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/ConstantOfShape_4_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/ConstantOfShape_4"](%/text_encoder/encoder/attn_layers.1/Sub_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Concat_20_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_20"](%/text_encoder/encoder/attn_layers.1/Cast_8_output_0, %/text_encoder/encoder/attn_layers.1/ConstantOfShape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_125_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.1/Constant_125"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_14_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_14"](%/text_encoder/encoder/attn_layers.1/Concat_20_output_0, %/text_encoder/encoder/attn_layers.1/Constant_125_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_126_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_126"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_127_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_127"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_128_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_128"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_129_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_129"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Slice_7_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_7"](%/text_encoder/encoder/attn_layers.1/Reshape_14_output_0, %/text_encoder/encoder/attn_layers.1/Constant_127_output_0, %/text_encoder/encoder/attn_layers.1/Constant_128_output_0, %/text_encoder/encoder/attn_layers.1/Constant_126_output_0, %/text_encoder/encoder/attn_layers.1/Constant_129_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Transpose_7_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose_7"](%/text_encoder/encoder/attn_layers.1/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_130_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_130"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_15_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_15"](%/text_encoder/encoder/attn_layers.1/Transpose_7_output_0, %/text_encoder/encoder/attn_layers.1/Constant_130_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_9"](%/text_encoder/encoder/attn_layers.1/Reshape_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Pad_4_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.1/Pad_4"](%/text_encoder/encoder/attn_layers.1/Reshape_13_output_0, %/text_encoder/encoder/attn_layers.1/Cast_9_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_131_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_131"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.1/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.1/Mul_4"](%/text_encoder/encoder/attn_layers.1/Gather_11_output_0, %/text_encoder/encoder/attn_layers.1/Constant_131_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %onnx::Unsqueeze_1855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_34"](%/text_encoder/encoder/attn_layers.1/Gather_9_output_0, %onnx::Unsqueeze_1855), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1857 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_35"](%/text_encoder/encoder/attn_layers.1/Gather_10_output_0, %onnx::Unsqueeze_1857), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1859 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_36"](%/text_encoder/encoder/attn_layers.1/Gather_11_output_0, %onnx::Unsqueeze_1859), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1861 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_37"](%/text_encoder/encoder/attn_layers.1/Mul_4_output_0, %onnx::Unsqueeze_1861), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_21_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_21"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_34_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_35_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_36_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.1/Reshape_16_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_16"](%/text_encoder/encoder/attn_layers.1/Pad_4_output_0, %/text_encoder/encoder/attn_layers.1/Concat_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.1/Constant_132_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_132"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.1/Constant_133_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_133"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.1/Constant_134_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_134"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.1/Constant_135_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_135"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.1/Slice_8_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_8"](%/text_encoder/encoder/attn_layers.1/Reshape_16_output_0, %/text_encoder/encoder/attn_layers.1/Constant_133_output_0, %/text_encoder/encoder/attn_layers.1/Constant_134_output_0, %/text_encoder/encoder/attn_layers.1/Constant_132_output_0, %/text_encoder/encoder/attn_layers.1/Constant_135_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.1/Constant_136_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_136"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.1/Shape_14"](%/text_encoder/encoder/attn_layers.1/Concat_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Gather_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Gather_14"](%/text_encoder/encoder/attn_layers.1/Shape_14_output_0, %/text_encoder/encoder/attn_layers.1/Constant_136_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_137_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_137"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Sub_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.1/Sub_9"](%/text_encoder/encoder/attn_layers.1/Constant_137_output_0, %/text_encoder/encoder/attn_layers.1/Gather_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_10"](%/text_encoder/encoder/attn_layers.1/Concat_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/ConstantOfShape_5_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/ConstantOfShape_5"](%/text_encoder/encoder/attn_layers.1/Sub_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Concat_22_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_22"](%/text_encoder/encoder/attn_layers.1/Cast_10_output_0, %/text_encoder/encoder/attn_layers.1/ConstantOfShape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_138_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.1/Constant_138"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_17_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_17"](%/text_encoder/encoder/attn_layers.1/Concat_22_output_0, %/text_encoder/encoder/attn_layers.1/Constant_138_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_139_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_139"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_140_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_140"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_141"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_142_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_142"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Slice_9_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_9"](%/text_encoder/encoder/attn_layers.1/Reshape_17_output_0, %/text_encoder/encoder/attn_layers.1/Constant_140_output_0, %/text_encoder/encoder/attn_layers.1/Constant_141_output_0, %/text_encoder/encoder/attn_layers.1/Constant_139_output_0, %/text_encoder/encoder/attn_layers.1/Constant_142_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Transpose_8_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose_8"](%/text_encoder/encoder/attn_layers.1/Slice_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_143"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Reshape_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_18"](%/text_encoder/encoder/attn_layers.1/Transpose_8_output_0, %/text_encoder/encoder/attn_layers.1/Constant_143_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Cast_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.1/Cast_11"](%/text_encoder/encoder/attn_layers.1/Reshape_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Pad_5_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.1/Pad_5"](%text_encoder.encoder.attn_layers.1.emb_rel_v, %/text_encoder/encoder/attn_layers.1/Cast_11_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.1/Constant_144_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_144"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Constant_145_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_145"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Constant_146_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_146"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_38"](%/text_encoder/encoder/attn_layers.1/Sub_1_output_0, %/text_encoder/encoder/attn_layers.1/Constant_146_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Constant_147_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_147"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Slice_10_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.1/Slice_10"](%/text_encoder/encoder/attn_layers.1/Pad_5_output_0, %/text_encoder/encoder/attn_layers.1/Constant_145_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_38_output_0, %/text_encoder/encoder/attn_layers.1/Constant_144_output_0, %/text_encoder/encoder/attn_layers.1/Constant_147_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.1/Constant_148_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.1/Constant_148"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_39_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_39"](%/text_encoder/encoder/attn_layers.1/Slice_10_output_0, %/text_encoder/encoder/attn_layers.1/Constant_148_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.1/MatMul_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.1/MatMul_3"](%/text_encoder/encoder/attn_layers.1/Slice_8_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.1/Add_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.1/Add_3"](%/text_encoder/encoder/attn_layers.1/MatMul_2_output_0, %/text_encoder/encoder/attn_layers.1/MatMul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:161:0
  %/text_encoder/encoder/attn_layers.1/Transpose_9_output_0 : Float(*, *, *, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.1/Transpose_9"](%/text_encoder/encoder/attn_layers.1/Add_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %onnx::Unsqueeze_1910 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_40"](%/text_encoder/encoder/attn_layers.1/Gather_output_0, %onnx::Unsqueeze_1910), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1912 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_41"](%/text_encoder/encoder/attn_layers.1/Gather_1_output_0, %onnx::Unsqueeze_1912), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %onnx::Unsqueeze_1914 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.1/Unsqueeze_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.1/Unsqueeze_42"](%/text_encoder/encoder/attn_layers.1/Gather_3_output_0, %onnx::Unsqueeze_1914), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1
  %/text_encoder/encoder/attn_layers.1/Concat_23_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.1/Concat_23"](%/text_encoder/encoder/attn_layers.1/Unsqueeze_40_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_41_output_0, %/text_encoder/encoder/attn_layers.1/Unsqueeze_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.1/Reshape_19_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.1/Reshape_19"](%/text_encoder/encoder/attn_layers.1/Transpose_9_output_0, %/text_encoder/encoder/attn_layers.1/Concat_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.1/conv_o/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.1/conv_o/Conv"](%/text_encoder/encoder/attn_layers.1/Reshape_19_output_0, %text_encoder.encoder.attn_layers.1.conv_o.weight, %text_encoder.encoder.attn_layers.1.conv_o.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.1/torch.nn.modules.conv.Conv1d::conv_o # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/Add_2_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_2"](%/text_encoder/encoder/Mul_2_output_0, %/text_encoder/encoder/attn_layers.1/conv_o/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:422:0
  %/text_encoder/encoder/norm_layers_1.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.1/Transpose"](%/text_encoder/encoder/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_1.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.1/ReduceMean"](%/text_encoder/encoder/norm_layers_1.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_1.1/Sub"](%/text_encoder/encoder/norm_layers_1.1/Transpose_output_0, %/text_encoder/encoder/norm_layers_1.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_1.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_1.1/Pow"](%/text_encoder/encoder/norm_layers_1.1/Sub_output_0, %/text_encoder/encoder/norm_layers_1.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.1/ReduceMean_1"](%/text_encoder/encoder/norm_layers_1.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_1.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.1/Add"](%/text_encoder/encoder/norm_layers_1.1/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_1.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_1.1/Sqrt"](%/text_encoder/encoder/norm_layers_1.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_1.1/Div"](%/text_encoder/encoder/norm_layers_1.1/Sub_output_0, %/text_encoder/encoder/norm_layers_1.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_1.1/Mul"](%/text_encoder/encoder/norm_layers_1.1/Div_output_0, %text_encoder.encoder.norm_layers_1.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.1/Add_1"](%/text_encoder/encoder/norm_layers_1.1/Mul_output_0, %text_encoder.encoder.norm_layers_1.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.1/Transpose_1"](%/text_encoder/encoder/norm_layers_1.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/ffn_layers.1/Mul_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.1/Mul"](%/text_encoder/encoder/norm_layers_1.1/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:291:0
  %/text_encoder/encoder/ffn_layers.1/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_1_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.1/ConstantOfShape"](%/text_encoder/encoder/ffn_layers.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.1/Concat"](%/text_encoder/encoder/ffn_layers.1/Constant_1_output_0, %/text_encoder/encoder/ffn_layers.1/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Reshape_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.1/Reshape"](%/text_encoder/encoder/ffn_layers.1/Concat_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.1/Slice"](%/text_encoder/encoder/ffn_layers.1/Reshape_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_4_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_5_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_3_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Transpose_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.1/Transpose"](%/text_encoder/encoder/ffn_layers.1/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Reshape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.1/Reshape_1"](%/text_encoder/encoder/ffn_layers.1/Transpose_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.1/Cast"](%/text_encoder/encoder/ffn_layers.1/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Pad_output_0 : Float(*, *, *, strides=[19584, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.1/Pad"](%/text_encoder/encoder/ffn_layers.1/Mul_output_0, %/text_encoder/encoder/ffn_layers.1/Cast_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/conv_1/Conv_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.1/conv_1/Conv"](%/text_encoder/encoder/ffn_layers.1/Pad_output_0, %text_encoder.encoder.ffn_layers.1.conv_1.weight, %text_encoder.encoder.ffn_layers.1.conv_1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1/torch.nn.modules.conv.Conv1d::conv_1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.1/Relu_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name="/text_encoder/encoder/ffn_layers.1/Relu"](%/text_encoder/encoder/ffn_layers.1/conv_1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:292:0
  %/text_encoder/encoder/ffn_layers.1/Mul_1_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.1/Mul_1"](%/text_encoder/encoder/ffn_layers.1/Relu_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:294:0
  %/text_encoder/encoder/ffn_layers.1/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_9_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.1/ConstantOfShape_1"](%/text_encoder/encoder/ffn_layers.1/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.1/Concat_1"](%/text_encoder/encoder/ffn_layers.1/Constant_9_output_0, %/text_encoder/encoder/ffn_layers.1/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Reshape_2_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.1/Reshape_2"](%/text_encoder/encoder/ffn_layers.1/Concat_1_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Slice_1_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.1/Slice_1"](%/text_encoder/encoder/ffn_layers.1/Reshape_2_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_12_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_13_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_11_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Transpose_1_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.1/Transpose_1"](%/text_encoder/encoder/ffn_layers.1/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.1/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Reshape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.1/Reshape_3"](%/text_encoder/encoder/ffn_layers.1/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.1/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.1/Cast_1"](%/text_encoder/encoder/ffn_layers.1/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/Pad_1_output_0 : Float(*, *, *, strides=[78336, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.1/Pad_1"](%/text_encoder/encoder/ffn_layers.1/Mul_1_output_0, %/text_encoder/encoder/ffn_layers.1/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.1/conv_2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.1/conv_2/Conv"](%/text_encoder/encoder/ffn_layers.1/Pad_1_output_0, %text_encoder.encoder.ffn_layers.1.conv_2.weight, %text_encoder.encoder.ffn_layers.1.conv_2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1/torch.nn.modules.conv.Conv1d::conv_2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.1/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.1/Mul_2"](%/text_encoder/encoder/ffn_layers.1/conv_2/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:295:0
  %/text_encoder/encoder/Add_3_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_3"](%/text_encoder/encoder/norm_layers_1.1/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.1/Mul_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:430:0
  %/text_encoder/encoder/norm_layers_2.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.1/Transpose"](%/text_encoder/encoder/Add_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_2.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.1/ReduceMean"](%/text_encoder/encoder/norm_layers_2.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_2.1/Sub"](%/text_encoder/encoder/norm_layers_2.1/Transpose_output_0, %/text_encoder/encoder/norm_layers_2.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_2.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_2.1/Pow"](%/text_encoder/encoder/norm_layers_2.1/Sub_output_0, %/text_encoder/encoder/norm_layers_2.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.1/ReduceMean_1"](%/text_encoder/encoder/norm_layers_2.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_2.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.1/Add"](%/text_encoder/encoder/norm_layers_2.1/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_2.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_2.1/Sqrt"](%/text_encoder/encoder/norm_layers_2.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_2.1/Div"](%/text_encoder/encoder/norm_layers_2.1/Sub_output_0, %/text_encoder/encoder/norm_layers_2.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_2.1/Mul"](%/text_encoder/encoder/norm_layers_2.1/Div_output_0, %text_encoder.encoder.norm_layers_2.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.1/Add_1"](%/text_encoder/encoder/norm_layers_2.1/Mul_output_0, %text_encoder.encoder.norm_layers_2.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.1/Transpose_1"](%/text_encoder/encoder/norm_layers_2.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/Mul_3_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/Mul_3"](%/text_encoder/encoder/norm_layers_2.1/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:419:0
  %/text_encoder/encoder/attn_layers.2/conv_q/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.2/conv_q/Conv"](%/text_encoder/encoder/Mul_3_output_0, %text_encoder.encoder.attn_layers.2.conv_q.weight, %text_encoder.encoder.attn_layers.2.conv_q.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2/torch.nn.modules.conv.Conv1d::conv_q # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.2/conv_k/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.2/conv_k/Conv"](%/text_encoder/encoder/Mul_3_output_0, %text_encoder.encoder.attn_layers.2.conv_k.weight, %text_encoder.encoder.attn_layers.2.conv_k.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2/torch.nn.modules.conv.Conv1d::conv_k # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.2/conv_v/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.2/conv_v/Conv"](%/text_encoder/encoder/Mul_3_output_0, %text_encoder.encoder.attn_layers.2.conv_v.weight, %text_encoder.encoder.attn_layers.2.conv_v.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2/torch.nn.modules.conv.Conv1d::conv_v # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.2/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape"](%/text_encoder/encoder/attn_layers.2/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather"](%/text_encoder/encoder/attn_layers.2/Shape_output_0, %/text_encoder/encoder/attn_layers.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_1"](%/text_encoder/encoder/attn_layers.2/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_1"](%/text_encoder/encoder/attn_layers.2/Shape_1_output_0, %/text_encoder/encoder/attn_layers.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_2"](%/text_encoder/encoder/attn_layers.2/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_2"](%/text_encoder/encoder/attn_layers.2/Shape_2_output_0, %/text_encoder/encoder/attn_layers.2/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_3"](%/text_encoder/encoder/attn_layers.2/conv_q/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.2/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_3"](%/text_encoder/encoder/attn_layers.2/Shape_3_output_0, %/text_encoder/encoder/attn_layers.2/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %onnx::Unsqueeze_2013 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze"](%/text_encoder/encoder/attn_layers.2/Gather_output_0, %onnx::Unsqueeze_2013), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2019 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_1"](%/text_encoder/encoder/attn_layers.2/Gather_3_output_0, %onnx::Unsqueeze_2019), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_output_0, %/text_encoder/encoder/attn_layers.2/Constant_4_output_0, %/text_encoder/encoder/attn_layers.2/Constant_5_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.2/Reshape_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape"](%/text_encoder/encoder/attn_layers.2/conv_q/Conv_output_0, %/text_encoder/encoder/attn_layers.2/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.2/Transpose_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose"](%/text_encoder/encoder/attn_layers.2/Reshape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %onnx::Unsqueeze_2024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_2"](%/text_encoder/encoder/attn_layers.2/Gather_output_0, %onnx::Unsqueeze_2024), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2030 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_3"](%/text_encoder/encoder/attn_layers.2/Gather_2_output_0, %onnx::Unsqueeze_2030), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_1"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_2_output_0, %/text_encoder/encoder/attn_layers.2/Constant_6_output_0, %/text_encoder/encoder/attn_layers.2/Constant_7_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %onnx::Unsqueeze_2033 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_4"](%/text_encoder/encoder/attn_layers.2/Gather_output_0, %onnx::Unsqueeze_2033), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2039 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_5"](%/text_encoder/encoder/attn_layers.2/Gather_2_output_0, %onnx::Unsqueeze_2039), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_2"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_4_output_0, %/text_encoder/encoder/attn_layers.2/Constant_8_output_0, %/text_encoder/encoder/attn_layers.2/Constant_9_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.2/Reshape_1_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_1"](%/text_encoder/encoder/attn_layers.2/conv_k/Conv_output_0, %/text_encoder/encoder/attn_layers.2/Concat_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %/text_encoder/encoder/attn_layers.2/Reshape_2_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_2"](%/text_encoder/encoder/attn_layers.2/conv_v/Conv_output_0, %/text_encoder/encoder/attn_layers.2/Concat_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.2/Transpose_1_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose_1"](%/text_encoder/encoder/attn_layers.2/Reshape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.2/MatMul_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.2/MatMul"](%/text_encoder/encoder/attn_layers.2/Transpose_output_0, %/text_encoder/encoder/attn_layers.2/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.2/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.2/Div_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.2/Div"](%/text_encoder/encoder/attn_layers.2/MatMul_output_0, %/text_encoder/encoder/attn_layers.2/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.2/Constant_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.2/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub"](%/text_encoder/encoder/attn_layers.2/Gather_2_output_0, %/text_encoder/encoder/attn_layers.2/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.2/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.2/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.2/Mul"](%/text_encoder/encoder/attn_layers.2/Gather_2_output_0, %/text_encoder/encoder/attn_layers.2/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.2/Constant_13_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.2/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub_1"](%/text_encoder/encoder/attn_layers.2/Mul_output_0, %/text_encoder/encoder/attn_layers.2/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.2/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2058 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_6"](%/text_encoder/encoder/attn_layers.2/Sub_output_0, %onnx::Unsqueeze_2058), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2060 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_7"](%/text_encoder/encoder/attn_layers.2/Sub_output_0, %onnx::Unsqueeze_2060), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_3"](%/text_encoder/encoder/attn_layers.2/Constant_14_output_0, %/text_encoder/encoder/attn_layers.2/Constant_15_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_6_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_7_output_0, %/text_encoder/encoder/attn_layers.2/Constant_16_output_0, %/text_encoder/encoder/attn_layers.2/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2071 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_8"](%/text_encoder/encoder/attn_layers.2/Sub_output_0, %onnx::Unsqueeze_2071), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2073 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_9"](%/text_encoder/encoder/attn_layers.2/Sub_output_0, %onnx::Unsqueeze_2073), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_4"](%/text_encoder/encoder/attn_layers.2/Constant_18_output_0, %/text_encoder/encoder/attn_layers.2/Constant_19_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_8_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_9_output_0, %/text_encoder/encoder/attn_layers.2/Constant_20_output_0, %/text_encoder/encoder/attn_layers.2/Constant_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2084 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_10"](%/text_encoder/encoder/attn_layers.2/Sub_output_0, %onnx::Unsqueeze_2084), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2086 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_11"](%/text_encoder/encoder/attn_layers.2/Sub_output_0, %onnx::Unsqueeze_2086), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_5"](%/text_encoder/encoder/attn_layers.2/Constant_22_output_0, %/text_encoder/encoder/attn_layers.2/Constant_23_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_10_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_11_output_0, %/text_encoder/encoder/attn_layers.2/Constant_24_output_0, %/text_encoder/encoder/attn_layers.2/Constant_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2097 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_12"](%/text_encoder/encoder/attn_layers.2/Sub_output_0, %onnx::Unsqueeze_2097), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2099 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_13"](%/text_encoder/encoder/attn_layers.2/Sub_output_0, %onnx::Unsqueeze_2099), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_6"](%/text_encoder/encoder/attn_layers.2/Constant_26_output_0, %/text_encoder/encoder/attn_layers.2/Constant_27_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_12_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_13_output_0, %/text_encoder/encoder/attn_layers.2/Constant_28_output_0, %/text_encoder/encoder/attn_layers.2/Constant_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_4"](%/text_encoder/encoder/attn_layers.2/Concat_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_4"](%/text_encoder/encoder/attn_layers.2/Shape_4_output_0, %/text_encoder/encoder/attn_layers.2/Constant_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub_2"](%/text_encoder/encoder/attn_layers.2/Constant_31_output_0, %/text_encoder/encoder/attn_layers.2/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast"](%/text_encoder/encoder/attn_layers.2/Concat_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/ConstantOfShape"](%/text_encoder/encoder/attn_layers.2/Sub_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Concat_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_7"](%/text_encoder/encoder/attn_layers.2/Cast_output_0, %/text_encoder/encoder/attn_layers.2/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_32_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.2/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_3"](%/text_encoder/encoder/attn_layers.2/Concat_7_output_0, %/text_encoder/encoder/attn_layers.2/Constant_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice"](%/text_encoder/encoder/attn_layers.2/Reshape_3_output_0, %/text_encoder/encoder/attn_layers.2/Constant_34_output_0, %/text_encoder/encoder/attn_layers.2/Constant_35_output_0, %/text_encoder/encoder/attn_layers.2/Constant_33_output_0, %/text_encoder/encoder/attn_layers.2/Constant_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Transpose_2_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose_2"](%/text_encoder/encoder/attn_layers.2/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_4"](%/text_encoder/encoder/attn_layers.2/Transpose_2_output_0, %/text_encoder/encoder/attn_layers.2/Constant_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_1"](%/text_encoder/encoder/attn_layers.2/Reshape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Pad_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.2/Pad"](%text_encoder.encoder.attn_layers.2.emb_rel_k, %/text_encoder/encoder/attn_layers.2/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_40"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_14"](%/text_encoder/encoder/attn_layers.2/Sub_1_output_0, %/text_encoder/encoder/attn_layers.2/Constant_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_41"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Slice_1_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_1"](%/text_encoder/encoder/attn_layers.2/Pad_output_0, %/text_encoder/encoder/attn_layers.2/Constant_39_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_14_output_0, %/text_encoder/encoder/attn_layers.2/Constant_38_output_0, %/text_encoder/encoder/attn_layers.2/Constant_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_42"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_15_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_15"](%/text_encoder/encoder/attn_layers.2/Slice_1_output_0, %/text_encoder/encoder/attn_layers.2/Constant_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.2/Transpose_3_output_0 : Float(1, *, *, *, strides=[19104, 19104, 1, 96], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose_3"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.2/MatMul_1_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.2/MatMul_1"](%/text_encoder/encoder/attn_layers.2/Transpose_output_0, %/text_encoder/encoder/attn_layers.2/Transpose_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.2/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_5"](%/text_encoder/encoder/attn_layers.2/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.2/Constant_43_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_43"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.2/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_5"](%/text_encoder/encoder/attn_layers.2/Shape_5_output_0, %/text_encoder/encoder/attn_layers.2/Constant_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.2/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_6"](%/text_encoder/encoder/attn_layers.2/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.2/Constant_44_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_44"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.2/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_6"](%/text_encoder/encoder/attn_layers.2/Shape_6_output_0, %/text_encoder/encoder/attn_layers.2/Constant_44_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.2/Shape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_7"](%/text_encoder/encoder/attn_layers.2/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.2/Constant_45_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_45"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.2/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_7"](%/text_encoder/encoder/attn_layers.2/Shape_7_output_0, %/text_encoder/encoder/attn_layers.2/Constant_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.2/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_46"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_47_output_0 : Long(8, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  0  0  0  0  0  0 [ CPULongType{8} ], onnx_name="/text_encoder/encoder/attn_layers.2/Constant_47"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/ConstantOfShape_1"](%/text_encoder/encoder/attn_layers.2/Constant_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Concat_8_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_8"](%/text_encoder/encoder/attn_layers.2/Constant_47_output_0, %/text_encoder/encoder/attn_layers.2/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_48_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.2/Constant_48"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_5_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_5"](%/text_encoder/encoder/attn_layers.2/Concat_8_output_0, %/text_encoder/encoder/attn_layers.2/Constant_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_49"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_50"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_51"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_52"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Slice_2_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_2"](%/text_encoder/encoder/attn_layers.2/Reshape_5_output_0, %/text_encoder/encoder/attn_layers.2/Constant_50_output_0, %/text_encoder/encoder/attn_layers.2/Constant_51_output_0, %/text_encoder/encoder/attn_layers.2/Constant_49_output_0, %/text_encoder/encoder/attn_layers.2/Constant_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Transpose_4_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose_4"](%/text_encoder/encoder/attn_layers.2/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_53"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_6"](%/text_encoder/encoder/attn_layers.2/Transpose_4_output_0, %/text_encoder/encoder/attn_layers.2/Constant_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_2"](%/text_encoder/encoder/attn_layers.2/Reshape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Pad_1_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.2/Pad_1"](%/text_encoder/encoder/attn_layers.2/MatMul_1_output_0, %/text_encoder/encoder/attn_layers.2/Cast_2_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_54_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_54"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.2/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.2/Mul_1"](%/text_encoder/encoder/attn_layers.2/Gather_7_output_0, %/text_encoder/encoder/attn_layers.2/Constant_54_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.2/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.2/Mul_2"](%/text_encoder/encoder/attn_layers.2/Mul_1_output_0, %/text_encoder/encoder/attn_layers.2/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %onnx::Unsqueeze_2175 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_16"](%/text_encoder/encoder/attn_layers.2/Gather_5_output_0, %onnx::Unsqueeze_2175), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2177 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_17"](%/text_encoder/encoder/attn_layers.2/Gather_6_output_0, %onnx::Unsqueeze_2177), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2179 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_18"](%/text_encoder/encoder/attn_layers.2/Mul_2_output_0, %onnx::Unsqueeze_2179), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_9"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_16_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_17_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.2/Reshape_7_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_7"](%/text_encoder/encoder/attn_layers.2/Pad_1_output_0, %/text_encoder/encoder/attn_layers.2/Concat_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.2/Constant_55_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_55"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.2/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub_3"](%/text_encoder/encoder/attn_layers.2/Gather_7_output_0, %/text_encoder/encoder/attn_layers.2/Constant_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.2/Constant_56_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_56"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_19"](%/text_encoder/encoder/attn_layers.2/Sub_3_output_0, %onnx::Unsqueeze_2187), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_57"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_58"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_59_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_59"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_60_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_60"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_10"](%/text_encoder/encoder/attn_layers.2/Constant_56_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_19_output_0, %/text_encoder/encoder/attn_layers.2/Constant_57_output_0, %/text_encoder/encoder/attn_layers.2/Constant_58_output_0, %/text_encoder/encoder/attn_layers.2/Constant_59_output_0, %/text_encoder/encoder/attn_layers.2/Constant_60_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_61_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_61"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2200 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_20"](%/text_encoder/encoder/attn_layers.2/Sub_3_output_0, %onnx::Unsqueeze_2200), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_62_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_62"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_63_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_63"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_64_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_64"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_65_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_65"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_11"](%/text_encoder/encoder/attn_layers.2/Constant_61_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_20_output_0, %/text_encoder/encoder/attn_layers.2/Constant_62_output_0, %/text_encoder/encoder/attn_layers.2/Constant_63_output_0, %/text_encoder/encoder/attn_layers.2/Constant_64_output_0, %/text_encoder/encoder/attn_layers.2/Constant_65_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_66_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_66"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Shape_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_8"](%/text_encoder/encoder/attn_layers.2/Concat_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Gather_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_8"](%/text_encoder/encoder/attn_layers.2/Shape_8_output_0, %/text_encoder/encoder/attn_layers.2/Constant_66_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_67_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_67"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Sub_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub_4"](%/text_encoder/encoder/attn_layers.2/Constant_67_output_0, %/text_encoder/encoder/attn_layers.2/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_3"](%/text_encoder/encoder/attn_layers.2/Concat_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/ConstantOfShape_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/ConstantOfShape_2"](%/text_encoder/encoder/attn_layers.2/Sub_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Concat_12_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_12"](%/text_encoder/encoder/attn_layers.2/Cast_3_output_0, %/text_encoder/encoder/attn_layers.2/ConstantOfShape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_68_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.2/Constant_68"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_8_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_8"](%/text_encoder/encoder/attn_layers.2/Concat_12_output_0, %/text_encoder/encoder/attn_layers.2/Constant_68_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_69_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_69"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_70"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_71_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_71"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_72"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Slice_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_3"](%/text_encoder/encoder/attn_layers.2/Reshape_8_output_0, %/text_encoder/encoder/attn_layers.2/Constant_70_output_0, %/text_encoder/encoder/attn_layers.2/Constant_71_output_0, %/text_encoder/encoder/attn_layers.2/Constant_69_output_0, %/text_encoder/encoder/attn_layers.2/Constant_72_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Transpose_5_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose_5"](%/text_encoder/encoder/attn_layers.2/Slice_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_73_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_73"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_9"](%/text_encoder/encoder/attn_layers.2/Transpose_5_output_0, %/text_encoder/encoder/attn_layers.2/Constant_73_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_4"](%/text_encoder/encoder/attn_layers.2/Reshape_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Pad_2_output_0 : Float(*, *, *, strides=[40198, 20099, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.2/Pad_2"](%/text_encoder/encoder/attn_layers.2/Reshape_7_output_0, %/text_encoder/encoder/attn_layers.2/Cast_4_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_74_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_74"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.2/Add"](%/text_encoder/encoder/attn_layers.2/Gather_7_output_0, %/text_encoder/encoder/attn_layers.2/Constant_74_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_75_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_75"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Sub_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub_5"](%/text_encoder/encoder/attn_layers.2/Mul_1_output_0, %/text_encoder/encoder/attn_layers.2/Constant_75_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %onnx::Unsqueeze_2237 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_21"](%/text_encoder/encoder/attn_layers.2/Gather_5_output_0, %onnx::Unsqueeze_2237), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2239 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_22"](%/text_encoder/encoder/attn_layers.2/Gather_6_output_0, %onnx::Unsqueeze_2239), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2241 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_23"](%/text_encoder/encoder/attn_layers.2/Add_output_0, %onnx::Unsqueeze_2241), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2243 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_24"](%/text_encoder/encoder/attn_layers.2/Sub_5_output_0, %onnx::Unsqueeze_2243), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_13"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_21_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_22_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_23_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Reshape_10_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_10"](%/text_encoder/encoder/attn_layers.2/Pad_2_output_0, %/text_encoder/encoder/attn_layers.2/Concat_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_76"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_77_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_77"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_78"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_25"](%/text_encoder/encoder/attn_layers.2/Gather_7_output_0, %/text_encoder/encoder/attn_layers.2/Constant_78_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_79_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_79"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Slice_4_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_4"](%/text_encoder/encoder/attn_layers.2/Reshape_10_output_0, %/text_encoder/encoder/attn_layers.2/Constant_77_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_25_output_0, %/text_encoder/encoder/attn_layers.2/Constant_76_output_0, %/text_encoder/encoder/attn_layers.2/Constant_79_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_80_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_80"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_81"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_26"](%/text_encoder/encoder/attn_layers.2/Sub_3_output_0, %/text_encoder/encoder/attn_layers.2/Constant_81_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_82_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_82"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_83_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_83"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Slice_5_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_5"](%/text_encoder/encoder/attn_layers.2/Slice_4_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_26_output_0, %/text_encoder/encoder/attn_layers.2/Constant_82_output_0, %/text_encoder/encoder/attn_layers.2/Constant_80_output_0, %/text_encoder/encoder/attn_layers.2/Constant_83_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.2/Constant_84_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_84"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.2/Div_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.2/Div_1"](%/text_encoder/encoder/attn_layers.2/Slice_5_output_0, %/text_encoder/encoder/attn_layers.2/Constant_84_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.2/Add_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.2/Add_1"](%/text_encoder/encoder/attn_layers.2/Div_output_0, %/text_encoder/encoder/attn_layers.2/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:139:0
  %/text_encoder/encoder/attn_layers.2/Cast_5_output_0 : Bool(*, 1, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_5"](%/text_encoder/encoder/attn_layers.0/Equal_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.2/Constant_85_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_85"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.2/Where_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/text_encoder/encoder/attn_layers.2/Where"](%/text_encoder/encoder/attn_layers.2/Cast_5_output_0, %/text_encoder/encoder/attn_layers.2/Constant_85_output_0, %/text_encoder/encoder/attn_layers.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.2/Softmax_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/text_encoder/encoder/attn_layers.2/Softmax"](%/text_encoder/encoder/attn_layers.2/Where_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/text_encoder/encoder/attn_layers.2/MatMul_2_output_0 : Float(*, *, *, 96, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.2/MatMul_2"](%/text_encoder/encoder/attn_layers.2/Softmax_output_0, %/text_encoder/encoder/attn_layers.2/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:156:0
  %/text_encoder/encoder/attn_layers.2/Shape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_9"](%/text_encoder/encoder/attn_layers.2/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.2/Constant_86_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_86"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.2/Gather_9_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_9"](%/text_encoder/encoder/attn_layers.2/Shape_9_output_0, %/text_encoder/encoder/attn_layers.2/Constant_86_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.2/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_10"](%/text_encoder/encoder/attn_layers.2/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.2/Constant_87_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_87"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.2/Gather_10_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_10"](%/text_encoder/encoder/attn_layers.2/Shape_10_output_0, %/text_encoder/encoder/attn_layers.2/Constant_87_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.2/Shape_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_11"](%/text_encoder/encoder/attn_layers.2/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.2/Constant_88_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_88"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.2/Gather_11_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_11"](%/text_encoder/encoder/attn_layers.2/Shape_11_output_0, %/text_encoder/encoder/attn_layers.2/Constant_88_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.2/Constant_89_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_89"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.2/Sub_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub_6"](%/text_encoder/encoder/attn_layers.2/Gather_11_output_0, %/text_encoder/encoder/attn_layers.2/Constant_89_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.2/Constant_90_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_90"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2286 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_27"](%/text_encoder/encoder/attn_layers.2/Sub_6_output_0, %onnx::Unsqueeze_2286), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_91_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_91"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_92_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_92"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_93_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_93"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_94_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_94"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_95_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_95"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_96_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_96"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_14_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_14"](%/text_encoder/encoder/attn_layers.2/Constant_90_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_27_output_0, %/text_encoder/encoder/attn_layers.2/Constant_91_output_0, %/text_encoder/encoder/attn_layers.2/Constant_92_output_0, %/text_encoder/encoder/attn_layers.2/Constant_93_output_0, %/text_encoder/encoder/attn_layers.2/Constant_94_output_0, %/text_encoder/encoder/attn_layers.2/Constant_95_output_0, %/text_encoder/encoder/attn_layers.2/Constant_96_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_97_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_97"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2303 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_28"](%/text_encoder/encoder/attn_layers.2/Sub_6_output_0, %onnx::Unsqueeze_2303), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_98_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_98"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_99_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_99"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_100_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_100"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_101_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_101"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_102_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_102"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_103_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_103"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_15_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_15"](%/text_encoder/encoder/attn_layers.2/Constant_97_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_28_output_0, %/text_encoder/encoder/attn_layers.2/Constant_98_output_0, %/text_encoder/encoder/attn_layers.2/Constant_99_output_0, %/text_encoder/encoder/attn_layers.2/Constant_100_output_0, %/text_encoder/encoder/attn_layers.2/Constant_101_output_0, %/text_encoder/encoder/attn_layers.2/Constant_102_output_0, %/text_encoder/encoder/attn_layers.2/Constant_103_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_104_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_104"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Shape_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_12"](%/text_encoder/encoder/attn_layers.2/Concat_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Gather_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_12"](%/text_encoder/encoder/attn_layers.2/Shape_12_output_0, %/text_encoder/encoder/attn_layers.2/Constant_104_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_105_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_105"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Sub_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub_7"](%/text_encoder/encoder/attn_layers.2/Constant_105_output_0, %/text_encoder/encoder/attn_layers.2/Gather_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_6"](%/text_encoder/encoder/attn_layers.2/Concat_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/ConstantOfShape_3_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/ConstantOfShape_3"](%/text_encoder/encoder/attn_layers.2/Sub_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Concat_16_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_16"](%/text_encoder/encoder/attn_layers.2/Cast_6_output_0, %/text_encoder/encoder/attn_layers.2/ConstantOfShape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_106_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.2/Constant_106"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_11_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_11"](%/text_encoder/encoder/attn_layers.2/Concat_16_output_0, %/text_encoder/encoder/attn_layers.2/Constant_106_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_107_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_107"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_108"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_109_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_109"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_110"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Slice_6_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_6"](%/text_encoder/encoder/attn_layers.2/Reshape_11_output_0, %/text_encoder/encoder/attn_layers.2/Constant_108_output_0, %/text_encoder/encoder/attn_layers.2/Constant_109_output_0, %/text_encoder/encoder/attn_layers.2/Constant_107_output_0, %/text_encoder/encoder/attn_layers.2/Constant_110_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Transpose_6_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose_6"](%/text_encoder/encoder/attn_layers.2/Slice_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_111_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_111"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_12_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_12"](%/text_encoder/encoder/attn_layers.2/Transpose_6_output_0, %/text_encoder/encoder/attn_layers.2/Constant_111_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_7_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_7"](%/text_encoder/encoder/attn_layers.2/Reshape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Pad_3_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.2/Pad_3"](%/text_encoder/encoder/attn_layers.2/Softmax_output_0, %/text_encoder/encoder/attn_layers.2/Cast_7_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_112_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_112"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.2/Pow_output_0 : Long(requires_grad=0, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/attn_layers.2/Pow"](%/text_encoder/encoder/attn_layers.2/Gather_11_output_0, %/text_encoder/encoder/attn_layers.2/Constant_112_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.2/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.2/Mul_3"](%/text_encoder/encoder/attn_layers.2/Gather_11_output_0, %/text_encoder/encoder/attn_layers.2/Sub_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.2/Add_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.2/Add_2"](%/text_encoder/encoder/attn_layers.2/Pow_output_0, %/text_encoder/encoder/attn_layers.2/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_2344 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_29"](%/text_encoder/encoder/attn_layers.2/Gather_9_output_0, %onnx::Unsqueeze_2344), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2346 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_30"](%/text_encoder/encoder/attn_layers.2/Gather_10_output_0, %onnx::Unsqueeze_2346), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2348 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_31"](%/text_encoder/encoder/attn_layers.2/Add_2_output_0, %onnx::Unsqueeze_2348), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_17_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_17"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_29_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_30_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.2/Reshape_13_output_0 : Float(*, *, *, strides=[39800, 19900, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_13"](%/text_encoder/encoder/attn_layers.2/Pad_3_output_0, %/text_encoder/encoder/attn_layers.2/Concat_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_2352 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_32"](%/text_encoder/encoder/attn_layers.2/Gather_11_output_0, %onnx::Unsqueeze_2352), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_113_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_113"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_114_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_114"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_115_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_115"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_116_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_116"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_117_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_117"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_18"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_32_output_0, %/text_encoder/encoder/attn_layers.2/Constant_113_output_0, %/text_encoder/encoder/attn_layers.2/Constant_114_output_0, %/text_encoder/encoder/attn_layers.2/Constant_115_output_0, %/text_encoder/encoder/attn_layers.2/Constant_116_output_0, %/text_encoder/encoder/attn_layers.2/Constant_117_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %onnx::Unsqueeze_2365 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_33"](%/text_encoder/encoder/attn_layers.2/Gather_11_output_0, %onnx::Unsqueeze_2365), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_118_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_118"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_119_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_119"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_120_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_120"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_121_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_121"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Constant_122_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_122"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_19_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_19"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_33_output_0, %/text_encoder/encoder/attn_layers.2/Constant_118_output_0, %/text_encoder/encoder/attn_layers.2/Constant_119_output_0, %/text_encoder/encoder/attn_layers.2/Constant_120_output_0, %/text_encoder/encoder/attn_layers.2/Constant_121_output_0, %/text_encoder/encoder/attn_layers.2/Constant_122_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_123_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_123"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Shape_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_13"](%/text_encoder/encoder/attn_layers.2/Concat_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Gather_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_13"](%/text_encoder/encoder/attn_layers.2/Shape_13_output_0, %/text_encoder/encoder/attn_layers.2/Constant_123_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_124_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_124"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Sub_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub_8"](%/text_encoder/encoder/attn_layers.2/Constant_124_output_0, %/text_encoder/encoder/attn_layers.2/Gather_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_8"](%/text_encoder/encoder/attn_layers.2/Concat_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/ConstantOfShape_4_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/ConstantOfShape_4"](%/text_encoder/encoder/attn_layers.2/Sub_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Concat_20_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_20"](%/text_encoder/encoder/attn_layers.2/Cast_8_output_0, %/text_encoder/encoder/attn_layers.2/ConstantOfShape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_125_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.2/Constant_125"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_14_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_14"](%/text_encoder/encoder/attn_layers.2/Concat_20_output_0, %/text_encoder/encoder/attn_layers.2/Constant_125_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_126_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_126"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_127_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_127"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_128_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_128"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_129_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_129"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Slice_7_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_7"](%/text_encoder/encoder/attn_layers.2/Reshape_14_output_0, %/text_encoder/encoder/attn_layers.2/Constant_127_output_0, %/text_encoder/encoder/attn_layers.2/Constant_128_output_0, %/text_encoder/encoder/attn_layers.2/Constant_126_output_0, %/text_encoder/encoder/attn_layers.2/Constant_129_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Transpose_7_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose_7"](%/text_encoder/encoder/attn_layers.2/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_130_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_130"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_15_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_15"](%/text_encoder/encoder/attn_layers.2/Transpose_7_output_0, %/text_encoder/encoder/attn_layers.2/Constant_130_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_9"](%/text_encoder/encoder/attn_layers.2/Reshape_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Pad_4_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.2/Pad_4"](%/text_encoder/encoder/attn_layers.2/Reshape_13_output_0, %/text_encoder/encoder/attn_layers.2/Cast_9_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_131_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_131"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.2/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.2/Mul_4"](%/text_encoder/encoder/attn_layers.2/Gather_11_output_0, %/text_encoder/encoder/attn_layers.2/Constant_131_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %onnx::Unsqueeze_2402 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_34"](%/text_encoder/encoder/attn_layers.2/Gather_9_output_0, %onnx::Unsqueeze_2402), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2404 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_35"](%/text_encoder/encoder/attn_layers.2/Gather_10_output_0, %onnx::Unsqueeze_2404), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2406 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_36"](%/text_encoder/encoder/attn_layers.2/Gather_11_output_0, %onnx::Unsqueeze_2406), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2408 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_37"](%/text_encoder/encoder/attn_layers.2/Mul_4_output_0, %onnx::Unsqueeze_2408), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_21_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_21"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_34_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_35_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_36_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.2/Reshape_16_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_16"](%/text_encoder/encoder/attn_layers.2/Pad_4_output_0, %/text_encoder/encoder/attn_layers.2/Concat_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.2/Constant_132_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_132"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.2/Constant_133_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_133"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.2/Constant_134_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_134"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.2/Constant_135_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_135"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.2/Slice_8_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_8"](%/text_encoder/encoder/attn_layers.2/Reshape_16_output_0, %/text_encoder/encoder/attn_layers.2/Constant_133_output_0, %/text_encoder/encoder/attn_layers.2/Constant_134_output_0, %/text_encoder/encoder/attn_layers.2/Constant_132_output_0, %/text_encoder/encoder/attn_layers.2/Constant_135_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.2/Constant_136_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_136"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.2/Shape_14"](%/text_encoder/encoder/attn_layers.2/Concat_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Gather_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Gather_14"](%/text_encoder/encoder/attn_layers.2/Shape_14_output_0, %/text_encoder/encoder/attn_layers.2/Constant_136_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_137_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_137"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Sub_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.2/Sub_9"](%/text_encoder/encoder/attn_layers.2/Constant_137_output_0, %/text_encoder/encoder/attn_layers.2/Gather_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_10"](%/text_encoder/encoder/attn_layers.2/Concat_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/ConstantOfShape_5_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/ConstantOfShape_5"](%/text_encoder/encoder/attn_layers.2/Sub_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Concat_22_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_22"](%/text_encoder/encoder/attn_layers.2/Cast_10_output_0, %/text_encoder/encoder/attn_layers.2/ConstantOfShape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_138_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.2/Constant_138"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_17_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_17"](%/text_encoder/encoder/attn_layers.2/Concat_22_output_0, %/text_encoder/encoder/attn_layers.2/Constant_138_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_139_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_139"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_140_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_140"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_141"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_142_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_142"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Slice_9_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_9"](%/text_encoder/encoder/attn_layers.2/Reshape_17_output_0, %/text_encoder/encoder/attn_layers.2/Constant_140_output_0, %/text_encoder/encoder/attn_layers.2/Constant_141_output_0, %/text_encoder/encoder/attn_layers.2/Constant_139_output_0, %/text_encoder/encoder/attn_layers.2/Constant_142_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Transpose_8_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose_8"](%/text_encoder/encoder/attn_layers.2/Slice_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_143"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Reshape_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_18"](%/text_encoder/encoder/attn_layers.2/Transpose_8_output_0, %/text_encoder/encoder/attn_layers.2/Constant_143_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Cast_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.2/Cast_11"](%/text_encoder/encoder/attn_layers.2/Reshape_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Pad_5_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.2/Pad_5"](%text_encoder.encoder.attn_layers.2.emb_rel_v, %/text_encoder/encoder/attn_layers.2/Cast_11_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.2/Constant_144_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_144"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Constant_145_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_145"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Constant_146_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_146"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_38"](%/text_encoder/encoder/attn_layers.2/Sub_1_output_0, %/text_encoder/encoder/attn_layers.2/Constant_146_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Constant_147_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_147"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Slice_10_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.2/Slice_10"](%/text_encoder/encoder/attn_layers.2/Pad_5_output_0, %/text_encoder/encoder/attn_layers.2/Constant_145_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_38_output_0, %/text_encoder/encoder/attn_layers.2/Constant_144_output_0, %/text_encoder/encoder/attn_layers.2/Constant_147_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.2/Constant_148_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.2/Constant_148"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_39_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_39"](%/text_encoder/encoder/attn_layers.2/Slice_10_output_0, %/text_encoder/encoder/attn_layers.2/Constant_148_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.2/MatMul_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.2/MatMul_3"](%/text_encoder/encoder/attn_layers.2/Slice_8_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.2/Add_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.2/Add_3"](%/text_encoder/encoder/attn_layers.2/MatMul_2_output_0, %/text_encoder/encoder/attn_layers.2/MatMul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:161:0
  %/text_encoder/encoder/attn_layers.2/Transpose_9_output_0 : Float(*, *, *, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.2/Transpose_9"](%/text_encoder/encoder/attn_layers.2/Add_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %onnx::Unsqueeze_2457 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_40"](%/text_encoder/encoder/attn_layers.2/Gather_output_0, %onnx::Unsqueeze_2457), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_41"](%/text_encoder/encoder/attn_layers.2/Gather_1_output_0, %onnx::Unsqueeze_2459), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %onnx::Unsqueeze_2461 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.2/Unsqueeze_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.2/Unsqueeze_42"](%/text_encoder/encoder/attn_layers.2/Gather_3_output_0, %onnx::Unsqueeze_2461), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2
  %/text_encoder/encoder/attn_layers.2/Concat_23_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.2/Concat_23"](%/text_encoder/encoder/attn_layers.2/Unsqueeze_40_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_41_output_0, %/text_encoder/encoder/attn_layers.2/Unsqueeze_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.2/Reshape_19_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.2/Reshape_19"](%/text_encoder/encoder/attn_layers.2/Transpose_9_output_0, %/text_encoder/encoder/attn_layers.2/Concat_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.2/conv_o/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.2/conv_o/Conv"](%/text_encoder/encoder/attn_layers.2/Reshape_19_output_0, %text_encoder.encoder.attn_layers.2.conv_o.weight, %text_encoder.encoder.attn_layers.2.conv_o.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.2/torch.nn.modules.conv.Conv1d::conv_o # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/Add_4_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_4"](%/text_encoder/encoder/Mul_3_output_0, %/text_encoder/encoder/attn_layers.2/conv_o/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:422:0
  %/text_encoder/encoder/norm_layers_1.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.2/Transpose"](%/text_encoder/encoder/Add_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_1.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.2/ReduceMean"](%/text_encoder/encoder/norm_layers_1.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_1.2/Sub"](%/text_encoder/encoder/norm_layers_1.2/Transpose_output_0, %/text_encoder/encoder/norm_layers_1.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_1.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_1.2/Pow"](%/text_encoder/encoder/norm_layers_1.2/Sub_output_0, %/text_encoder/encoder/norm_layers_1.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.2/ReduceMean_1"](%/text_encoder/encoder/norm_layers_1.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_1.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.2/Add"](%/text_encoder/encoder/norm_layers_1.2/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_1.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_1.2/Sqrt"](%/text_encoder/encoder/norm_layers_1.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_1.2/Div"](%/text_encoder/encoder/norm_layers_1.2/Sub_output_0, %/text_encoder/encoder/norm_layers_1.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_1.2/Mul"](%/text_encoder/encoder/norm_layers_1.2/Div_output_0, %text_encoder.encoder.norm_layers_1.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.2/Add_1"](%/text_encoder/encoder/norm_layers_1.2/Mul_output_0, %text_encoder.encoder.norm_layers_1.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.2/Transpose_1"](%/text_encoder/encoder/norm_layers_1.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/ffn_layers.2/Mul_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.2/Mul"](%/text_encoder/encoder/norm_layers_1.2/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:291:0
  %/text_encoder/encoder/ffn_layers.2/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_1_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.2/ConstantOfShape"](%/text_encoder/encoder/ffn_layers.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.2/Concat"](%/text_encoder/encoder/ffn_layers.2/Constant_1_output_0, %/text_encoder/encoder/ffn_layers.2/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Reshape_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.2/Reshape"](%/text_encoder/encoder/ffn_layers.2/Concat_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.2/Slice"](%/text_encoder/encoder/ffn_layers.2/Reshape_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_4_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_5_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_3_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Transpose_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.2/Transpose"](%/text_encoder/encoder/ffn_layers.2/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Reshape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.2/Reshape_1"](%/text_encoder/encoder/ffn_layers.2/Transpose_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.2/Cast"](%/text_encoder/encoder/ffn_layers.2/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Pad_output_0 : Float(*, *, *, strides=[19584, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.2/Pad"](%/text_encoder/encoder/ffn_layers.2/Mul_output_0, %/text_encoder/encoder/ffn_layers.2/Cast_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/conv_1/Conv_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.2/conv_1/Conv"](%/text_encoder/encoder/ffn_layers.2/Pad_output_0, %text_encoder.encoder.ffn_layers.2.conv_1.weight, %text_encoder.encoder.ffn_layers.2.conv_1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2/torch.nn.modules.conv.Conv1d::conv_1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.2/Relu_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name="/text_encoder/encoder/ffn_layers.2/Relu"](%/text_encoder/encoder/ffn_layers.2/conv_1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:292:0
  %/text_encoder/encoder/ffn_layers.2/Mul_1_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.2/Mul_1"](%/text_encoder/encoder/ffn_layers.2/Relu_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:294:0
  %/text_encoder/encoder/ffn_layers.2/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_9_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.2/ConstantOfShape_1"](%/text_encoder/encoder/ffn_layers.2/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.2/Concat_1"](%/text_encoder/encoder/ffn_layers.2/Constant_9_output_0, %/text_encoder/encoder/ffn_layers.2/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Reshape_2_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.2/Reshape_2"](%/text_encoder/encoder/ffn_layers.2/Concat_1_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Slice_1_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.2/Slice_1"](%/text_encoder/encoder/ffn_layers.2/Reshape_2_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_12_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_13_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_11_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Transpose_1_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.2/Transpose_1"](%/text_encoder/encoder/ffn_layers.2/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.2/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Reshape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.2/Reshape_3"](%/text_encoder/encoder/ffn_layers.2/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.2/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.2/Cast_1"](%/text_encoder/encoder/ffn_layers.2/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/Pad_1_output_0 : Float(*, *, *, strides=[78336, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.2/Pad_1"](%/text_encoder/encoder/ffn_layers.2/Mul_1_output_0, %/text_encoder/encoder/ffn_layers.2/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.2/conv_2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.2/conv_2/Conv"](%/text_encoder/encoder/ffn_layers.2/Pad_1_output_0, %text_encoder.encoder.ffn_layers.2.conv_2.weight, %text_encoder.encoder.ffn_layers.2.conv_2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2/torch.nn.modules.conv.Conv1d::conv_2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.2/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.2/Mul_2"](%/text_encoder/encoder/ffn_layers.2/conv_2/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:295:0
  %/text_encoder/encoder/Add_5_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_5"](%/text_encoder/encoder/norm_layers_1.2/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.2/Mul_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:430:0
  %/text_encoder/encoder/norm_layers_2.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.2/Transpose"](%/text_encoder/encoder/Add_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_2.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.2/ReduceMean"](%/text_encoder/encoder/norm_layers_2.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_2.2/Sub"](%/text_encoder/encoder/norm_layers_2.2/Transpose_output_0, %/text_encoder/encoder/norm_layers_2.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_2.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_2.2/Pow"](%/text_encoder/encoder/norm_layers_2.2/Sub_output_0, %/text_encoder/encoder/norm_layers_2.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.2/ReduceMean_1"](%/text_encoder/encoder/norm_layers_2.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_2.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.2/Add"](%/text_encoder/encoder/norm_layers_2.2/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_2.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_2.2/Sqrt"](%/text_encoder/encoder/norm_layers_2.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_2.2/Div"](%/text_encoder/encoder/norm_layers_2.2/Sub_output_0, %/text_encoder/encoder/norm_layers_2.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_2.2/Mul"](%/text_encoder/encoder/norm_layers_2.2/Div_output_0, %text_encoder.encoder.norm_layers_2.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.2/Add_1"](%/text_encoder/encoder/norm_layers_2.2/Mul_output_0, %text_encoder.encoder.norm_layers_2.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.2/Transpose_1"](%/text_encoder/encoder/norm_layers_2.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/Mul_4_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/Mul_4"](%/text_encoder/encoder/norm_layers_2.2/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:419:0
  %/text_encoder/encoder/attn_layers.3/conv_q/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.3/conv_q/Conv"](%/text_encoder/encoder/Mul_4_output_0, %text_encoder.encoder.attn_layers.3.conv_q.weight, %text_encoder.encoder.attn_layers.3.conv_q.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3/torch.nn.modules.conv.Conv1d::conv_q # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.3/conv_k/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.3/conv_k/Conv"](%/text_encoder/encoder/Mul_4_output_0, %text_encoder.encoder.attn_layers.3.conv_k.weight, %text_encoder.encoder.attn_layers.3.conv_k.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3/torch.nn.modules.conv.Conv1d::conv_k # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.3/conv_v/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.3/conv_v/Conv"](%/text_encoder/encoder/Mul_4_output_0, %text_encoder.encoder.attn_layers.3.conv_v.weight, %text_encoder.encoder.attn_layers.3.conv_v.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3/torch.nn.modules.conv.Conv1d::conv_v # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.3/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape"](%/text_encoder/encoder/attn_layers.3/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather"](%/text_encoder/encoder/attn_layers.3/Shape_output_0, %/text_encoder/encoder/attn_layers.3/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_1"](%/text_encoder/encoder/attn_layers.3/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_1"](%/text_encoder/encoder/attn_layers.3/Shape_1_output_0, %/text_encoder/encoder/attn_layers.3/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_2"](%/text_encoder/encoder/attn_layers.3/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_2"](%/text_encoder/encoder/attn_layers.3/Shape_2_output_0, %/text_encoder/encoder/attn_layers.3/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_3"](%/text_encoder/encoder/attn_layers.3/conv_q/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.3/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_3"](%/text_encoder/encoder/attn_layers.3/Shape_3_output_0, %/text_encoder/encoder/attn_layers.3/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %onnx::Unsqueeze_2560 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze"](%/text_encoder/encoder/attn_layers.3/Gather_output_0, %onnx::Unsqueeze_2560), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2566 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_1"](%/text_encoder/encoder/attn_layers.3/Gather_3_output_0, %onnx::Unsqueeze_2566), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_output_0, %/text_encoder/encoder/attn_layers.3/Constant_4_output_0, %/text_encoder/encoder/attn_layers.3/Constant_5_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.3/Reshape_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape"](%/text_encoder/encoder/attn_layers.3/conv_q/Conv_output_0, %/text_encoder/encoder/attn_layers.3/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.3/Transpose_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose"](%/text_encoder/encoder/attn_layers.3/Reshape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %onnx::Unsqueeze_2571 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_2"](%/text_encoder/encoder/attn_layers.3/Gather_output_0, %onnx::Unsqueeze_2571), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2577 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_3"](%/text_encoder/encoder/attn_layers.3/Gather_2_output_0, %onnx::Unsqueeze_2577), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_1"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_2_output_0, %/text_encoder/encoder/attn_layers.3/Constant_6_output_0, %/text_encoder/encoder/attn_layers.3/Constant_7_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %onnx::Unsqueeze_2580 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_4"](%/text_encoder/encoder/attn_layers.3/Gather_output_0, %onnx::Unsqueeze_2580), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2586 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_5"](%/text_encoder/encoder/attn_layers.3/Gather_2_output_0, %onnx::Unsqueeze_2586), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_2"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_4_output_0, %/text_encoder/encoder/attn_layers.3/Constant_8_output_0, %/text_encoder/encoder/attn_layers.3/Constant_9_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.3/Reshape_1_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_1"](%/text_encoder/encoder/attn_layers.3/conv_k/Conv_output_0, %/text_encoder/encoder/attn_layers.3/Concat_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %/text_encoder/encoder/attn_layers.3/Reshape_2_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_2"](%/text_encoder/encoder/attn_layers.3/conv_v/Conv_output_0, %/text_encoder/encoder/attn_layers.3/Concat_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.3/Transpose_1_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose_1"](%/text_encoder/encoder/attn_layers.3/Reshape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.3/MatMul_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.3/MatMul"](%/text_encoder/encoder/attn_layers.3/Transpose_output_0, %/text_encoder/encoder/attn_layers.3/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.3/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.3/Div_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.3/Div"](%/text_encoder/encoder/attn_layers.3/MatMul_output_0, %/text_encoder/encoder/attn_layers.3/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.3/Constant_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.3/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub"](%/text_encoder/encoder/attn_layers.3/Gather_2_output_0, %/text_encoder/encoder/attn_layers.3/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.3/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.3/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.3/Mul"](%/text_encoder/encoder/attn_layers.3/Gather_2_output_0, %/text_encoder/encoder/attn_layers.3/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.3/Constant_13_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.3/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub_1"](%/text_encoder/encoder/attn_layers.3/Mul_output_0, %/text_encoder/encoder/attn_layers.3/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.3/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2605 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_6"](%/text_encoder/encoder/attn_layers.3/Sub_output_0, %onnx::Unsqueeze_2605), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2607 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_7"](%/text_encoder/encoder/attn_layers.3/Sub_output_0, %onnx::Unsqueeze_2607), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_3"](%/text_encoder/encoder/attn_layers.3/Constant_14_output_0, %/text_encoder/encoder/attn_layers.3/Constant_15_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_6_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_7_output_0, %/text_encoder/encoder/attn_layers.3/Constant_16_output_0, %/text_encoder/encoder/attn_layers.3/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2618 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_8"](%/text_encoder/encoder/attn_layers.3/Sub_output_0, %onnx::Unsqueeze_2618), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2620 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_9"](%/text_encoder/encoder/attn_layers.3/Sub_output_0, %onnx::Unsqueeze_2620), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_4"](%/text_encoder/encoder/attn_layers.3/Constant_18_output_0, %/text_encoder/encoder/attn_layers.3/Constant_19_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_8_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_9_output_0, %/text_encoder/encoder/attn_layers.3/Constant_20_output_0, %/text_encoder/encoder/attn_layers.3/Constant_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_10"](%/text_encoder/encoder/attn_layers.3/Sub_output_0, %onnx::Unsqueeze_2631), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2633 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_11"](%/text_encoder/encoder/attn_layers.3/Sub_output_0, %onnx::Unsqueeze_2633), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_5"](%/text_encoder/encoder/attn_layers.3/Constant_22_output_0, %/text_encoder/encoder/attn_layers.3/Constant_23_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_10_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_11_output_0, %/text_encoder/encoder/attn_layers.3/Constant_24_output_0, %/text_encoder/encoder/attn_layers.3/Constant_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2644 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_12"](%/text_encoder/encoder/attn_layers.3/Sub_output_0, %onnx::Unsqueeze_2644), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2646 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_13"](%/text_encoder/encoder/attn_layers.3/Sub_output_0, %onnx::Unsqueeze_2646), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_6"](%/text_encoder/encoder/attn_layers.3/Constant_26_output_0, %/text_encoder/encoder/attn_layers.3/Constant_27_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_12_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_13_output_0, %/text_encoder/encoder/attn_layers.3/Constant_28_output_0, %/text_encoder/encoder/attn_layers.3/Constant_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_4"](%/text_encoder/encoder/attn_layers.3/Concat_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_4"](%/text_encoder/encoder/attn_layers.3/Shape_4_output_0, %/text_encoder/encoder/attn_layers.3/Constant_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub_2"](%/text_encoder/encoder/attn_layers.3/Constant_31_output_0, %/text_encoder/encoder/attn_layers.3/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast"](%/text_encoder/encoder/attn_layers.3/Concat_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/ConstantOfShape"](%/text_encoder/encoder/attn_layers.3/Sub_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Concat_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_7"](%/text_encoder/encoder/attn_layers.3/Cast_output_0, %/text_encoder/encoder/attn_layers.3/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_32_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.3/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_3"](%/text_encoder/encoder/attn_layers.3/Concat_7_output_0, %/text_encoder/encoder/attn_layers.3/Constant_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice"](%/text_encoder/encoder/attn_layers.3/Reshape_3_output_0, %/text_encoder/encoder/attn_layers.3/Constant_34_output_0, %/text_encoder/encoder/attn_layers.3/Constant_35_output_0, %/text_encoder/encoder/attn_layers.3/Constant_33_output_0, %/text_encoder/encoder/attn_layers.3/Constant_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Transpose_2_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose_2"](%/text_encoder/encoder/attn_layers.3/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_4"](%/text_encoder/encoder/attn_layers.3/Transpose_2_output_0, %/text_encoder/encoder/attn_layers.3/Constant_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_1"](%/text_encoder/encoder/attn_layers.3/Reshape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Pad_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.3/Pad"](%text_encoder.encoder.attn_layers.3.emb_rel_k, %/text_encoder/encoder/attn_layers.3/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_40"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_14"](%/text_encoder/encoder/attn_layers.3/Sub_1_output_0, %/text_encoder/encoder/attn_layers.3/Constant_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_41"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Slice_1_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_1"](%/text_encoder/encoder/attn_layers.3/Pad_output_0, %/text_encoder/encoder/attn_layers.3/Constant_39_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_14_output_0, %/text_encoder/encoder/attn_layers.3/Constant_38_output_0, %/text_encoder/encoder/attn_layers.3/Constant_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_42"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_15_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_15"](%/text_encoder/encoder/attn_layers.3/Slice_1_output_0, %/text_encoder/encoder/attn_layers.3/Constant_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.3/Transpose_3_output_0 : Float(1, *, *, *, strides=[19104, 19104, 1, 96], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose_3"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.3/MatMul_1_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.3/MatMul_1"](%/text_encoder/encoder/attn_layers.3/Transpose_output_0, %/text_encoder/encoder/attn_layers.3/Transpose_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.3/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_5"](%/text_encoder/encoder/attn_layers.3/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.3/Constant_43_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_43"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.3/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_5"](%/text_encoder/encoder/attn_layers.3/Shape_5_output_0, %/text_encoder/encoder/attn_layers.3/Constant_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.3/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_6"](%/text_encoder/encoder/attn_layers.3/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.3/Constant_44_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_44"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.3/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_6"](%/text_encoder/encoder/attn_layers.3/Shape_6_output_0, %/text_encoder/encoder/attn_layers.3/Constant_44_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.3/Shape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_7"](%/text_encoder/encoder/attn_layers.3/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.3/Constant_45_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_45"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.3/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_7"](%/text_encoder/encoder/attn_layers.3/Shape_7_output_0, %/text_encoder/encoder/attn_layers.3/Constant_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.3/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_46"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_47_output_0 : Long(8, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  0  0  0  0  0  0 [ CPULongType{8} ], onnx_name="/text_encoder/encoder/attn_layers.3/Constant_47"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/ConstantOfShape_1"](%/text_encoder/encoder/attn_layers.3/Constant_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Concat_8_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_8"](%/text_encoder/encoder/attn_layers.3/Constant_47_output_0, %/text_encoder/encoder/attn_layers.3/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_48_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.3/Constant_48"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_5_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_5"](%/text_encoder/encoder/attn_layers.3/Concat_8_output_0, %/text_encoder/encoder/attn_layers.3/Constant_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_49"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_50"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_51"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_52"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Slice_2_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_2"](%/text_encoder/encoder/attn_layers.3/Reshape_5_output_0, %/text_encoder/encoder/attn_layers.3/Constant_50_output_0, %/text_encoder/encoder/attn_layers.3/Constant_51_output_0, %/text_encoder/encoder/attn_layers.3/Constant_49_output_0, %/text_encoder/encoder/attn_layers.3/Constant_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Transpose_4_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose_4"](%/text_encoder/encoder/attn_layers.3/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_53"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_6"](%/text_encoder/encoder/attn_layers.3/Transpose_4_output_0, %/text_encoder/encoder/attn_layers.3/Constant_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_2"](%/text_encoder/encoder/attn_layers.3/Reshape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Pad_1_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.3/Pad_1"](%/text_encoder/encoder/attn_layers.3/MatMul_1_output_0, %/text_encoder/encoder/attn_layers.3/Cast_2_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_54_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_54"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.3/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.3/Mul_1"](%/text_encoder/encoder/attn_layers.3/Gather_7_output_0, %/text_encoder/encoder/attn_layers.3/Constant_54_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.3/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.3/Mul_2"](%/text_encoder/encoder/attn_layers.3/Mul_1_output_0, %/text_encoder/encoder/attn_layers.3/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %onnx::Unsqueeze_2722 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_16"](%/text_encoder/encoder/attn_layers.3/Gather_5_output_0, %onnx::Unsqueeze_2722), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2724 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_17"](%/text_encoder/encoder/attn_layers.3/Gather_6_output_0, %onnx::Unsqueeze_2724), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2726 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_18"](%/text_encoder/encoder/attn_layers.3/Mul_2_output_0, %onnx::Unsqueeze_2726), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_9"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_16_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_17_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.3/Reshape_7_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_7"](%/text_encoder/encoder/attn_layers.3/Pad_1_output_0, %/text_encoder/encoder/attn_layers.3/Concat_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.3/Constant_55_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_55"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.3/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub_3"](%/text_encoder/encoder/attn_layers.3/Gather_7_output_0, %/text_encoder/encoder/attn_layers.3/Constant_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.3/Constant_56_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_56"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2734 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_19"](%/text_encoder/encoder/attn_layers.3/Sub_3_output_0, %onnx::Unsqueeze_2734), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_57"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_58"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_59_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_59"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_60_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_60"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_10"](%/text_encoder/encoder/attn_layers.3/Constant_56_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_19_output_0, %/text_encoder/encoder/attn_layers.3/Constant_57_output_0, %/text_encoder/encoder/attn_layers.3/Constant_58_output_0, %/text_encoder/encoder/attn_layers.3/Constant_59_output_0, %/text_encoder/encoder/attn_layers.3/Constant_60_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_61_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_61"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2747 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_20"](%/text_encoder/encoder/attn_layers.3/Sub_3_output_0, %onnx::Unsqueeze_2747), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_62_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_62"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_63_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_63"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_64_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_64"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_65_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_65"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_11"](%/text_encoder/encoder/attn_layers.3/Constant_61_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_20_output_0, %/text_encoder/encoder/attn_layers.3/Constant_62_output_0, %/text_encoder/encoder/attn_layers.3/Constant_63_output_0, %/text_encoder/encoder/attn_layers.3/Constant_64_output_0, %/text_encoder/encoder/attn_layers.3/Constant_65_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_66_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_66"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Shape_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_8"](%/text_encoder/encoder/attn_layers.3/Concat_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Gather_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_8"](%/text_encoder/encoder/attn_layers.3/Shape_8_output_0, %/text_encoder/encoder/attn_layers.3/Constant_66_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_67_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_67"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Sub_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub_4"](%/text_encoder/encoder/attn_layers.3/Constant_67_output_0, %/text_encoder/encoder/attn_layers.3/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_3"](%/text_encoder/encoder/attn_layers.3/Concat_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/ConstantOfShape_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/ConstantOfShape_2"](%/text_encoder/encoder/attn_layers.3/Sub_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Concat_12_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_12"](%/text_encoder/encoder/attn_layers.3/Cast_3_output_0, %/text_encoder/encoder/attn_layers.3/ConstantOfShape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_68_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.3/Constant_68"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_8_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_8"](%/text_encoder/encoder/attn_layers.3/Concat_12_output_0, %/text_encoder/encoder/attn_layers.3/Constant_68_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_69_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_69"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_70"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_71_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_71"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_72"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Slice_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_3"](%/text_encoder/encoder/attn_layers.3/Reshape_8_output_0, %/text_encoder/encoder/attn_layers.3/Constant_70_output_0, %/text_encoder/encoder/attn_layers.3/Constant_71_output_0, %/text_encoder/encoder/attn_layers.3/Constant_69_output_0, %/text_encoder/encoder/attn_layers.3/Constant_72_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Transpose_5_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose_5"](%/text_encoder/encoder/attn_layers.3/Slice_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_73_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_73"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_9"](%/text_encoder/encoder/attn_layers.3/Transpose_5_output_0, %/text_encoder/encoder/attn_layers.3/Constant_73_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_4"](%/text_encoder/encoder/attn_layers.3/Reshape_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Pad_2_output_0 : Float(*, *, *, strides=[40198, 20099, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.3/Pad_2"](%/text_encoder/encoder/attn_layers.3/Reshape_7_output_0, %/text_encoder/encoder/attn_layers.3/Cast_4_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_74_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_74"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.3/Add"](%/text_encoder/encoder/attn_layers.3/Gather_7_output_0, %/text_encoder/encoder/attn_layers.3/Constant_74_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_75_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_75"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Sub_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub_5"](%/text_encoder/encoder/attn_layers.3/Mul_1_output_0, %/text_encoder/encoder/attn_layers.3/Constant_75_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %onnx::Unsqueeze_2784 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_21"](%/text_encoder/encoder/attn_layers.3/Gather_5_output_0, %onnx::Unsqueeze_2784), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2786 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_22"](%/text_encoder/encoder/attn_layers.3/Gather_6_output_0, %onnx::Unsqueeze_2786), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2788 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_23"](%/text_encoder/encoder/attn_layers.3/Add_output_0, %onnx::Unsqueeze_2788), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2790 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_24"](%/text_encoder/encoder/attn_layers.3/Sub_5_output_0, %onnx::Unsqueeze_2790), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_13"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_21_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_22_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_23_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Reshape_10_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_10"](%/text_encoder/encoder/attn_layers.3/Pad_2_output_0, %/text_encoder/encoder/attn_layers.3/Concat_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_76"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_77_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_77"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_78"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_25"](%/text_encoder/encoder/attn_layers.3/Gather_7_output_0, %/text_encoder/encoder/attn_layers.3/Constant_78_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_79_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_79"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Slice_4_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_4"](%/text_encoder/encoder/attn_layers.3/Reshape_10_output_0, %/text_encoder/encoder/attn_layers.3/Constant_77_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_25_output_0, %/text_encoder/encoder/attn_layers.3/Constant_76_output_0, %/text_encoder/encoder/attn_layers.3/Constant_79_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_80_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_80"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_81"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_26"](%/text_encoder/encoder/attn_layers.3/Sub_3_output_0, %/text_encoder/encoder/attn_layers.3/Constant_81_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_82_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_82"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_83_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_83"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Slice_5_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_5"](%/text_encoder/encoder/attn_layers.3/Slice_4_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_26_output_0, %/text_encoder/encoder/attn_layers.3/Constant_82_output_0, %/text_encoder/encoder/attn_layers.3/Constant_80_output_0, %/text_encoder/encoder/attn_layers.3/Constant_83_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.3/Constant_84_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_84"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.3/Div_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.3/Div_1"](%/text_encoder/encoder/attn_layers.3/Slice_5_output_0, %/text_encoder/encoder/attn_layers.3/Constant_84_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.3/Add_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.3/Add_1"](%/text_encoder/encoder/attn_layers.3/Div_output_0, %/text_encoder/encoder/attn_layers.3/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:139:0
  %/text_encoder/encoder/attn_layers.3/Cast_5_output_0 : Bool(*, 1, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_5"](%/text_encoder/encoder/attn_layers.0/Equal_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.3/Constant_85_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_85"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.3/Where_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/text_encoder/encoder/attn_layers.3/Where"](%/text_encoder/encoder/attn_layers.3/Cast_5_output_0, %/text_encoder/encoder/attn_layers.3/Constant_85_output_0, %/text_encoder/encoder/attn_layers.3/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.3/Softmax_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/text_encoder/encoder/attn_layers.3/Softmax"](%/text_encoder/encoder/attn_layers.3/Where_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/text_encoder/encoder/attn_layers.3/MatMul_2_output_0 : Float(*, *, *, 96, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.3/MatMul_2"](%/text_encoder/encoder/attn_layers.3/Softmax_output_0, %/text_encoder/encoder/attn_layers.3/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:156:0
  %/text_encoder/encoder/attn_layers.3/Shape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_9"](%/text_encoder/encoder/attn_layers.3/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.3/Constant_86_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_86"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.3/Gather_9_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_9"](%/text_encoder/encoder/attn_layers.3/Shape_9_output_0, %/text_encoder/encoder/attn_layers.3/Constant_86_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.3/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_10"](%/text_encoder/encoder/attn_layers.3/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.3/Constant_87_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_87"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.3/Gather_10_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_10"](%/text_encoder/encoder/attn_layers.3/Shape_10_output_0, %/text_encoder/encoder/attn_layers.3/Constant_87_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.3/Shape_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_11"](%/text_encoder/encoder/attn_layers.3/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.3/Constant_88_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_88"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.3/Gather_11_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_11"](%/text_encoder/encoder/attn_layers.3/Shape_11_output_0, %/text_encoder/encoder/attn_layers.3/Constant_88_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.3/Constant_89_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_89"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.3/Sub_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub_6"](%/text_encoder/encoder/attn_layers.3/Gather_11_output_0, %/text_encoder/encoder/attn_layers.3/Constant_89_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.3/Constant_90_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_90"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2833 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_27"](%/text_encoder/encoder/attn_layers.3/Sub_6_output_0, %onnx::Unsqueeze_2833), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_91_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_91"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_92_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_92"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_93_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_93"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_94_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_94"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_95_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_95"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_96_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_96"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_14_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_14"](%/text_encoder/encoder/attn_layers.3/Constant_90_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_27_output_0, %/text_encoder/encoder/attn_layers.3/Constant_91_output_0, %/text_encoder/encoder/attn_layers.3/Constant_92_output_0, %/text_encoder/encoder/attn_layers.3/Constant_93_output_0, %/text_encoder/encoder/attn_layers.3/Constant_94_output_0, %/text_encoder/encoder/attn_layers.3/Constant_95_output_0, %/text_encoder/encoder/attn_layers.3/Constant_96_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_97_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_97"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2850 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_28"](%/text_encoder/encoder/attn_layers.3/Sub_6_output_0, %onnx::Unsqueeze_2850), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_98_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_98"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_99_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_99"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_100_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_100"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_101_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_101"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_102_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_102"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_103_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_103"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_15_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_15"](%/text_encoder/encoder/attn_layers.3/Constant_97_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_28_output_0, %/text_encoder/encoder/attn_layers.3/Constant_98_output_0, %/text_encoder/encoder/attn_layers.3/Constant_99_output_0, %/text_encoder/encoder/attn_layers.3/Constant_100_output_0, %/text_encoder/encoder/attn_layers.3/Constant_101_output_0, %/text_encoder/encoder/attn_layers.3/Constant_102_output_0, %/text_encoder/encoder/attn_layers.3/Constant_103_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_104_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_104"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Shape_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_12"](%/text_encoder/encoder/attn_layers.3/Concat_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Gather_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_12"](%/text_encoder/encoder/attn_layers.3/Shape_12_output_0, %/text_encoder/encoder/attn_layers.3/Constant_104_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_105_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_105"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Sub_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub_7"](%/text_encoder/encoder/attn_layers.3/Constant_105_output_0, %/text_encoder/encoder/attn_layers.3/Gather_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_6"](%/text_encoder/encoder/attn_layers.3/Concat_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/ConstantOfShape_3_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/ConstantOfShape_3"](%/text_encoder/encoder/attn_layers.3/Sub_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Concat_16_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_16"](%/text_encoder/encoder/attn_layers.3/Cast_6_output_0, %/text_encoder/encoder/attn_layers.3/ConstantOfShape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_106_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.3/Constant_106"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_11_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_11"](%/text_encoder/encoder/attn_layers.3/Concat_16_output_0, %/text_encoder/encoder/attn_layers.3/Constant_106_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_107_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_107"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_108"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_109_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_109"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_110"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Slice_6_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_6"](%/text_encoder/encoder/attn_layers.3/Reshape_11_output_0, %/text_encoder/encoder/attn_layers.3/Constant_108_output_0, %/text_encoder/encoder/attn_layers.3/Constant_109_output_0, %/text_encoder/encoder/attn_layers.3/Constant_107_output_0, %/text_encoder/encoder/attn_layers.3/Constant_110_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Transpose_6_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose_6"](%/text_encoder/encoder/attn_layers.3/Slice_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_111_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_111"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_12_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_12"](%/text_encoder/encoder/attn_layers.3/Transpose_6_output_0, %/text_encoder/encoder/attn_layers.3/Constant_111_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_7_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_7"](%/text_encoder/encoder/attn_layers.3/Reshape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Pad_3_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.3/Pad_3"](%/text_encoder/encoder/attn_layers.3/Softmax_output_0, %/text_encoder/encoder/attn_layers.3/Cast_7_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_112_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_112"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.3/Pow_output_0 : Long(requires_grad=0, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/attn_layers.3/Pow"](%/text_encoder/encoder/attn_layers.3/Gather_11_output_0, %/text_encoder/encoder/attn_layers.3/Constant_112_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.3/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.3/Mul_3"](%/text_encoder/encoder/attn_layers.3/Gather_11_output_0, %/text_encoder/encoder/attn_layers.3/Sub_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.3/Add_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.3/Add_2"](%/text_encoder/encoder/attn_layers.3/Pow_output_0, %/text_encoder/encoder/attn_layers.3/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_2891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_29"](%/text_encoder/encoder/attn_layers.3/Gather_9_output_0, %onnx::Unsqueeze_2891), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_30"](%/text_encoder/encoder/attn_layers.3/Gather_10_output_0, %onnx::Unsqueeze_2893), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2895 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_31"](%/text_encoder/encoder/attn_layers.3/Add_2_output_0, %onnx::Unsqueeze_2895), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_17_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_17"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_29_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_30_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.3/Reshape_13_output_0 : Float(*, *, *, strides=[39800, 19900, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_13"](%/text_encoder/encoder/attn_layers.3/Pad_3_output_0, %/text_encoder/encoder/attn_layers.3/Concat_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_2899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_32"](%/text_encoder/encoder/attn_layers.3/Gather_11_output_0, %onnx::Unsqueeze_2899), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_113_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_113"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_114_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_114"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_115_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_115"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_116_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_116"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_117_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_117"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_18"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_32_output_0, %/text_encoder/encoder/attn_layers.3/Constant_113_output_0, %/text_encoder/encoder/attn_layers.3/Constant_114_output_0, %/text_encoder/encoder/attn_layers.3/Constant_115_output_0, %/text_encoder/encoder/attn_layers.3/Constant_116_output_0, %/text_encoder/encoder/attn_layers.3/Constant_117_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %onnx::Unsqueeze_2912 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_33"](%/text_encoder/encoder/attn_layers.3/Gather_11_output_0, %onnx::Unsqueeze_2912), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_118_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_118"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_119_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_119"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_120_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_120"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_121_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_121"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Constant_122_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_122"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_19_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_19"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_33_output_0, %/text_encoder/encoder/attn_layers.3/Constant_118_output_0, %/text_encoder/encoder/attn_layers.3/Constant_119_output_0, %/text_encoder/encoder/attn_layers.3/Constant_120_output_0, %/text_encoder/encoder/attn_layers.3/Constant_121_output_0, %/text_encoder/encoder/attn_layers.3/Constant_122_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_123_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_123"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Shape_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_13"](%/text_encoder/encoder/attn_layers.3/Concat_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Gather_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_13"](%/text_encoder/encoder/attn_layers.3/Shape_13_output_0, %/text_encoder/encoder/attn_layers.3/Constant_123_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_124_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_124"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Sub_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub_8"](%/text_encoder/encoder/attn_layers.3/Constant_124_output_0, %/text_encoder/encoder/attn_layers.3/Gather_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_8"](%/text_encoder/encoder/attn_layers.3/Concat_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/ConstantOfShape_4_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/ConstantOfShape_4"](%/text_encoder/encoder/attn_layers.3/Sub_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Concat_20_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_20"](%/text_encoder/encoder/attn_layers.3/Cast_8_output_0, %/text_encoder/encoder/attn_layers.3/ConstantOfShape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_125_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.3/Constant_125"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_14_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_14"](%/text_encoder/encoder/attn_layers.3/Concat_20_output_0, %/text_encoder/encoder/attn_layers.3/Constant_125_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_126_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_126"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_127_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_127"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_128_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_128"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_129_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_129"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Slice_7_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_7"](%/text_encoder/encoder/attn_layers.3/Reshape_14_output_0, %/text_encoder/encoder/attn_layers.3/Constant_127_output_0, %/text_encoder/encoder/attn_layers.3/Constant_128_output_0, %/text_encoder/encoder/attn_layers.3/Constant_126_output_0, %/text_encoder/encoder/attn_layers.3/Constant_129_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Transpose_7_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose_7"](%/text_encoder/encoder/attn_layers.3/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_130_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_130"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_15_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_15"](%/text_encoder/encoder/attn_layers.3/Transpose_7_output_0, %/text_encoder/encoder/attn_layers.3/Constant_130_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_9"](%/text_encoder/encoder/attn_layers.3/Reshape_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Pad_4_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.3/Pad_4"](%/text_encoder/encoder/attn_layers.3/Reshape_13_output_0, %/text_encoder/encoder/attn_layers.3/Cast_9_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_131_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_131"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.3/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.3/Mul_4"](%/text_encoder/encoder/attn_layers.3/Gather_11_output_0, %/text_encoder/encoder/attn_layers.3/Constant_131_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %onnx::Unsqueeze_2949 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_34"](%/text_encoder/encoder/attn_layers.3/Gather_9_output_0, %onnx::Unsqueeze_2949), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2951 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_35"](%/text_encoder/encoder/attn_layers.3/Gather_10_output_0, %onnx::Unsqueeze_2951), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2953 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_36"](%/text_encoder/encoder/attn_layers.3/Gather_11_output_0, %onnx::Unsqueeze_2953), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_2955 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_37"](%/text_encoder/encoder/attn_layers.3/Mul_4_output_0, %onnx::Unsqueeze_2955), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_21_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_21"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_34_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_35_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_36_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.3/Reshape_16_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_16"](%/text_encoder/encoder/attn_layers.3/Pad_4_output_0, %/text_encoder/encoder/attn_layers.3/Concat_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.3/Constant_132_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_132"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.3/Constant_133_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_133"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.3/Constant_134_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_134"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.3/Constant_135_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_135"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.3/Slice_8_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_8"](%/text_encoder/encoder/attn_layers.3/Reshape_16_output_0, %/text_encoder/encoder/attn_layers.3/Constant_133_output_0, %/text_encoder/encoder/attn_layers.3/Constant_134_output_0, %/text_encoder/encoder/attn_layers.3/Constant_132_output_0, %/text_encoder/encoder/attn_layers.3/Constant_135_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.3/Constant_136_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_136"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.3/Shape_14"](%/text_encoder/encoder/attn_layers.3/Concat_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Gather_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Gather_14"](%/text_encoder/encoder/attn_layers.3/Shape_14_output_0, %/text_encoder/encoder/attn_layers.3/Constant_136_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_137_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_137"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Sub_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.3/Sub_9"](%/text_encoder/encoder/attn_layers.3/Constant_137_output_0, %/text_encoder/encoder/attn_layers.3/Gather_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_10"](%/text_encoder/encoder/attn_layers.3/Concat_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/ConstantOfShape_5_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/ConstantOfShape_5"](%/text_encoder/encoder/attn_layers.3/Sub_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Concat_22_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_22"](%/text_encoder/encoder/attn_layers.3/Cast_10_output_0, %/text_encoder/encoder/attn_layers.3/ConstantOfShape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_138_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.3/Constant_138"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_17_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_17"](%/text_encoder/encoder/attn_layers.3/Concat_22_output_0, %/text_encoder/encoder/attn_layers.3/Constant_138_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_139_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_139"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_140_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_140"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_141"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_142_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_142"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Slice_9_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_9"](%/text_encoder/encoder/attn_layers.3/Reshape_17_output_0, %/text_encoder/encoder/attn_layers.3/Constant_140_output_0, %/text_encoder/encoder/attn_layers.3/Constant_141_output_0, %/text_encoder/encoder/attn_layers.3/Constant_139_output_0, %/text_encoder/encoder/attn_layers.3/Constant_142_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Transpose_8_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose_8"](%/text_encoder/encoder/attn_layers.3/Slice_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_143"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Reshape_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_18"](%/text_encoder/encoder/attn_layers.3/Transpose_8_output_0, %/text_encoder/encoder/attn_layers.3/Constant_143_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Cast_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.3/Cast_11"](%/text_encoder/encoder/attn_layers.3/Reshape_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Pad_5_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.3/Pad_5"](%text_encoder.encoder.attn_layers.3.emb_rel_v, %/text_encoder/encoder/attn_layers.3/Cast_11_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.3/Constant_144_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_144"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Constant_145_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_145"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Constant_146_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_146"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_38"](%/text_encoder/encoder/attn_layers.3/Sub_1_output_0, %/text_encoder/encoder/attn_layers.3/Constant_146_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Constant_147_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_147"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Slice_10_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.3/Slice_10"](%/text_encoder/encoder/attn_layers.3/Pad_5_output_0, %/text_encoder/encoder/attn_layers.3/Constant_145_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_38_output_0, %/text_encoder/encoder/attn_layers.3/Constant_144_output_0, %/text_encoder/encoder/attn_layers.3/Constant_147_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.3/Constant_148_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.3/Constant_148"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_39_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_39"](%/text_encoder/encoder/attn_layers.3/Slice_10_output_0, %/text_encoder/encoder/attn_layers.3/Constant_148_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.3/MatMul_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.3/MatMul_3"](%/text_encoder/encoder/attn_layers.3/Slice_8_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.3/Add_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.3/Add_3"](%/text_encoder/encoder/attn_layers.3/MatMul_2_output_0, %/text_encoder/encoder/attn_layers.3/MatMul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:161:0
  %/text_encoder/encoder/attn_layers.3/Transpose_9_output_0 : Float(*, *, *, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.3/Transpose_9"](%/text_encoder/encoder/attn_layers.3/Add_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %onnx::Unsqueeze_3004 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_40"](%/text_encoder/encoder/attn_layers.3/Gather_output_0, %onnx::Unsqueeze_3004), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_3006 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_41"](%/text_encoder/encoder/attn_layers.3/Gather_1_output_0, %onnx::Unsqueeze_3006), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %onnx::Unsqueeze_3008 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.3/Unsqueeze_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.3/Unsqueeze_42"](%/text_encoder/encoder/attn_layers.3/Gather_3_output_0, %onnx::Unsqueeze_3008), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3
  %/text_encoder/encoder/attn_layers.3/Concat_23_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.3/Concat_23"](%/text_encoder/encoder/attn_layers.3/Unsqueeze_40_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_41_output_0, %/text_encoder/encoder/attn_layers.3/Unsqueeze_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.3/Reshape_19_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.3/Reshape_19"](%/text_encoder/encoder/attn_layers.3/Transpose_9_output_0, %/text_encoder/encoder/attn_layers.3/Concat_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.3/conv_o/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.3/conv_o/Conv"](%/text_encoder/encoder/attn_layers.3/Reshape_19_output_0, %text_encoder.encoder.attn_layers.3.conv_o.weight, %text_encoder.encoder.attn_layers.3.conv_o.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.3/torch.nn.modules.conv.Conv1d::conv_o # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/Add_6_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_6"](%/text_encoder/encoder/Mul_4_output_0, %/text_encoder/encoder/attn_layers.3/conv_o/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:422:0
  %/text_encoder/encoder/norm_layers_1.3/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.3/Transpose"](%/text_encoder/encoder/Add_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_1.3/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.3/ReduceMean"](%/text_encoder/encoder/norm_layers_1.3/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_1.3/Sub"](%/text_encoder/encoder/norm_layers_1.3/Transpose_output_0, %/text_encoder/encoder/norm_layers_1.3/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_1.3/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_1.3/Pow"](%/text_encoder/encoder/norm_layers_1.3/Sub_output_0, %/text_encoder/encoder/norm_layers_1.3/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.3/ReduceMean_1"](%/text_encoder/encoder/norm_layers_1.3/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_1.3/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.3/Add"](%/text_encoder/encoder/norm_layers_1.3/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_1.3/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_1.3/Sqrt"](%/text_encoder/encoder/norm_layers_1.3/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_1.3/Div"](%/text_encoder/encoder/norm_layers_1.3/Sub_output_0, %/text_encoder/encoder/norm_layers_1.3/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_1.3/Mul"](%/text_encoder/encoder/norm_layers_1.3/Div_output_0, %text_encoder.encoder.norm_layers_1.3.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.3/Add_1"](%/text_encoder/encoder/norm_layers_1.3/Mul_output_0, %text_encoder.encoder.norm_layers_1.3.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.3/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.3/Transpose_1"](%/text_encoder/encoder/norm_layers_1.3/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/ffn_layers.3/Mul_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.3/Mul"](%/text_encoder/encoder/norm_layers_1.3/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:291:0
  %/text_encoder/encoder/ffn_layers.3/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_1_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.3/ConstantOfShape"](%/text_encoder/encoder/ffn_layers.3/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.3/Concat"](%/text_encoder/encoder/ffn_layers.3/Constant_1_output_0, %/text_encoder/encoder/ffn_layers.3/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Reshape_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.3/Reshape"](%/text_encoder/encoder/ffn_layers.3/Concat_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.3/Slice"](%/text_encoder/encoder/ffn_layers.3/Reshape_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_4_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_5_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_3_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Transpose_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.3/Transpose"](%/text_encoder/encoder/ffn_layers.3/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Reshape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.3/Reshape_1"](%/text_encoder/encoder/ffn_layers.3/Transpose_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.3/Cast"](%/text_encoder/encoder/ffn_layers.3/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Pad_output_0 : Float(*, *, *, strides=[19584, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.3/Pad"](%/text_encoder/encoder/ffn_layers.3/Mul_output_0, %/text_encoder/encoder/ffn_layers.3/Cast_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/conv_1/Conv_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.3/conv_1/Conv"](%/text_encoder/encoder/ffn_layers.3/Pad_output_0, %text_encoder.encoder.ffn_layers.3.conv_1.weight, %text_encoder.encoder.ffn_layers.3.conv_1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3/torch.nn.modules.conv.Conv1d::conv_1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.3/Relu_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name="/text_encoder/encoder/ffn_layers.3/Relu"](%/text_encoder/encoder/ffn_layers.3/conv_1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:292:0
  %/text_encoder/encoder/ffn_layers.3/Mul_1_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.3/Mul_1"](%/text_encoder/encoder/ffn_layers.3/Relu_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:294:0
  %/text_encoder/encoder/ffn_layers.3/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_9_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.3/ConstantOfShape_1"](%/text_encoder/encoder/ffn_layers.3/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.3/Concat_1"](%/text_encoder/encoder/ffn_layers.3/Constant_9_output_0, %/text_encoder/encoder/ffn_layers.3/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Reshape_2_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.3/Reshape_2"](%/text_encoder/encoder/ffn_layers.3/Concat_1_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Slice_1_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.3/Slice_1"](%/text_encoder/encoder/ffn_layers.3/Reshape_2_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_12_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_13_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_11_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Transpose_1_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.3/Transpose_1"](%/text_encoder/encoder/ffn_layers.3/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.3/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Reshape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.3/Reshape_3"](%/text_encoder/encoder/ffn_layers.3/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.3/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.3/Cast_1"](%/text_encoder/encoder/ffn_layers.3/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/Pad_1_output_0 : Float(*, *, *, strides=[78336, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.3/Pad_1"](%/text_encoder/encoder/ffn_layers.3/Mul_1_output_0, %/text_encoder/encoder/ffn_layers.3/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.3/conv_2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.3/conv_2/Conv"](%/text_encoder/encoder/ffn_layers.3/Pad_1_output_0, %text_encoder.encoder.ffn_layers.3.conv_2.weight, %text_encoder.encoder.ffn_layers.3.conv_2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3/torch.nn.modules.conv.Conv1d::conv_2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.3/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.3/Mul_2"](%/text_encoder/encoder/ffn_layers.3/conv_2/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:295:0
  %/text_encoder/encoder/Add_7_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_7"](%/text_encoder/encoder/norm_layers_1.3/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.3/Mul_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:430:0
  %/text_encoder/encoder/norm_layers_2.3/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.3/Transpose"](%/text_encoder/encoder/Add_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_2.3/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.3/ReduceMean"](%/text_encoder/encoder/norm_layers_2.3/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_2.3/Sub"](%/text_encoder/encoder/norm_layers_2.3/Transpose_output_0, %/text_encoder/encoder/norm_layers_2.3/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_2.3/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_2.3/Pow"](%/text_encoder/encoder/norm_layers_2.3/Sub_output_0, %/text_encoder/encoder/norm_layers_2.3/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.3/ReduceMean_1"](%/text_encoder/encoder/norm_layers_2.3/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_2.3/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.3/Add"](%/text_encoder/encoder/norm_layers_2.3/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_2.3/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_2.3/Sqrt"](%/text_encoder/encoder/norm_layers_2.3/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_2.3/Div"](%/text_encoder/encoder/norm_layers_2.3/Sub_output_0, %/text_encoder/encoder/norm_layers_2.3/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_2.3/Mul"](%/text_encoder/encoder/norm_layers_2.3/Div_output_0, %text_encoder.encoder.norm_layers_2.3.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.3/Add_1"](%/text_encoder/encoder/norm_layers_2.3/Mul_output_0, %text_encoder.encoder.norm_layers_2.3.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.3/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.3/Transpose_1"](%/text_encoder/encoder/norm_layers_2.3/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/Mul_5_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/Mul_5"](%/text_encoder/encoder/norm_layers_2.3/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:419:0
  %/text_encoder/encoder/attn_layers.4/conv_q/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.4/conv_q/Conv"](%/text_encoder/encoder/Mul_5_output_0, %text_encoder.encoder.attn_layers.4.conv_q.weight, %text_encoder.encoder.attn_layers.4.conv_q.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4/torch.nn.modules.conv.Conv1d::conv_q # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.4/conv_k/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.4/conv_k/Conv"](%/text_encoder/encoder/Mul_5_output_0, %text_encoder.encoder.attn_layers.4.conv_k.weight, %text_encoder.encoder.attn_layers.4.conv_k.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4/torch.nn.modules.conv.Conv1d::conv_k # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.4/conv_v/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.4/conv_v/Conv"](%/text_encoder/encoder/Mul_5_output_0, %text_encoder.encoder.attn_layers.4.conv_v.weight, %text_encoder.encoder.attn_layers.4.conv_v.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4/torch.nn.modules.conv.Conv1d::conv_v # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.4/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape"](%/text_encoder/encoder/attn_layers.4/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather"](%/text_encoder/encoder/attn_layers.4/Shape_output_0, %/text_encoder/encoder/attn_layers.4/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_1"](%/text_encoder/encoder/attn_layers.4/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_1"](%/text_encoder/encoder/attn_layers.4/Shape_1_output_0, %/text_encoder/encoder/attn_layers.4/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_2"](%/text_encoder/encoder/attn_layers.4/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_2"](%/text_encoder/encoder/attn_layers.4/Shape_2_output_0, %/text_encoder/encoder/attn_layers.4/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_3"](%/text_encoder/encoder/attn_layers.4/conv_q/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.4/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_3"](%/text_encoder/encoder/attn_layers.4/Shape_3_output_0, %/text_encoder/encoder/attn_layers.4/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %onnx::Unsqueeze_3107 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze"](%/text_encoder/encoder/attn_layers.4/Gather_output_0, %onnx::Unsqueeze_3107), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3113 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_1"](%/text_encoder/encoder/attn_layers.4/Gather_3_output_0, %onnx::Unsqueeze_3113), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_output_0, %/text_encoder/encoder/attn_layers.4/Constant_4_output_0, %/text_encoder/encoder/attn_layers.4/Constant_5_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.4/Reshape_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape"](%/text_encoder/encoder/attn_layers.4/conv_q/Conv_output_0, %/text_encoder/encoder/attn_layers.4/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.4/Transpose_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose"](%/text_encoder/encoder/attn_layers.4/Reshape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %onnx::Unsqueeze_3118 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_2"](%/text_encoder/encoder/attn_layers.4/Gather_output_0, %onnx::Unsqueeze_3118), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3124 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_3"](%/text_encoder/encoder/attn_layers.4/Gather_2_output_0, %onnx::Unsqueeze_3124), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_1"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_2_output_0, %/text_encoder/encoder/attn_layers.4/Constant_6_output_0, %/text_encoder/encoder/attn_layers.4/Constant_7_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %onnx::Unsqueeze_3127 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_4"](%/text_encoder/encoder/attn_layers.4/Gather_output_0, %onnx::Unsqueeze_3127), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3133 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_5"](%/text_encoder/encoder/attn_layers.4/Gather_2_output_0, %onnx::Unsqueeze_3133), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_2"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_4_output_0, %/text_encoder/encoder/attn_layers.4/Constant_8_output_0, %/text_encoder/encoder/attn_layers.4/Constant_9_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.4/Reshape_1_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_1"](%/text_encoder/encoder/attn_layers.4/conv_k/Conv_output_0, %/text_encoder/encoder/attn_layers.4/Concat_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %/text_encoder/encoder/attn_layers.4/Reshape_2_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_2"](%/text_encoder/encoder/attn_layers.4/conv_v/Conv_output_0, %/text_encoder/encoder/attn_layers.4/Concat_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.4/Transpose_1_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose_1"](%/text_encoder/encoder/attn_layers.4/Reshape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.4/MatMul_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.4/MatMul"](%/text_encoder/encoder/attn_layers.4/Transpose_output_0, %/text_encoder/encoder/attn_layers.4/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.4/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.4/Div_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.4/Div"](%/text_encoder/encoder/attn_layers.4/MatMul_output_0, %/text_encoder/encoder/attn_layers.4/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.4/Constant_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.4/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub"](%/text_encoder/encoder/attn_layers.4/Gather_2_output_0, %/text_encoder/encoder/attn_layers.4/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.4/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.4/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.4/Mul"](%/text_encoder/encoder/attn_layers.4/Gather_2_output_0, %/text_encoder/encoder/attn_layers.4/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.4/Constant_13_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.4/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub_1"](%/text_encoder/encoder/attn_layers.4/Mul_output_0, %/text_encoder/encoder/attn_layers.4/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.4/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_6"](%/text_encoder/encoder/attn_layers.4/Sub_output_0, %onnx::Unsqueeze_3152), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3154 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_7"](%/text_encoder/encoder/attn_layers.4/Sub_output_0, %onnx::Unsqueeze_3154), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_3"](%/text_encoder/encoder/attn_layers.4/Constant_14_output_0, %/text_encoder/encoder/attn_layers.4/Constant_15_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_6_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_7_output_0, %/text_encoder/encoder/attn_layers.4/Constant_16_output_0, %/text_encoder/encoder/attn_layers.4/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3165 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_8"](%/text_encoder/encoder/attn_layers.4/Sub_output_0, %onnx::Unsqueeze_3165), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3167 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_9"](%/text_encoder/encoder/attn_layers.4/Sub_output_0, %onnx::Unsqueeze_3167), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_4"](%/text_encoder/encoder/attn_layers.4/Constant_18_output_0, %/text_encoder/encoder/attn_layers.4/Constant_19_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_8_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_9_output_0, %/text_encoder/encoder/attn_layers.4/Constant_20_output_0, %/text_encoder/encoder/attn_layers.4/Constant_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3178 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_10"](%/text_encoder/encoder/attn_layers.4/Sub_output_0, %onnx::Unsqueeze_3178), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3180 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_11"](%/text_encoder/encoder/attn_layers.4/Sub_output_0, %onnx::Unsqueeze_3180), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_5"](%/text_encoder/encoder/attn_layers.4/Constant_22_output_0, %/text_encoder/encoder/attn_layers.4/Constant_23_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_10_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_11_output_0, %/text_encoder/encoder/attn_layers.4/Constant_24_output_0, %/text_encoder/encoder/attn_layers.4/Constant_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_12"](%/text_encoder/encoder/attn_layers.4/Sub_output_0, %onnx::Unsqueeze_3191), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3193 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_13"](%/text_encoder/encoder/attn_layers.4/Sub_output_0, %onnx::Unsqueeze_3193), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_6"](%/text_encoder/encoder/attn_layers.4/Constant_26_output_0, %/text_encoder/encoder/attn_layers.4/Constant_27_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_12_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_13_output_0, %/text_encoder/encoder/attn_layers.4/Constant_28_output_0, %/text_encoder/encoder/attn_layers.4/Constant_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_4"](%/text_encoder/encoder/attn_layers.4/Concat_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_4"](%/text_encoder/encoder/attn_layers.4/Shape_4_output_0, %/text_encoder/encoder/attn_layers.4/Constant_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub_2"](%/text_encoder/encoder/attn_layers.4/Constant_31_output_0, %/text_encoder/encoder/attn_layers.4/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast"](%/text_encoder/encoder/attn_layers.4/Concat_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/ConstantOfShape"](%/text_encoder/encoder/attn_layers.4/Sub_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Concat_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_7"](%/text_encoder/encoder/attn_layers.4/Cast_output_0, %/text_encoder/encoder/attn_layers.4/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_32_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.4/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_3"](%/text_encoder/encoder/attn_layers.4/Concat_7_output_0, %/text_encoder/encoder/attn_layers.4/Constant_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice"](%/text_encoder/encoder/attn_layers.4/Reshape_3_output_0, %/text_encoder/encoder/attn_layers.4/Constant_34_output_0, %/text_encoder/encoder/attn_layers.4/Constant_35_output_0, %/text_encoder/encoder/attn_layers.4/Constant_33_output_0, %/text_encoder/encoder/attn_layers.4/Constant_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Transpose_2_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose_2"](%/text_encoder/encoder/attn_layers.4/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_4"](%/text_encoder/encoder/attn_layers.4/Transpose_2_output_0, %/text_encoder/encoder/attn_layers.4/Constant_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_1"](%/text_encoder/encoder/attn_layers.4/Reshape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Pad_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.4/Pad"](%text_encoder.encoder.attn_layers.4.emb_rel_k, %/text_encoder/encoder/attn_layers.4/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_40"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_14"](%/text_encoder/encoder/attn_layers.4/Sub_1_output_0, %/text_encoder/encoder/attn_layers.4/Constant_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_41"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Slice_1_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_1"](%/text_encoder/encoder/attn_layers.4/Pad_output_0, %/text_encoder/encoder/attn_layers.4/Constant_39_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_14_output_0, %/text_encoder/encoder/attn_layers.4/Constant_38_output_0, %/text_encoder/encoder/attn_layers.4/Constant_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_42"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_15_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_15"](%/text_encoder/encoder/attn_layers.4/Slice_1_output_0, %/text_encoder/encoder/attn_layers.4/Constant_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.4/Transpose_3_output_0 : Float(1, *, *, *, strides=[19104, 19104, 1, 96], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose_3"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.4/MatMul_1_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.4/MatMul_1"](%/text_encoder/encoder/attn_layers.4/Transpose_output_0, %/text_encoder/encoder/attn_layers.4/Transpose_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.4/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_5"](%/text_encoder/encoder/attn_layers.4/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.4/Constant_43_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_43"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.4/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_5"](%/text_encoder/encoder/attn_layers.4/Shape_5_output_0, %/text_encoder/encoder/attn_layers.4/Constant_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.4/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_6"](%/text_encoder/encoder/attn_layers.4/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.4/Constant_44_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_44"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.4/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_6"](%/text_encoder/encoder/attn_layers.4/Shape_6_output_0, %/text_encoder/encoder/attn_layers.4/Constant_44_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.4/Shape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_7"](%/text_encoder/encoder/attn_layers.4/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.4/Constant_45_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_45"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.4/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_7"](%/text_encoder/encoder/attn_layers.4/Shape_7_output_0, %/text_encoder/encoder/attn_layers.4/Constant_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.4/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_46"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_47_output_0 : Long(8, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  0  0  0  0  0  0 [ CPULongType{8} ], onnx_name="/text_encoder/encoder/attn_layers.4/Constant_47"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/ConstantOfShape_1"](%/text_encoder/encoder/attn_layers.4/Constant_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Concat_8_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_8"](%/text_encoder/encoder/attn_layers.4/Constant_47_output_0, %/text_encoder/encoder/attn_layers.4/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_48_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.4/Constant_48"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_5_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_5"](%/text_encoder/encoder/attn_layers.4/Concat_8_output_0, %/text_encoder/encoder/attn_layers.4/Constant_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_49"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_50"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_51"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_52"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Slice_2_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_2"](%/text_encoder/encoder/attn_layers.4/Reshape_5_output_0, %/text_encoder/encoder/attn_layers.4/Constant_50_output_0, %/text_encoder/encoder/attn_layers.4/Constant_51_output_0, %/text_encoder/encoder/attn_layers.4/Constant_49_output_0, %/text_encoder/encoder/attn_layers.4/Constant_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Transpose_4_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose_4"](%/text_encoder/encoder/attn_layers.4/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_53"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_6"](%/text_encoder/encoder/attn_layers.4/Transpose_4_output_0, %/text_encoder/encoder/attn_layers.4/Constant_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_2"](%/text_encoder/encoder/attn_layers.4/Reshape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Pad_1_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.4/Pad_1"](%/text_encoder/encoder/attn_layers.4/MatMul_1_output_0, %/text_encoder/encoder/attn_layers.4/Cast_2_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_54_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_54"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.4/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.4/Mul_1"](%/text_encoder/encoder/attn_layers.4/Gather_7_output_0, %/text_encoder/encoder/attn_layers.4/Constant_54_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.4/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.4/Mul_2"](%/text_encoder/encoder/attn_layers.4/Mul_1_output_0, %/text_encoder/encoder/attn_layers.4/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %onnx::Unsqueeze_3269 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_16"](%/text_encoder/encoder/attn_layers.4/Gather_5_output_0, %onnx::Unsqueeze_3269), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3271 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_17"](%/text_encoder/encoder/attn_layers.4/Gather_6_output_0, %onnx::Unsqueeze_3271), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3273 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_18"](%/text_encoder/encoder/attn_layers.4/Mul_2_output_0, %onnx::Unsqueeze_3273), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_9"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_16_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_17_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.4/Reshape_7_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_7"](%/text_encoder/encoder/attn_layers.4/Pad_1_output_0, %/text_encoder/encoder/attn_layers.4/Concat_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.4/Constant_55_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_55"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.4/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub_3"](%/text_encoder/encoder/attn_layers.4/Gather_7_output_0, %/text_encoder/encoder/attn_layers.4/Constant_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.4/Constant_56_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_56"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3281 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_19"](%/text_encoder/encoder/attn_layers.4/Sub_3_output_0, %onnx::Unsqueeze_3281), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_57"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_58"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_59_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_59"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_60_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_60"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_10"](%/text_encoder/encoder/attn_layers.4/Constant_56_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_19_output_0, %/text_encoder/encoder/attn_layers.4/Constant_57_output_0, %/text_encoder/encoder/attn_layers.4/Constant_58_output_0, %/text_encoder/encoder/attn_layers.4/Constant_59_output_0, %/text_encoder/encoder/attn_layers.4/Constant_60_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_61_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_61"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3294 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_20"](%/text_encoder/encoder/attn_layers.4/Sub_3_output_0, %onnx::Unsqueeze_3294), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_62_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_62"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_63_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_63"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_64_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_64"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_65_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_65"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_11"](%/text_encoder/encoder/attn_layers.4/Constant_61_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_20_output_0, %/text_encoder/encoder/attn_layers.4/Constant_62_output_0, %/text_encoder/encoder/attn_layers.4/Constant_63_output_0, %/text_encoder/encoder/attn_layers.4/Constant_64_output_0, %/text_encoder/encoder/attn_layers.4/Constant_65_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_66_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_66"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Shape_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_8"](%/text_encoder/encoder/attn_layers.4/Concat_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Gather_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_8"](%/text_encoder/encoder/attn_layers.4/Shape_8_output_0, %/text_encoder/encoder/attn_layers.4/Constant_66_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_67_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_67"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Sub_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub_4"](%/text_encoder/encoder/attn_layers.4/Constant_67_output_0, %/text_encoder/encoder/attn_layers.4/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_3"](%/text_encoder/encoder/attn_layers.4/Concat_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/ConstantOfShape_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/ConstantOfShape_2"](%/text_encoder/encoder/attn_layers.4/Sub_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Concat_12_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_12"](%/text_encoder/encoder/attn_layers.4/Cast_3_output_0, %/text_encoder/encoder/attn_layers.4/ConstantOfShape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_68_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.4/Constant_68"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_8_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_8"](%/text_encoder/encoder/attn_layers.4/Concat_12_output_0, %/text_encoder/encoder/attn_layers.4/Constant_68_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_69_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_69"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_70"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_71_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_71"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_72"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Slice_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_3"](%/text_encoder/encoder/attn_layers.4/Reshape_8_output_0, %/text_encoder/encoder/attn_layers.4/Constant_70_output_0, %/text_encoder/encoder/attn_layers.4/Constant_71_output_0, %/text_encoder/encoder/attn_layers.4/Constant_69_output_0, %/text_encoder/encoder/attn_layers.4/Constant_72_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Transpose_5_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose_5"](%/text_encoder/encoder/attn_layers.4/Slice_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_73_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_73"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_9"](%/text_encoder/encoder/attn_layers.4/Transpose_5_output_0, %/text_encoder/encoder/attn_layers.4/Constant_73_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_4"](%/text_encoder/encoder/attn_layers.4/Reshape_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Pad_2_output_0 : Float(*, *, *, strides=[40198, 20099, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.4/Pad_2"](%/text_encoder/encoder/attn_layers.4/Reshape_7_output_0, %/text_encoder/encoder/attn_layers.4/Cast_4_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_74_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_74"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.4/Add"](%/text_encoder/encoder/attn_layers.4/Gather_7_output_0, %/text_encoder/encoder/attn_layers.4/Constant_74_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_75_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_75"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Sub_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub_5"](%/text_encoder/encoder/attn_layers.4/Mul_1_output_0, %/text_encoder/encoder/attn_layers.4/Constant_75_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %onnx::Unsqueeze_3331 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_21"](%/text_encoder/encoder/attn_layers.4/Gather_5_output_0, %onnx::Unsqueeze_3331), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3333 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_22"](%/text_encoder/encoder/attn_layers.4/Gather_6_output_0, %onnx::Unsqueeze_3333), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3335 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_23"](%/text_encoder/encoder/attn_layers.4/Add_output_0, %onnx::Unsqueeze_3335), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3337 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_24"](%/text_encoder/encoder/attn_layers.4/Sub_5_output_0, %onnx::Unsqueeze_3337), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_13"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_21_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_22_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_23_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Reshape_10_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_10"](%/text_encoder/encoder/attn_layers.4/Pad_2_output_0, %/text_encoder/encoder/attn_layers.4/Concat_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_76"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_77_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_77"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_78"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_25"](%/text_encoder/encoder/attn_layers.4/Gather_7_output_0, %/text_encoder/encoder/attn_layers.4/Constant_78_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_79_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_79"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Slice_4_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_4"](%/text_encoder/encoder/attn_layers.4/Reshape_10_output_0, %/text_encoder/encoder/attn_layers.4/Constant_77_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_25_output_0, %/text_encoder/encoder/attn_layers.4/Constant_76_output_0, %/text_encoder/encoder/attn_layers.4/Constant_79_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_80_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_80"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_81"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_26"](%/text_encoder/encoder/attn_layers.4/Sub_3_output_0, %/text_encoder/encoder/attn_layers.4/Constant_81_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_82_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_82"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_83_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_83"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Slice_5_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_5"](%/text_encoder/encoder/attn_layers.4/Slice_4_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_26_output_0, %/text_encoder/encoder/attn_layers.4/Constant_82_output_0, %/text_encoder/encoder/attn_layers.4/Constant_80_output_0, %/text_encoder/encoder/attn_layers.4/Constant_83_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.4/Constant_84_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_84"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.4/Div_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.4/Div_1"](%/text_encoder/encoder/attn_layers.4/Slice_5_output_0, %/text_encoder/encoder/attn_layers.4/Constant_84_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.4/Add_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.4/Add_1"](%/text_encoder/encoder/attn_layers.4/Div_output_0, %/text_encoder/encoder/attn_layers.4/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:139:0
  %/text_encoder/encoder/attn_layers.4/Cast_5_output_0 : Bool(*, 1, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_5"](%/text_encoder/encoder/attn_layers.0/Equal_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.4/Constant_85_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_85"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.4/Where_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/text_encoder/encoder/attn_layers.4/Where"](%/text_encoder/encoder/attn_layers.4/Cast_5_output_0, %/text_encoder/encoder/attn_layers.4/Constant_85_output_0, %/text_encoder/encoder/attn_layers.4/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.4/Softmax_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/text_encoder/encoder/attn_layers.4/Softmax"](%/text_encoder/encoder/attn_layers.4/Where_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/text_encoder/encoder/attn_layers.4/MatMul_2_output_0 : Float(*, *, *, 96, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.4/MatMul_2"](%/text_encoder/encoder/attn_layers.4/Softmax_output_0, %/text_encoder/encoder/attn_layers.4/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:156:0
  %/text_encoder/encoder/attn_layers.4/Shape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_9"](%/text_encoder/encoder/attn_layers.4/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.4/Constant_86_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_86"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.4/Gather_9_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_9"](%/text_encoder/encoder/attn_layers.4/Shape_9_output_0, %/text_encoder/encoder/attn_layers.4/Constant_86_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.4/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_10"](%/text_encoder/encoder/attn_layers.4/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.4/Constant_87_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_87"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.4/Gather_10_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_10"](%/text_encoder/encoder/attn_layers.4/Shape_10_output_0, %/text_encoder/encoder/attn_layers.4/Constant_87_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.4/Shape_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_11"](%/text_encoder/encoder/attn_layers.4/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.4/Constant_88_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_88"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.4/Gather_11_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_11"](%/text_encoder/encoder/attn_layers.4/Shape_11_output_0, %/text_encoder/encoder/attn_layers.4/Constant_88_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.4/Constant_89_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_89"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.4/Sub_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub_6"](%/text_encoder/encoder/attn_layers.4/Gather_11_output_0, %/text_encoder/encoder/attn_layers.4/Constant_89_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.4/Constant_90_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_90"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3380 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_27"](%/text_encoder/encoder/attn_layers.4/Sub_6_output_0, %onnx::Unsqueeze_3380), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_91_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_91"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_92_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_92"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_93_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_93"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_94_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_94"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_95_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_95"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_96_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_96"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_14_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_14"](%/text_encoder/encoder/attn_layers.4/Constant_90_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_27_output_0, %/text_encoder/encoder/attn_layers.4/Constant_91_output_0, %/text_encoder/encoder/attn_layers.4/Constant_92_output_0, %/text_encoder/encoder/attn_layers.4/Constant_93_output_0, %/text_encoder/encoder/attn_layers.4/Constant_94_output_0, %/text_encoder/encoder/attn_layers.4/Constant_95_output_0, %/text_encoder/encoder/attn_layers.4/Constant_96_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_97_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_97"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3397 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_28"](%/text_encoder/encoder/attn_layers.4/Sub_6_output_0, %onnx::Unsqueeze_3397), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_98_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_98"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_99_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_99"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_100_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_100"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_101_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_101"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_102_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_102"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_103_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_103"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_15_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_15"](%/text_encoder/encoder/attn_layers.4/Constant_97_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_28_output_0, %/text_encoder/encoder/attn_layers.4/Constant_98_output_0, %/text_encoder/encoder/attn_layers.4/Constant_99_output_0, %/text_encoder/encoder/attn_layers.4/Constant_100_output_0, %/text_encoder/encoder/attn_layers.4/Constant_101_output_0, %/text_encoder/encoder/attn_layers.4/Constant_102_output_0, %/text_encoder/encoder/attn_layers.4/Constant_103_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_104_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_104"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Shape_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_12"](%/text_encoder/encoder/attn_layers.4/Concat_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Gather_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_12"](%/text_encoder/encoder/attn_layers.4/Shape_12_output_0, %/text_encoder/encoder/attn_layers.4/Constant_104_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_105_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_105"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Sub_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub_7"](%/text_encoder/encoder/attn_layers.4/Constant_105_output_0, %/text_encoder/encoder/attn_layers.4/Gather_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_6"](%/text_encoder/encoder/attn_layers.4/Concat_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/ConstantOfShape_3_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/ConstantOfShape_3"](%/text_encoder/encoder/attn_layers.4/Sub_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Concat_16_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_16"](%/text_encoder/encoder/attn_layers.4/Cast_6_output_0, %/text_encoder/encoder/attn_layers.4/ConstantOfShape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_106_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.4/Constant_106"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_11_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_11"](%/text_encoder/encoder/attn_layers.4/Concat_16_output_0, %/text_encoder/encoder/attn_layers.4/Constant_106_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_107_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_107"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_108"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_109_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_109"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_110"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Slice_6_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_6"](%/text_encoder/encoder/attn_layers.4/Reshape_11_output_0, %/text_encoder/encoder/attn_layers.4/Constant_108_output_0, %/text_encoder/encoder/attn_layers.4/Constant_109_output_0, %/text_encoder/encoder/attn_layers.4/Constant_107_output_0, %/text_encoder/encoder/attn_layers.4/Constant_110_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Transpose_6_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose_6"](%/text_encoder/encoder/attn_layers.4/Slice_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_111_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_111"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_12_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_12"](%/text_encoder/encoder/attn_layers.4/Transpose_6_output_0, %/text_encoder/encoder/attn_layers.4/Constant_111_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_7_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_7"](%/text_encoder/encoder/attn_layers.4/Reshape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Pad_3_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.4/Pad_3"](%/text_encoder/encoder/attn_layers.4/Softmax_output_0, %/text_encoder/encoder/attn_layers.4/Cast_7_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_112_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_112"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.4/Pow_output_0 : Long(requires_grad=0, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/attn_layers.4/Pow"](%/text_encoder/encoder/attn_layers.4/Gather_11_output_0, %/text_encoder/encoder/attn_layers.4/Constant_112_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.4/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.4/Mul_3"](%/text_encoder/encoder/attn_layers.4/Gather_11_output_0, %/text_encoder/encoder/attn_layers.4/Sub_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.4/Add_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.4/Add_2"](%/text_encoder/encoder/attn_layers.4/Pow_output_0, %/text_encoder/encoder/attn_layers.4/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_3438 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_29"](%/text_encoder/encoder/attn_layers.4/Gather_9_output_0, %onnx::Unsqueeze_3438), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3440 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_30"](%/text_encoder/encoder/attn_layers.4/Gather_10_output_0, %onnx::Unsqueeze_3440), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3442 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_31"](%/text_encoder/encoder/attn_layers.4/Add_2_output_0, %onnx::Unsqueeze_3442), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_17_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_17"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_29_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_30_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.4/Reshape_13_output_0 : Float(*, *, *, strides=[39800, 19900, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_13"](%/text_encoder/encoder/attn_layers.4/Pad_3_output_0, %/text_encoder/encoder/attn_layers.4/Concat_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_3446 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_32"](%/text_encoder/encoder/attn_layers.4/Gather_11_output_0, %onnx::Unsqueeze_3446), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_113_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_113"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_114_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_114"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_115_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_115"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_116_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_116"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_117_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_117"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_18"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_32_output_0, %/text_encoder/encoder/attn_layers.4/Constant_113_output_0, %/text_encoder/encoder/attn_layers.4/Constant_114_output_0, %/text_encoder/encoder/attn_layers.4/Constant_115_output_0, %/text_encoder/encoder/attn_layers.4/Constant_116_output_0, %/text_encoder/encoder/attn_layers.4/Constant_117_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %onnx::Unsqueeze_3459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_33"](%/text_encoder/encoder/attn_layers.4/Gather_11_output_0, %onnx::Unsqueeze_3459), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_118_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_118"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_119_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_119"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_120_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_120"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_121_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_121"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Constant_122_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_122"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_19_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_19"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_33_output_0, %/text_encoder/encoder/attn_layers.4/Constant_118_output_0, %/text_encoder/encoder/attn_layers.4/Constant_119_output_0, %/text_encoder/encoder/attn_layers.4/Constant_120_output_0, %/text_encoder/encoder/attn_layers.4/Constant_121_output_0, %/text_encoder/encoder/attn_layers.4/Constant_122_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_123_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_123"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Shape_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_13"](%/text_encoder/encoder/attn_layers.4/Concat_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Gather_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_13"](%/text_encoder/encoder/attn_layers.4/Shape_13_output_0, %/text_encoder/encoder/attn_layers.4/Constant_123_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_124_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_124"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Sub_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub_8"](%/text_encoder/encoder/attn_layers.4/Constant_124_output_0, %/text_encoder/encoder/attn_layers.4/Gather_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_8"](%/text_encoder/encoder/attn_layers.4/Concat_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/ConstantOfShape_4_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/ConstantOfShape_4"](%/text_encoder/encoder/attn_layers.4/Sub_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Concat_20_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_20"](%/text_encoder/encoder/attn_layers.4/Cast_8_output_0, %/text_encoder/encoder/attn_layers.4/ConstantOfShape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_125_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.4/Constant_125"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_14_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_14"](%/text_encoder/encoder/attn_layers.4/Concat_20_output_0, %/text_encoder/encoder/attn_layers.4/Constant_125_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_126_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_126"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_127_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_127"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_128_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_128"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_129_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_129"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Slice_7_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_7"](%/text_encoder/encoder/attn_layers.4/Reshape_14_output_0, %/text_encoder/encoder/attn_layers.4/Constant_127_output_0, %/text_encoder/encoder/attn_layers.4/Constant_128_output_0, %/text_encoder/encoder/attn_layers.4/Constant_126_output_0, %/text_encoder/encoder/attn_layers.4/Constant_129_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Transpose_7_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose_7"](%/text_encoder/encoder/attn_layers.4/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_130_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_130"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_15_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_15"](%/text_encoder/encoder/attn_layers.4/Transpose_7_output_0, %/text_encoder/encoder/attn_layers.4/Constant_130_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_9"](%/text_encoder/encoder/attn_layers.4/Reshape_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Pad_4_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.4/Pad_4"](%/text_encoder/encoder/attn_layers.4/Reshape_13_output_0, %/text_encoder/encoder/attn_layers.4/Cast_9_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_131_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_131"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.4/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.4/Mul_4"](%/text_encoder/encoder/attn_layers.4/Gather_11_output_0, %/text_encoder/encoder/attn_layers.4/Constant_131_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %onnx::Unsqueeze_3496 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_34"](%/text_encoder/encoder/attn_layers.4/Gather_9_output_0, %onnx::Unsqueeze_3496), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3498 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_35"](%/text_encoder/encoder/attn_layers.4/Gather_10_output_0, %onnx::Unsqueeze_3498), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3500 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_36"](%/text_encoder/encoder/attn_layers.4/Gather_11_output_0, %onnx::Unsqueeze_3500), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3502 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_37"](%/text_encoder/encoder/attn_layers.4/Mul_4_output_0, %onnx::Unsqueeze_3502), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_21_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_21"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_34_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_35_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_36_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.4/Reshape_16_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_16"](%/text_encoder/encoder/attn_layers.4/Pad_4_output_0, %/text_encoder/encoder/attn_layers.4/Concat_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.4/Constant_132_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_132"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.4/Constant_133_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_133"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.4/Constant_134_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_134"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.4/Constant_135_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_135"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.4/Slice_8_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_8"](%/text_encoder/encoder/attn_layers.4/Reshape_16_output_0, %/text_encoder/encoder/attn_layers.4/Constant_133_output_0, %/text_encoder/encoder/attn_layers.4/Constant_134_output_0, %/text_encoder/encoder/attn_layers.4/Constant_132_output_0, %/text_encoder/encoder/attn_layers.4/Constant_135_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.4/Constant_136_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_136"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.4/Shape_14"](%/text_encoder/encoder/attn_layers.4/Concat_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Gather_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Gather_14"](%/text_encoder/encoder/attn_layers.4/Shape_14_output_0, %/text_encoder/encoder/attn_layers.4/Constant_136_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_137_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_137"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Sub_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.4/Sub_9"](%/text_encoder/encoder/attn_layers.4/Constant_137_output_0, %/text_encoder/encoder/attn_layers.4/Gather_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_10"](%/text_encoder/encoder/attn_layers.4/Concat_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/ConstantOfShape_5_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/ConstantOfShape_5"](%/text_encoder/encoder/attn_layers.4/Sub_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Concat_22_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_22"](%/text_encoder/encoder/attn_layers.4/Cast_10_output_0, %/text_encoder/encoder/attn_layers.4/ConstantOfShape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_138_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.4/Constant_138"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_17_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_17"](%/text_encoder/encoder/attn_layers.4/Concat_22_output_0, %/text_encoder/encoder/attn_layers.4/Constant_138_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_139_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_139"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_140_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_140"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_141"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_142_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_142"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Slice_9_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_9"](%/text_encoder/encoder/attn_layers.4/Reshape_17_output_0, %/text_encoder/encoder/attn_layers.4/Constant_140_output_0, %/text_encoder/encoder/attn_layers.4/Constant_141_output_0, %/text_encoder/encoder/attn_layers.4/Constant_139_output_0, %/text_encoder/encoder/attn_layers.4/Constant_142_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Transpose_8_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose_8"](%/text_encoder/encoder/attn_layers.4/Slice_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_143"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Reshape_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_18"](%/text_encoder/encoder/attn_layers.4/Transpose_8_output_0, %/text_encoder/encoder/attn_layers.4/Constant_143_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Cast_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.4/Cast_11"](%/text_encoder/encoder/attn_layers.4/Reshape_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Pad_5_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.4/Pad_5"](%text_encoder.encoder.attn_layers.4.emb_rel_v, %/text_encoder/encoder/attn_layers.4/Cast_11_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.4/Constant_144_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_144"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Constant_145_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_145"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Constant_146_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_146"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_38"](%/text_encoder/encoder/attn_layers.4/Sub_1_output_0, %/text_encoder/encoder/attn_layers.4/Constant_146_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Constant_147_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_147"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Slice_10_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.4/Slice_10"](%/text_encoder/encoder/attn_layers.4/Pad_5_output_0, %/text_encoder/encoder/attn_layers.4/Constant_145_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_38_output_0, %/text_encoder/encoder/attn_layers.4/Constant_144_output_0, %/text_encoder/encoder/attn_layers.4/Constant_147_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.4/Constant_148_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.4/Constant_148"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_39_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_39"](%/text_encoder/encoder/attn_layers.4/Slice_10_output_0, %/text_encoder/encoder/attn_layers.4/Constant_148_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.4/MatMul_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.4/MatMul_3"](%/text_encoder/encoder/attn_layers.4/Slice_8_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.4/Add_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.4/Add_3"](%/text_encoder/encoder/attn_layers.4/MatMul_2_output_0, %/text_encoder/encoder/attn_layers.4/MatMul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:161:0
  %/text_encoder/encoder/attn_layers.4/Transpose_9_output_0 : Float(*, *, *, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.4/Transpose_9"](%/text_encoder/encoder/attn_layers.4/Add_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %onnx::Unsqueeze_3551 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_40"](%/text_encoder/encoder/attn_layers.4/Gather_output_0, %onnx::Unsqueeze_3551), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3553 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_41"](%/text_encoder/encoder/attn_layers.4/Gather_1_output_0, %onnx::Unsqueeze_3553), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %onnx::Unsqueeze_3555 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.4/Unsqueeze_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.4/Unsqueeze_42"](%/text_encoder/encoder/attn_layers.4/Gather_3_output_0, %onnx::Unsqueeze_3555), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4
  %/text_encoder/encoder/attn_layers.4/Concat_23_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.4/Concat_23"](%/text_encoder/encoder/attn_layers.4/Unsqueeze_40_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_41_output_0, %/text_encoder/encoder/attn_layers.4/Unsqueeze_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.4/Reshape_19_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.4/Reshape_19"](%/text_encoder/encoder/attn_layers.4/Transpose_9_output_0, %/text_encoder/encoder/attn_layers.4/Concat_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.4/conv_o/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.4/conv_o/Conv"](%/text_encoder/encoder/attn_layers.4/Reshape_19_output_0, %text_encoder.encoder.attn_layers.4.conv_o.weight, %text_encoder.encoder.attn_layers.4.conv_o.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.4/torch.nn.modules.conv.Conv1d::conv_o # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/Add_8_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_8"](%/text_encoder/encoder/Mul_5_output_0, %/text_encoder/encoder/attn_layers.4/conv_o/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:422:0
  %/text_encoder/encoder/norm_layers_1.4/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.4/Transpose"](%/text_encoder/encoder/Add_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_1.4/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.4/ReduceMean"](%/text_encoder/encoder/norm_layers_1.4/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_1.4/Sub"](%/text_encoder/encoder/norm_layers_1.4/Transpose_output_0, %/text_encoder/encoder/norm_layers_1.4/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_1.4/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_1.4/Pow"](%/text_encoder/encoder/norm_layers_1.4/Sub_output_0, %/text_encoder/encoder/norm_layers_1.4/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.4/ReduceMean_1"](%/text_encoder/encoder/norm_layers_1.4/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_1.4/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.4/Add"](%/text_encoder/encoder/norm_layers_1.4/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_1.4/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_1.4/Sqrt"](%/text_encoder/encoder/norm_layers_1.4/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_1.4/Div"](%/text_encoder/encoder/norm_layers_1.4/Sub_output_0, %/text_encoder/encoder/norm_layers_1.4/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_1.4/Mul"](%/text_encoder/encoder/norm_layers_1.4/Div_output_0, %text_encoder.encoder.norm_layers_1.4.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.4/Add_1"](%/text_encoder/encoder/norm_layers_1.4/Mul_output_0, %text_encoder.encoder.norm_layers_1.4.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.4/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.4/Transpose_1"](%/text_encoder/encoder/norm_layers_1.4/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/ffn_layers.4/Mul_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.4/Mul"](%/text_encoder/encoder/norm_layers_1.4/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:291:0
  %/text_encoder/encoder/ffn_layers.4/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_1_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.4/ConstantOfShape"](%/text_encoder/encoder/ffn_layers.4/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.4/Concat"](%/text_encoder/encoder/ffn_layers.4/Constant_1_output_0, %/text_encoder/encoder/ffn_layers.4/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Reshape_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.4/Reshape"](%/text_encoder/encoder/ffn_layers.4/Concat_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.4/Slice"](%/text_encoder/encoder/ffn_layers.4/Reshape_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_4_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_5_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_3_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Transpose_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.4/Transpose"](%/text_encoder/encoder/ffn_layers.4/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Reshape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.4/Reshape_1"](%/text_encoder/encoder/ffn_layers.4/Transpose_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.4/Cast"](%/text_encoder/encoder/ffn_layers.4/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Pad_output_0 : Float(*, *, *, strides=[19584, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.4/Pad"](%/text_encoder/encoder/ffn_layers.4/Mul_output_0, %/text_encoder/encoder/ffn_layers.4/Cast_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/conv_1/Conv_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.4/conv_1/Conv"](%/text_encoder/encoder/ffn_layers.4/Pad_output_0, %text_encoder.encoder.ffn_layers.4.conv_1.weight, %text_encoder.encoder.ffn_layers.4.conv_1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4/torch.nn.modules.conv.Conv1d::conv_1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.4/Relu_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name="/text_encoder/encoder/ffn_layers.4/Relu"](%/text_encoder/encoder/ffn_layers.4/conv_1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:292:0
  %/text_encoder/encoder/ffn_layers.4/Mul_1_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.4/Mul_1"](%/text_encoder/encoder/ffn_layers.4/Relu_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:294:0
  %/text_encoder/encoder/ffn_layers.4/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_9_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.4/ConstantOfShape_1"](%/text_encoder/encoder/ffn_layers.4/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.4/Concat_1"](%/text_encoder/encoder/ffn_layers.4/Constant_9_output_0, %/text_encoder/encoder/ffn_layers.4/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Reshape_2_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.4/Reshape_2"](%/text_encoder/encoder/ffn_layers.4/Concat_1_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Slice_1_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.4/Slice_1"](%/text_encoder/encoder/ffn_layers.4/Reshape_2_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_12_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_13_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_11_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Transpose_1_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.4/Transpose_1"](%/text_encoder/encoder/ffn_layers.4/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.4/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Reshape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.4/Reshape_3"](%/text_encoder/encoder/ffn_layers.4/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.4/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.4/Cast_1"](%/text_encoder/encoder/ffn_layers.4/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/Pad_1_output_0 : Float(*, *, *, strides=[78336, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.4/Pad_1"](%/text_encoder/encoder/ffn_layers.4/Mul_1_output_0, %/text_encoder/encoder/ffn_layers.4/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.4/conv_2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.4/conv_2/Conv"](%/text_encoder/encoder/ffn_layers.4/Pad_1_output_0, %text_encoder.encoder.ffn_layers.4.conv_2.weight, %text_encoder.encoder.ffn_layers.4.conv_2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4/torch.nn.modules.conv.Conv1d::conv_2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.4/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.4/Mul_2"](%/text_encoder/encoder/ffn_layers.4/conv_2/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:295:0
  %/text_encoder/encoder/Add_9_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_9"](%/text_encoder/encoder/norm_layers_1.4/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.4/Mul_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:430:0
  %/text_encoder/encoder/norm_layers_2.4/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.4/Transpose"](%/text_encoder/encoder/Add_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_2.4/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.4/ReduceMean"](%/text_encoder/encoder/norm_layers_2.4/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_2.4/Sub"](%/text_encoder/encoder/norm_layers_2.4/Transpose_output_0, %/text_encoder/encoder/norm_layers_2.4/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_2.4/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_2.4/Pow"](%/text_encoder/encoder/norm_layers_2.4/Sub_output_0, %/text_encoder/encoder/norm_layers_2.4/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.4/ReduceMean_1"](%/text_encoder/encoder/norm_layers_2.4/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_2.4/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.4/Add"](%/text_encoder/encoder/norm_layers_2.4/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_2.4/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_2.4/Sqrt"](%/text_encoder/encoder/norm_layers_2.4/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_2.4/Div"](%/text_encoder/encoder/norm_layers_2.4/Sub_output_0, %/text_encoder/encoder/norm_layers_2.4/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_2.4/Mul"](%/text_encoder/encoder/norm_layers_2.4/Div_output_0, %text_encoder.encoder.norm_layers_2.4.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.4/Add_1"](%/text_encoder/encoder/norm_layers_2.4/Mul_output_0, %text_encoder.encoder.norm_layers_2.4.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.4/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.4/Transpose_1"](%/text_encoder/encoder/norm_layers_2.4/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/Mul_6_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/Mul_6"](%/text_encoder/encoder/norm_layers_2.4/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:419:0
  %/text_encoder/encoder/attn_layers.5/conv_q/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.5/conv_q/Conv"](%/text_encoder/encoder/Mul_6_output_0, %text_encoder.encoder.attn_layers.5.conv_q.weight, %text_encoder.encoder.attn_layers.5.conv_q.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5/torch.nn.modules.conv.Conv1d::conv_q # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.5/conv_k/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.5/conv_k/Conv"](%/text_encoder/encoder/Mul_6_output_0, %text_encoder.encoder.attn_layers.5.conv_k.weight, %text_encoder.encoder.attn_layers.5.conv_k.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5/torch.nn.modules.conv.Conv1d::conv_k # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.5/conv_v/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.5/conv_v/Conv"](%/text_encoder/encoder/Mul_6_output_0, %text_encoder.encoder.attn_layers.5.conv_v.weight, %text_encoder.encoder.attn_layers.5.conv_v.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5/torch.nn.modules.conv.Conv1d::conv_v # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/attn_layers.5/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape"](%/text_encoder/encoder/attn_layers.5/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather"](%/text_encoder/encoder/attn_layers.5/Shape_output_0, %/text_encoder/encoder/attn_layers.5/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_1"](%/text_encoder/encoder/attn_layers.5/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_1"](%/text_encoder/encoder/attn_layers.5/Shape_1_output_0, %/text_encoder/encoder/attn_layers.5/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_2"](%/text_encoder/encoder/attn_layers.5/conv_k/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_2"](%/text_encoder/encoder/attn_layers.5/Shape_2_output_0, %/text_encoder/encoder/attn_layers.5/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_3"](%/text_encoder/encoder/attn_layers.5/conv_q/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Constant_3_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %/text_encoder/encoder/attn_layers.5/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_3"](%/text_encoder/encoder/attn_layers.5/Shape_3_output_0, %/text_encoder/encoder/attn_layers.5/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:125:0
  %onnx::Unsqueeze_3654 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze"](%/text_encoder/encoder/attn_layers.5/Gather_output_0, %onnx::Unsqueeze_3654), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3660 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_1"](%/text_encoder/encoder/attn_layers.5/Gather_3_output_0, %onnx::Unsqueeze_3660), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_output_0, %/text_encoder/encoder/attn_layers.5/Constant_4_output_0, %/text_encoder/encoder/attn_layers.5/Constant_5_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.5/Reshape_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape"](%/text_encoder/encoder/attn_layers.5/conv_q/Conv_output_0, %/text_encoder/encoder/attn_layers.5/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %/text_encoder/encoder/attn_layers.5/Transpose_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose"](%/text_encoder/encoder/attn_layers.5/Reshape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:126:0
  %onnx::Unsqueeze_3665 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_2"](%/text_encoder/encoder/attn_layers.5/Gather_output_0, %onnx::Unsqueeze_3665), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3671 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_3"](%/text_encoder/encoder/attn_layers.5/Gather_2_output_0, %onnx::Unsqueeze_3671), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_1"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_2_output_0, %/text_encoder/encoder/attn_layers.5/Constant_6_output_0, %/text_encoder/encoder/attn_layers.5/Constant_7_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %onnx::Unsqueeze_3674 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_4"](%/text_encoder/encoder/attn_layers.5/Gather_output_0, %onnx::Unsqueeze_3674), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={96}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3680 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_5"](%/text_encoder/encoder/attn_layers.5/Gather_2_output_0, %onnx::Unsqueeze_3680), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_2"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_4_output_0, %/text_encoder/encoder/attn_layers.5/Constant_8_output_0, %/text_encoder/encoder/attn_layers.5/Constant_9_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.5/Reshape_1_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_1"](%/text_encoder/encoder/attn_layers.5/conv_k/Conv_output_0, %/text_encoder/encoder/attn_layers.5/Concat_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:127:0
  %/text_encoder/encoder/attn_layers.5/Reshape_2_output_0 : Float(*, 2, 96, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_2"](%/text_encoder/encoder/attn_layers.5/conv_v/Conv_output_0, %/text_encoder/encoder/attn_layers.5/Concat_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.5/Transpose_1_output_0 : Float(*, 2, *, 96, strides=[19200, 9600, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose_1"](%/text_encoder/encoder/attn_layers.5/Reshape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:128:0
  %/text_encoder/encoder/attn_layers.5/MatMul_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.5/MatMul"](%/text_encoder/encoder/attn_layers.5/Transpose_output_0, %/text_encoder/encoder/attn_layers.5/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.5/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.5/Div_output_0 : Float(*, 2, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.5/Div"](%/text_encoder/encoder/attn_layers.5/MatMul_output_0, %/text_encoder/encoder/attn_layers.5/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:130:0
  %/text_encoder/encoder/attn_layers.5/Constant_11_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.5/Sub_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub"](%/text_encoder/encoder/attn_layers.5/Gather_2_output_0, %/text_encoder/encoder/attn_layers.5/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:199:0
  %/text_encoder/encoder/attn_layers.5/Constant_12_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.5/Mul_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.5/Mul"](%/text_encoder/encoder/attn_layers.5/Gather_2_output_0, %/text_encoder/encoder/attn_layers.5/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.5/Constant_13_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.5/Sub_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub_1"](%/text_encoder/encoder/attn_layers.5/Mul_output_0, %/text_encoder/encoder/attn_layers.5/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:201:0
  %/text_encoder/encoder/attn_layers.5/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3699 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_6"](%/text_encoder/encoder/attn_layers.5/Sub_output_0, %onnx::Unsqueeze_3699), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3701 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_7"](%/text_encoder/encoder/attn_layers.5/Sub_output_0, %onnx::Unsqueeze_3701), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_3"](%/text_encoder/encoder/attn_layers.5/Constant_14_output_0, %/text_encoder/encoder/attn_layers.5/Constant_15_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_6_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_7_output_0, %/text_encoder/encoder/attn_layers.5/Constant_16_output_0, %/text_encoder/encoder/attn_layers.5/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3712 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_8"](%/text_encoder/encoder/attn_layers.5/Sub_output_0, %onnx::Unsqueeze_3712), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3714 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_9"](%/text_encoder/encoder/attn_layers.5/Sub_output_0, %onnx::Unsqueeze_3714), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_4"](%/text_encoder/encoder/attn_layers.5/Constant_18_output_0, %/text_encoder/encoder/attn_layers.5/Constant_19_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_8_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_9_output_0, %/text_encoder/encoder/attn_layers.5/Constant_20_output_0, %/text_encoder/encoder/attn_layers.5/Constant_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3725 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_10"](%/text_encoder/encoder/attn_layers.5/Sub_output_0, %onnx::Unsqueeze_3725), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3727 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_11"](%/text_encoder/encoder/attn_layers.5/Sub_output_0, %onnx::Unsqueeze_3727), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_5"](%/text_encoder/encoder/attn_layers.5/Constant_22_output_0, %/text_encoder/encoder/attn_layers.5/Constant_23_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_10_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_11_output_0, %/text_encoder/encoder/attn_layers.5/Constant_24_output_0, %/text_encoder/encoder/attn_layers.5/Constant_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3738 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_12"](%/text_encoder/encoder/attn_layers.5/Sub_output_0, %onnx::Unsqueeze_3738), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3740 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_13"](%/text_encoder/encoder/attn_layers.5/Sub_output_0, %onnx::Unsqueeze_3740), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_6_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_6"](%/text_encoder/encoder/attn_layers.5/Constant_26_output_0, %/text_encoder/encoder/attn_layers.5/Constant_27_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_12_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_13_output_0, %/text_encoder/encoder/attn_layers.5/Constant_28_output_0, %/text_encoder/encoder/attn_layers.5/Constant_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Shape_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_4"](%/text_encoder/encoder/attn_layers.5/Concat_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Gather_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_4"](%/text_encoder/encoder/attn_layers.5/Shape_4_output_0, %/text_encoder/encoder/attn_layers.5/Constant_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Sub_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub_2"](%/text_encoder/encoder/attn_layers.5/Constant_31_output_0, %/text_encoder/encoder/attn_layers.5/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast"](%/text_encoder/encoder/attn_layers.5/Concat_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/ConstantOfShape"](%/text_encoder/encoder/attn_layers.5/Sub_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Concat_7_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_7"](%/text_encoder/encoder/attn_layers.5/Cast_output_0, %/text_encoder/encoder/attn_layers.5/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_32_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.5/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_3"](%/text_encoder/encoder/attn_layers.5/Concat_7_output_0, %/text_encoder/encoder/attn_layers.5/Constant_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice"](%/text_encoder/encoder/attn_layers.5/Reshape_3_output_0, %/text_encoder/encoder/attn_layers.5/Constant_34_output_0, %/text_encoder/encoder/attn_layers.5/Constant_35_output_0, %/text_encoder/encoder/attn_layers.5/Constant_33_output_0, %/text_encoder/encoder/attn_layers.5/Constant_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Transpose_2_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose_2"](%/text_encoder/encoder/attn_layers.5/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_4"](%/text_encoder/encoder/attn_layers.5/Transpose_2_output_0, %/text_encoder/encoder/attn_layers.5/Constant_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_1"](%/text_encoder/encoder/attn_layers.5/Reshape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Pad_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.5/Pad"](%text_encoder.encoder.attn_layers.5.emb_rel_k, %/text_encoder/encoder/attn_layers.5/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Constant_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_40"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_14"](%/text_encoder/encoder/attn_layers.5/Sub_1_output_0, %/text_encoder/encoder/attn_layers.5/Constant_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Constant_41_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_41"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Slice_1_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_1"](%/text_encoder/encoder/attn_layers.5/Pad_output_0, %/text_encoder/encoder/attn_layers.5/Constant_39_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_14_output_0, %/text_encoder/encoder/attn_layers.5/Constant_38_output_0, %/text_encoder/encoder/attn_layers.5/Constant_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_42"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_15_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_15"](%/text_encoder/encoder/attn_layers.5/Slice_1_output_0, %/text_encoder/encoder/attn_layers.5/Constant_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.5/Transpose_3_output_0 : Float(1, *, *, *, strides=[19104, 19104, 1, 96], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose_3"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.5/MatMul_1_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.5/MatMul_1"](%/text_encoder/encoder/attn_layers.5/Transpose_output_0, %/text_encoder/encoder/attn_layers.5/Transpose_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:193:0
  %/text_encoder/encoder/attn_layers.5/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_5"](%/text_encoder/encoder/attn_layers.5/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.5/Constant_43_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_43"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.5/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_5"](%/text_encoder/encoder/attn_layers.5/Shape_5_output_0, %/text_encoder/encoder/attn_layers.5/Constant_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.5/Shape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_6"](%/text_encoder/encoder/attn_layers.5/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.5/Constant_44_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_44"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.5/Gather_6_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_6"](%/text_encoder/encoder/attn_layers.5/Shape_6_output_0, %/text_encoder/encoder/attn_layers.5/Constant_44_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.5/Shape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_7"](%/text_encoder/encoder/attn_layers.5/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.5/Constant_45_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_45"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.5/Gather_7_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_7"](%/text_encoder/encoder/attn_layers.5/Shape_7_output_0, %/text_encoder/encoder/attn_layers.5/Constant_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:217:0
  %/text_encoder/encoder/attn_layers.5/Constant_46_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_46"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_47_output_0 : Long(8, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1  0  0  0  0  0  0 [ CPULongType{8} ], onnx_name="/text_encoder/encoder/attn_layers.5/Constant_47"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/ConstantOfShape_1"](%/text_encoder/encoder/attn_layers.5/Constant_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Concat_8_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_8"](%/text_encoder/encoder/attn_layers.5/Constant_47_output_0, %/text_encoder/encoder/attn_layers.5/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_48_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.5/Constant_48"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_5_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_5"](%/text_encoder/encoder/attn_layers.5/Concat_8_output_0, %/text_encoder/encoder/attn_layers.5/Constant_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_49"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_50"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_51"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_52"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Slice_2_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_2"](%/text_encoder/encoder/attn_layers.5/Reshape_5_output_0, %/text_encoder/encoder/attn_layers.5/Constant_50_output_0, %/text_encoder/encoder/attn_layers.5/Constant_51_output_0, %/text_encoder/encoder/attn_layers.5/Constant_49_output_0, %/text_encoder/encoder/attn_layers.5/Constant_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Transpose_4_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose_4"](%/text_encoder/encoder/attn_layers.5/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_53"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_6"](%/text_encoder/encoder/attn_layers.5/Transpose_4_output_0, %/text_encoder/encoder/attn_layers.5/Constant_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_2"](%/text_encoder/encoder/attn_layers.5/Reshape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Pad_1_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.5/Pad_1"](%/text_encoder/encoder/attn_layers.5/MatMul_1_output_0, %/text_encoder/encoder/attn_layers.5/Cast_2_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_54_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_54"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.5/Mul_1_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.5/Mul_1"](%/text_encoder/encoder/attn_layers.5/Gather_7_output_0, %/text_encoder/encoder/attn_layers.5/Constant_54_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.5/Mul_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.5/Mul_2"](%/text_encoder/encoder/attn_layers.5/Mul_1_output_0, %/text_encoder/encoder/attn_layers.5/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %onnx::Unsqueeze_3816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_16"](%/text_encoder/encoder/attn_layers.5/Gather_5_output_0, %onnx::Unsqueeze_3816), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_17"](%/text_encoder/encoder/attn_layers.5/Gather_6_output_0, %onnx::Unsqueeze_3818), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3820 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_18"](%/text_encoder/encoder/attn_layers.5/Mul_2_output_0, %onnx::Unsqueeze_3820), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_9_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_9"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_16_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_17_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.5/Reshape_7_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_7"](%/text_encoder/encoder/attn_layers.5/Pad_1_output_0, %/text_encoder/encoder/attn_layers.5/Concat_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:221:0
  %/text_encoder/encoder/attn_layers.5/Constant_55_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_55"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.5/Sub_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub_3"](%/text_encoder/encoder/attn_layers.5/Gather_7_output_0, %/text_encoder/encoder/attn_layers.5/Constant_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:222:0
  %/text_encoder/encoder/attn_layers.5/Constant_56_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_56"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3828 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_19"](%/text_encoder/encoder/attn_layers.5/Sub_3_output_0, %onnx::Unsqueeze_3828), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_57"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_58_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_58"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_59_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_59"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_60_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_60"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_10"](%/text_encoder/encoder/attn_layers.5/Constant_56_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_19_output_0, %/text_encoder/encoder/attn_layers.5/Constant_57_output_0, %/text_encoder/encoder/attn_layers.5/Constant_58_output_0, %/text_encoder/encoder/attn_layers.5/Constant_59_output_0, %/text_encoder/encoder/attn_layers.5/Constant_60_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_61_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_61"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3841 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_20"](%/text_encoder/encoder/attn_layers.5/Sub_3_output_0, %onnx::Unsqueeze_3841), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_62_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_62"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_63_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_63"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_64_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_64"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_65_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_65"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_11"](%/text_encoder/encoder/attn_layers.5/Constant_61_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_20_output_0, %/text_encoder/encoder/attn_layers.5/Constant_62_output_0, %/text_encoder/encoder/attn_layers.5/Constant_63_output_0, %/text_encoder/encoder/attn_layers.5/Constant_64_output_0, %/text_encoder/encoder/attn_layers.5/Constant_65_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_66_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_66"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Shape_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_8"](%/text_encoder/encoder/attn_layers.5/Concat_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Gather_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_8"](%/text_encoder/encoder/attn_layers.5/Shape_8_output_0, %/text_encoder/encoder/attn_layers.5/Constant_66_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_67_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_67"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Sub_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub_4"](%/text_encoder/encoder/attn_layers.5/Constant_67_output_0, %/text_encoder/encoder/attn_layers.5/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_3"](%/text_encoder/encoder/attn_layers.5/Concat_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/ConstantOfShape_2_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/ConstantOfShape_2"](%/text_encoder/encoder/attn_layers.5/Sub_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Concat_12_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_12"](%/text_encoder/encoder/attn_layers.5/Cast_3_output_0, %/text_encoder/encoder/attn_layers.5/ConstantOfShape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_68_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.5/Constant_68"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_8_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_8"](%/text_encoder/encoder/attn_layers.5/Concat_12_output_0, %/text_encoder/encoder/attn_layers.5/Constant_68_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_69_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_69"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_70"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_71_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_71"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_72"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Slice_3_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_3"](%/text_encoder/encoder/attn_layers.5/Reshape_8_output_0, %/text_encoder/encoder/attn_layers.5/Constant_70_output_0, %/text_encoder/encoder/attn_layers.5/Constant_71_output_0, %/text_encoder/encoder/attn_layers.5/Constant_69_output_0, %/text_encoder/encoder/attn_layers.5/Constant_72_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Transpose_5_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose_5"](%/text_encoder/encoder/attn_layers.5/Slice_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_73_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_73"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_9"](%/text_encoder/encoder/attn_layers.5/Transpose_5_output_0, %/text_encoder/encoder/attn_layers.5/Constant_73_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_4_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_4"](%/text_encoder/encoder/attn_layers.5/Reshape_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Pad_2_output_0 : Float(*, *, *, strides=[40198, 20099, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.5/Pad_2"](%/text_encoder/encoder/attn_layers.5/Reshape_7_output_0, %/text_encoder/encoder/attn_layers.5/Cast_4_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_74_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_74"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Add_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.5/Add"](%/text_encoder/encoder/attn_layers.5/Gather_7_output_0, %/text_encoder/encoder/attn_layers.5/Constant_74_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_75_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_75"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Sub_5_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub_5"](%/text_encoder/encoder/attn_layers.5/Mul_1_output_0, %/text_encoder/encoder/attn_layers.5/Constant_75_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %onnx::Unsqueeze_3878 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_21"](%/text_encoder/encoder/attn_layers.5/Gather_5_output_0, %onnx::Unsqueeze_3878), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3880 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_22"](%/text_encoder/encoder/attn_layers.5/Gather_6_output_0, %onnx::Unsqueeze_3880), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3882 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_23"](%/text_encoder/encoder/attn_layers.5/Add_output_0, %onnx::Unsqueeze_3882), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3884 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_24"](%/text_encoder/encoder/attn_layers.5/Sub_5_output_0, %onnx::Unsqueeze_3884), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_13"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_21_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_22_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_23_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Reshape_10_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_10"](%/text_encoder/encoder/attn_layers.5/Pad_2_output_0, %/text_encoder/encoder/attn_layers.5/Concat_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_76"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_77_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_77"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_78"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_25"](%/text_encoder/encoder/attn_layers.5/Gather_7_output_0, %/text_encoder/encoder/attn_layers.5/Constant_78_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_79_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_79"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Slice_4_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_4"](%/text_encoder/encoder/attn_layers.5/Reshape_10_output_0, %/text_encoder/encoder/attn_layers.5/Constant_77_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_25_output_0, %/text_encoder/encoder/attn_layers.5/Constant_76_output_0, %/text_encoder/encoder/attn_layers.5/Constant_79_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_80_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_80"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_81"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_26"](%/text_encoder/encoder/attn_layers.5/Sub_3_output_0, %/text_encoder/encoder/attn_layers.5/Constant_81_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_82_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_82"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_83_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_83"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Slice_5_output_0 : Float(*, *, *, *, strides=[40198, 20099, 199, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_5"](%/text_encoder/encoder/attn_layers.5/Slice_4_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_26_output_0, %/text_encoder/encoder/attn_layers.5/Constant_82_output_0, %/text_encoder/encoder/attn_layers.5/Constant_80_output_0, %/text_encoder/encoder/attn_layers.5/Constant_83_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:224:0
  %/text_encoder/encoder/attn_layers.5/Constant_84_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_84"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.5/Div_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/attn_layers.5/Div_1"](%/text_encoder/encoder/attn_layers.5/Slice_5_output_0, %/text_encoder/encoder/attn_layers.5/Constant_84_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:138:0
  %/text_encoder/encoder/attn_layers.5/Add_1_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.5/Add_1"](%/text_encoder/encoder/attn_layers.5/Div_output_0, %/text_encoder/encoder/attn_layers.5/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:139:0
  %/text_encoder/encoder/attn_layers.5/Cast_5_output_0 : Bool(*, 1, *, *, device=cpu) = onnx::Cast[to=9, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_5"](%/text_encoder/encoder/attn_layers.0/Equal_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.5/Constant_85_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_85"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.5/Where_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Where[onnx_name="/text_encoder/encoder/attn_layers.5/Where"](%/text_encoder/encoder/attn_layers.5/Cast_5_output_0, %/text_encoder/encoder/attn_layers.5/Constant_85_output_0, %/text_encoder/encoder/attn_layers.5/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:147:0
  %/text_encoder/encoder/attn_layers.5/Softmax_output_0 : Float(*, *, *, *, strides=[20000, 10000, 100, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/text_encoder/encoder/attn_layers.5/Softmax"](%/text_encoder/encoder/attn_layers.5/Where_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/text_encoder/encoder/attn_layers.5/MatMul_2_output_0 : Float(*, *, *, 96, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.5/MatMul_2"](%/text_encoder/encoder/attn_layers.5/Softmax_output_0, %/text_encoder/encoder/attn_layers.5/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:156:0
  %/text_encoder/encoder/attn_layers.5/Shape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_9"](%/text_encoder/encoder/attn_layers.5/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.5/Constant_86_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_86"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.5/Gather_9_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_9"](%/text_encoder/encoder/attn_layers.5/Shape_9_output_0, %/text_encoder/encoder/attn_layers.5/Constant_86_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.5/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_10"](%/text_encoder/encoder/attn_layers.5/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.5/Constant_87_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_87"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.5/Gather_10_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_10"](%/text_encoder/encoder/attn_layers.5/Shape_10_output_0, %/text_encoder/encoder/attn_layers.5/Constant_87_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.5/Shape_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_11"](%/text_encoder/encoder/attn_layers.5/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.5/Constant_88_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_88"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.5/Gather_11_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_11"](%/text_encoder/encoder/attn_layers.5/Shape_11_output_0, %/text_encoder/encoder/attn_layers.5/Constant_88_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:234:0
  %/text_encoder/encoder/attn_layers.5/Constant_89_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_89"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.5/Sub_6_output_0 : Long(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub_6"](%/text_encoder/encoder/attn_layers.5/Gather_11_output_0, %/text_encoder/encoder/attn_layers.5/Constant_89_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:236:0
  %/text_encoder/encoder/attn_layers.5/Constant_90_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_90"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3927 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_27"](%/text_encoder/encoder/attn_layers.5/Sub_6_output_0, %onnx::Unsqueeze_3927), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_91_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_91"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_92_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_92"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_93_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_93"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_94_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_94"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_95_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_95"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_96_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_96"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_14_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_14"](%/text_encoder/encoder/attn_layers.5/Constant_90_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_27_output_0, %/text_encoder/encoder/attn_layers.5/Constant_91_output_0, %/text_encoder/encoder/attn_layers.5/Constant_92_output_0, %/text_encoder/encoder/attn_layers.5/Constant_93_output_0, %/text_encoder/encoder/attn_layers.5/Constant_94_output_0, %/text_encoder/encoder/attn_layers.5/Constant_95_output_0, %/text_encoder/encoder/attn_layers.5/Constant_96_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_97_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_97"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3944 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_28"](%/text_encoder/encoder/attn_layers.5/Sub_6_output_0, %onnx::Unsqueeze_3944), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_98_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_98"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_99_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_99"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_100_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_100"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_101_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_101"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_102_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_102"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_103_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_103"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_15_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_15"](%/text_encoder/encoder/attn_layers.5/Constant_97_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_28_output_0, %/text_encoder/encoder/attn_layers.5/Constant_98_output_0, %/text_encoder/encoder/attn_layers.5/Constant_99_output_0, %/text_encoder/encoder/attn_layers.5/Constant_100_output_0, %/text_encoder/encoder/attn_layers.5/Constant_101_output_0, %/text_encoder/encoder/attn_layers.5/Constant_102_output_0, %/text_encoder/encoder/attn_layers.5/Constant_103_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_104_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_104"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Shape_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_12"](%/text_encoder/encoder/attn_layers.5/Concat_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Gather_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_12"](%/text_encoder/encoder/attn_layers.5/Shape_12_output_0, %/text_encoder/encoder/attn_layers.5/Constant_104_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_105_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_105"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Sub_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub_7"](%/text_encoder/encoder/attn_layers.5/Constant_105_output_0, %/text_encoder/encoder/attn_layers.5/Gather_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_6_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_6"](%/text_encoder/encoder/attn_layers.5/Concat_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/ConstantOfShape_3_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/ConstantOfShape_3"](%/text_encoder/encoder/attn_layers.5/Sub_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Concat_16_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_16"](%/text_encoder/encoder/attn_layers.5/Cast_6_output_0, %/text_encoder/encoder/attn_layers.5/ConstantOfShape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_106_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.5/Constant_106"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_11_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_11"](%/text_encoder/encoder/attn_layers.5/Concat_16_output_0, %/text_encoder/encoder/attn_layers.5/Constant_106_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_107_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_107"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_108"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_109_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_109"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_110"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Slice_6_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_6"](%/text_encoder/encoder/attn_layers.5/Reshape_11_output_0, %/text_encoder/encoder/attn_layers.5/Constant_108_output_0, %/text_encoder/encoder/attn_layers.5/Constant_109_output_0, %/text_encoder/encoder/attn_layers.5/Constant_107_output_0, %/text_encoder/encoder/attn_layers.5/Constant_110_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Transpose_6_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose_6"](%/text_encoder/encoder/attn_layers.5/Slice_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_111_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_111"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_12_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_12"](%/text_encoder/encoder/attn_layers.5/Transpose_6_output_0, %/text_encoder/encoder/attn_layers.5/Constant_111_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_7_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_7"](%/text_encoder/encoder/attn_layers.5/Reshape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Pad_3_output_0 : Float(*, *, *, *, strides=[39800, 19900, 199, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.5/Pad_3"](%/text_encoder/encoder/attn_layers.5/Softmax_output_0, %/text_encoder/encoder/attn_layers.5/Cast_7_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_112_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_112"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.5/Pow_output_0 : Long(requires_grad=0, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/attn_layers.5/Pow"](%/text_encoder/encoder/attn_layers.5/Gather_11_output_0, %/text_encoder/encoder/attn_layers.5/Constant_112_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:41:0
  %/text_encoder/encoder/attn_layers.5/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.5/Mul_3"](%/text_encoder/encoder/attn_layers.5/Gather_11_output_0, %/text_encoder/encoder/attn_layers.5/Sub_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.5/Add_2_output_0 : Long(requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.5/Add_2"](%/text_encoder/encoder/attn_layers.5/Pow_output_0, %/text_encoder/encoder/attn_layers.5/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_3985 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_29_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_29"](%/text_encoder/encoder/attn_layers.5/Gather_9_output_0, %onnx::Unsqueeze_3985), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3987 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_30"](%/text_encoder/encoder/attn_layers.5/Gather_10_output_0, %onnx::Unsqueeze_3987), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_3989 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_31"](%/text_encoder/encoder/attn_layers.5/Add_2_output_0, %onnx::Unsqueeze_3989), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_17_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_17"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_29_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_30_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %/text_encoder/encoder/attn_layers.5/Reshape_13_output_0 : Float(*, *, *, strides=[39800, 19900, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_13"](%/text_encoder/encoder/attn_layers.5/Pad_3_output_0, %/text_encoder/encoder/attn_layers.5/Concat_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:237:0
  %onnx::Unsqueeze_3993 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_32"](%/text_encoder/encoder/attn_layers.5/Gather_11_output_0, %onnx::Unsqueeze_3993), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_113_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_113"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_114_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_114"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_115_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_115"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_116_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_116"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_117_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_117"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_18"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_32_output_0, %/text_encoder/encoder/attn_layers.5/Constant_113_output_0, %/text_encoder/encoder/attn_layers.5/Constant_114_output_0, %/text_encoder/encoder/attn_layers.5/Constant_115_output_0, %/text_encoder/encoder/attn_layers.5/Constant_116_output_0, %/text_encoder/encoder/attn_layers.5/Constant_117_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %onnx::Unsqueeze_4006 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_33"](%/text_encoder/encoder/attn_layers.5/Gather_11_output_0, %onnx::Unsqueeze_4006), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_118_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_118"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_119_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_119"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_120_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_120"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_121_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_121"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Constant_122_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_122"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_19_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_19"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_33_output_0, %/text_encoder/encoder/attn_layers.5/Constant_118_output_0, %/text_encoder/encoder/attn_layers.5/Constant_119_output_0, %/text_encoder/encoder/attn_layers.5/Constant_120_output_0, %/text_encoder/encoder/attn_layers.5/Constant_121_output_0, %/text_encoder/encoder/attn_layers.5/Constant_122_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_123_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_123"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Shape_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_13"](%/text_encoder/encoder/attn_layers.5/Concat_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Gather_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_13"](%/text_encoder/encoder/attn_layers.5/Shape_13_output_0, %/text_encoder/encoder/attn_layers.5/Constant_123_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_124_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_124"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Sub_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub_8"](%/text_encoder/encoder/attn_layers.5/Constant_124_output_0, %/text_encoder/encoder/attn_layers.5/Gather_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_8_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_8"](%/text_encoder/encoder/attn_layers.5/Concat_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/ConstantOfShape_4_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/ConstantOfShape_4"](%/text_encoder/encoder/attn_layers.5/Sub_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Concat_20_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_20"](%/text_encoder/encoder/attn_layers.5/Cast_8_output_0, %/text_encoder/encoder/attn_layers.5/ConstantOfShape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_125_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.5/Constant_125"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_14_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_14"](%/text_encoder/encoder/attn_layers.5/Concat_20_output_0, %/text_encoder/encoder/attn_layers.5/Constant_125_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_126_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_126"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_127_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_127"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_128_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_128"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_129_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_129"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Slice_7_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_7"](%/text_encoder/encoder/attn_layers.5/Reshape_14_output_0, %/text_encoder/encoder/attn_layers.5/Constant_127_output_0, %/text_encoder/encoder/attn_layers.5/Constant_128_output_0, %/text_encoder/encoder/attn_layers.5/Constant_126_output_0, %/text_encoder/encoder/attn_layers.5/Constant_129_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Transpose_7_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose_7"](%/text_encoder/encoder/attn_layers.5/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_130_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_130"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_15_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_15"](%/text_encoder/encoder/attn_layers.5/Transpose_7_output_0, %/text_encoder/encoder/attn_layers.5/Constant_130_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_9_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_9"](%/text_encoder/encoder/attn_layers.5/Reshape_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Pad_4_output_0 : Float(*, *, *, strides=[40000, 20000, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.5/Pad_4"](%/text_encoder/encoder/attn_layers.5/Reshape_13_output_0, %/text_encoder/encoder/attn_layers.5/Cast_9_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_131_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_131"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.5/Mul_4_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/attn_layers.5/Mul_4"](%/text_encoder/encoder/attn_layers.5/Gather_11_output_0, %/text_encoder/encoder/attn_layers.5/Constant_131_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %onnx::Unsqueeze_4043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_34"](%/text_encoder/encoder/attn_layers.5/Gather_9_output_0, %onnx::Unsqueeze_4043), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_4045 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_35_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_35"](%/text_encoder/encoder/attn_layers.5/Gather_10_output_0, %onnx::Unsqueeze_4045), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_4047 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_36"](%/text_encoder/encoder/attn_layers.5/Gather_11_output_0, %onnx::Unsqueeze_4047), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_4049 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_37"](%/text_encoder/encoder/attn_layers.5/Mul_4_output_0, %onnx::Unsqueeze_4049), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_21_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_21"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_34_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_35_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_36_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.5/Reshape_16_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_16"](%/text_encoder/encoder/attn_layers.5/Pad_4_output_0, %/text_encoder/encoder/attn_layers.5/Concat_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.5/Constant_132_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_132"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.5/Constant_133_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_133"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.5/Constant_134_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_134"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.5/Constant_135_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_135"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.5/Slice_8_output_0 : Float(*, *, *, *, strides=[40000, 20000, 200, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_8"](%/text_encoder/encoder/attn_layers.5/Reshape_16_output_0, %/text_encoder/encoder/attn_layers.5/Constant_133_output_0, %/text_encoder/encoder/attn_layers.5/Constant_134_output_0, %/text_encoder/encoder/attn_layers.5/Constant_132_output_0, %/text_encoder/encoder/attn_layers.5/Constant_135_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:240:0
  %/text_encoder/encoder/attn_layers.5/Constant_136_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_136"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/text_encoder/encoder/attn_layers.5/Shape_14"](%/text_encoder/encoder/attn_layers.5/Concat_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Gather_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Gather_14"](%/text_encoder/encoder/attn_layers.5/Shape_14_output_0, %/text_encoder/encoder/attn_layers.5/Constant_136_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_137_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_137"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Sub_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/attn_layers.5/Sub_9"](%/text_encoder/encoder/attn_layers.5/Constant_137_output_0, %/text_encoder/encoder/attn_layers.5/Gather_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_10_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_10"](%/text_encoder/encoder/attn_layers.5/Concat_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/ConstantOfShape_5_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/ConstantOfShape_5"](%/text_encoder/encoder/attn_layers.5/Sub_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Concat_22_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_22"](%/text_encoder/encoder/attn_layers.5/Cast_10_output_0, %/text_encoder/encoder/attn_layers.5/ConstantOfShape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_138_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/attn_layers.5/Constant_138"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_17_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_17"](%/text_encoder/encoder/attn_layers.5/Concat_22_output_0, %/text_encoder/encoder/attn_layers.5/Constant_138_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_139_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_139"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_140_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_140"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_141"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_142_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_142"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Slice_9_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_9"](%/text_encoder/encoder/attn_layers.5/Reshape_17_output_0, %/text_encoder/encoder/attn_layers.5/Constant_140_output_0, %/text_encoder/encoder/attn_layers.5/Constant_141_output_0, %/text_encoder/encoder/attn_layers.5/Constant_139_output_0, %/text_encoder/encoder/attn_layers.5/Constant_142_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Transpose_8_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose_8"](%/text_encoder/encoder/attn_layers.5/Slice_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_143"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Reshape_18_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_18"](%/text_encoder/encoder/attn_layers.5/Transpose_8_output_0, %/text_encoder/encoder/attn_layers.5/Constant_143_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Cast_11_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/attn_layers.5/Cast_11"](%/text_encoder/encoder/attn_layers.5/Reshape_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Pad_5_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/attn_layers.5/Pad_5"](%text_encoder.encoder.attn_layers.5.emb_rel_v, %/text_encoder/encoder/attn_layers.5/Cast_11_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/attn_layers.5/Constant_144_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_144"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Constant_145_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_145"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Constant_146_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_146"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_38"](%/text_encoder/encoder/attn_layers.5/Sub_1_output_0, %/text_encoder/encoder/attn_layers.5/Constant_146_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Constant_147_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_147"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Slice_10_output_0 : Float(*, *, *, strides=[19104, 96, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/attn_layers.5/Slice_10"](%/text_encoder/encoder/attn_layers.5/Pad_5_output_0, %/text_encoder/encoder/attn_layers.5/Constant_145_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_38_output_0, %/text_encoder/encoder/attn_layers.5/Constant_144_output_0, %/text_encoder/encoder/attn_layers.5/Constant_147_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:206:0
  %/text_encoder/encoder/attn_layers.5/Constant_148_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/attn_layers.5/Constant_148"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_39_output_0 : Float(1, *, *, *, strides=[19104, 19104, 96, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_39"](%/text_encoder/encoder/attn_layers.5/Slice_10_output_0, %/text_encoder/encoder/attn_layers.5/Constant_148_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.5/MatMul_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/text_encoder/encoder/attn_layers.5/MatMul_3"](%/text_encoder/encoder/attn_layers.5/Slice_8_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:177:0
  %/text_encoder/encoder/attn_layers.5/Add_3_output_0 : Float(*, *, *, *, strides=[19200, 9600, 96, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/attn_layers.5/Add_3"](%/text_encoder/encoder/attn_layers.5/MatMul_2_output_0, %/text_encoder/encoder/attn_layers.5/MatMul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:161:0
  %/text_encoder/encoder/attn_layers.5/Transpose_9_output_0 : Float(*, *, *, *, strides=[19200, 9600, 100, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/text_encoder/encoder/attn_layers.5/Transpose_9"](%/text_encoder/encoder/attn_layers.5/Add_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %onnx::Unsqueeze_4098 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_40"](%/text_encoder/encoder/attn_layers.5/Gather_output_0, %onnx::Unsqueeze_4098), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_4100 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_41_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_41"](%/text_encoder/encoder/attn_layers.5/Gather_1_output_0, %onnx::Unsqueeze_4100), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %onnx::Unsqueeze_4102 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/text_encoder/encoder/attn_layers.5/Unsqueeze_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/text_encoder/encoder/attn_layers.5/Unsqueeze_42"](%/text_encoder/encoder/attn_layers.5/Gather_3_output_0, %onnx::Unsqueeze_4102), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5
  %/text_encoder/encoder/attn_layers.5/Concat_23_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/attn_layers.5/Concat_23"](%/text_encoder/encoder/attn_layers.5/Unsqueeze_40_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_41_output_0, %/text_encoder/encoder/attn_layers.5/Unsqueeze_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.5/Reshape_19_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/attn_layers.5/Reshape_19"](%/text_encoder/encoder/attn_layers.5/Transpose_9_output_0, %/text_encoder/encoder/attn_layers.5/Concat_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:162:0
  %/text_encoder/encoder/attn_layers.5/conv_o/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/attn_layers.5/conv_o/Conv"](%/text_encoder/encoder/attn_layers.5/Reshape_19_output_0, %text_encoder.encoder.attn_layers.5.conv_o.weight, %text_encoder.encoder.attn_layers.5.conv_o.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionMultiHeadAttention::attn_layers.5/torch.nn.modules.conv.Conv1d::conv_o # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/Add_10_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_10"](%/text_encoder/encoder/Mul_6_output_0, %/text_encoder/encoder/attn_layers.5/conv_o/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:422:0
  %/text_encoder/encoder/norm_layers_1.5/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.5/Transpose"](%/text_encoder/encoder/Add_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_1.5/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.5/ReduceMean"](%/text_encoder/encoder/norm_layers_1.5/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_1.5/Sub"](%/text_encoder/encoder/norm_layers_1.5/Transpose_output_0, %/text_encoder/encoder/norm_layers_1.5/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_1.5/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_1.5/Pow"](%/text_encoder/encoder/norm_layers_1.5/Sub_output_0, %/text_encoder/encoder/norm_layers_1.5/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_1.5/ReduceMean_1"](%/text_encoder/encoder/norm_layers_1.5/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_1.5/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.5/Add"](%/text_encoder/encoder/norm_layers_1.5/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_1.5/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_1.5/Sqrt"](%/text_encoder/encoder/norm_layers_1.5/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_1.5/Div"](%/text_encoder/encoder/norm_layers_1.5/Sub_output_0, %/text_encoder/encoder/norm_layers_1.5/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_1.5/Mul"](%/text_encoder/encoder/norm_layers_1.5/Div_output_0, %text_encoder.encoder.norm_layers_1.5.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_1.5/Add_1"](%/text_encoder/encoder/norm_layers_1.5/Mul_output_0, %text_encoder.encoder.norm_layers_1.5.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_1.5/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_1.5/Transpose_1"](%/text_encoder/encoder/norm_layers_1.5/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_1.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/ffn_layers.5/Mul_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.5/Mul"](%/text_encoder/encoder/norm_layers_1.5/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:291:0
  %/text_encoder/encoder/ffn_layers.5/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_1_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.5/ConstantOfShape"](%/text_encoder/encoder/ffn_layers.5/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Concat_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.5/Concat"](%/text_encoder/encoder/ffn_layers.5/Constant_1_output_0, %/text_encoder/encoder/ffn_layers.5/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_2_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Reshape_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.5/Reshape"](%/text_encoder/encoder/ffn_layers.5/Concat_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.5/Slice"](%/text_encoder/encoder/ffn_layers.5/Reshape_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_4_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_5_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_3_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Transpose_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.5/Transpose"](%/text_encoder/encoder/ffn_layers.5/Slice_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Reshape_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.5/Reshape_1"](%/text_encoder/encoder/ffn_layers.5/Transpose_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Cast_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.5/Cast"](%/text_encoder/encoder/ffn_layers.5/Reshape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Pad_output_0 : Float(*, *, *, strides=[19584, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.5/Pad"](%/text_encoder/encoder/ffn_layers.5/Mul_output_0, %/text_encoder/encoder/ffn_layers.5/Cast_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/conv_1/Conv_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.5/conv_1/Conv"](%/text_encoder/encoder/ffn_layers.5/Pad_output_0, %text_encoder.encoder.ffn_layers.5.conv_1.weight, %text_encoder.encoder.ffn_layers.5.conv_1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5/torch.nn.modules.conv.Conv1d::conv_1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.5/Relu_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Relu[onnx_name="/text_encoder/encoder/ffn_layers.5/Relu"](%/text_encoder/encoder/ffn_layers.5/conv_1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:292:0
  %/text_encoder/encoder/ffn_layers.5/Mul_1_output_0 : Float(*, 768, *, strides=[76800, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.5/Mul_1"](%/text_encoder/encoder/ffn_layers.5/Relu_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:294:0
  %/text_encoder/encoder/ffn_layers.5/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_9_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1  0  0  0  0 [ CPULongType{6} ], onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/ConstantOfShape_1_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.5/ConstantOfShape_1"](%/text_encoder/encoder/ffn_layers.5/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Concat_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/text_encoder/encoder/ffn_layers.5/Concat_1"](%/text_encoder/encoder/ffn_layers.5/Constant_9_output_0, %/text_encoder/encoder/ffn_layers.5/ConstantOfShape_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Reshape_2_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.5/Reshape_2"](%/text_encoder/encoder/ffn_layers.5/Concat_1_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Slice_1_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/text_encoder/encoder/ffn_layers.5/Slice_1"](%/text_encoder/encoder/ffn_layers.5/Reshape_2_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_12_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_13_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_11_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Transpose_1_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/text_encoder/encoder/ffn_layers.5/Transpose_1"](%/text_encoder/encoder/ffn_layers.5/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/text_encoder/encoder/ffn_layers.5/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Reshape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/text_encoder/encoder/ffn_layers.5/Reshape_3"](%/text_encoder/encoder/ffn_layers.5/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.5/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Cast_1_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/text_encoder/encoder/ffn_layers.5/Cast_1"](%/text_encoder/encoder/ffn_layers.5/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/Pad_1_output_0 : Float(*, *, *, strides=[78336, 102, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/text_encoder/encoder/ffn_layers.5/Pad_1"](%/text_encoder/encoder/ffn_layers.5/Mul_1_output_0, %/text_encoder/encoder/ffn_layers.5/Cast_1_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/text_encoder/encoder/ffn_layers.5/conv_2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[0, 0], strides=[1], onnx_name="/text_encoder/encoder/ffn_layers.5/conv_2/Conv"](%/text_encoder/encoder/ffn_layers.5/Pad_1_output_0, %text_encoder.encoder.ffn_layers.5.conv_2.weight, %text_encoder.encoder.ffn_layers.5.conv_2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5/torch.nn.modules.conv.Conv1d::conv_2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/encoder/ffn_layers.5/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/ffn_layers.5/Mul_2"](%/text_encoder/encoder/ffn_layers.5/conv_2/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.glow_tts.transformer.FeedForwardNetwork::ffn_layers.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:295:0
  %/text_encoder/encoder/Add_11_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/Add_11"](%/text_encoder/encoder/norm_layers_1.5/Transpose_1_output_0, %/text_encoder/encoder/ffn_layers.5/Mul_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:430:0
  %/text_encoder/encoder/norm_layers_2.5/Transpose_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.5/Transpose"](%/text_encoder/encoder/Add_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/text_encoder/encoder/norm_layers_2.5/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.5/ReduceMean"](%/text_encoder/encoder/norm_layers_2.5/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/text_encoder/encoder/norm_layers_2.5/Sub"](%/text_encoder/encoder/norm_layers_2.5/Transpose_output_0, %/text_encoder/encoder/norm_layers_2.5/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/text_encoder/encoder/norm_layers_2.5/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/text_encoder/encoder/norm_layers_2.5/Pow"](%/text_encoder/encoder/norm_layers_2.5/Sub_output_0, %/text_encoder/encoder/norm_layers_2.5/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/text_encoder/encoder/norm_layers_2.5/ReduceMean_1"](%/text_encoder/encoder/norm_layers_2.5/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/text_encoder/encoder/norm_layers_2.5/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.5/Add"](%/text_encoder/encoder/norm_layers_2.5/ReduceMean_1_output_0, %/text_encoder/encoder/norm_layers_2.5/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/text_encoder/encoder/norm_layers_2.5/Sqrt"](%/text_encoder/encoder/norm_layers_2.5/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/text_encoder/encoder/norm_layers_2.5/Div"](%/text_encoder/encoder/norm_layers_2.5/Sub_output_0, %/text_encoder/encoder/norm_layers_2.5/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/norm_layers_2.5/Mul"](%/text_encoder/encoder/norm_layers_2.5/Div_output_0, %text_encoder.encoder.norm_layers_2.5.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/text_encoder/encoder/norm_layers_2.5/Add_1"](%/text_encoder/encoder/norm_layers_2.5/Mul_output_0, %text_encoder.encoder.norm_layers_2.5.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/text_encoder/encoder/norm_layers_2.5/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/text_encoder/encoder/norm_layers_2.5/Transpose_1"](%/text_encoder/encoder/norm_layers_2.5/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder/TTS.tts.layers.generic.normalization.LayerNorm2::norm_layers_2.5 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/text_encoder/encoder/Mul_7_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/encoder/Mul_7"](%/text_encoder/encoder/norm_layers_2.5/Transpose_1_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/TTS.tts.layers.glow_tts.transformer.RelativePositionTransformer::encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/glow_tts/transformer.py:431:0
  %/text_encoder/proj/Conv_output_0 : Float(*, 384, *, strides=[38400, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/text_encoder/proj/Conv"](%/text_encoder/encoder/Mul_7_output_0, %text_encoder.proj.weight, %text_encoder.proj.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder/torch.nn.modules.conv.Conv1d::proj # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/text_encoder/Mul_2_output_0 : Float(*, 384, *, strides=[38400, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/text_encoder/Mul_2"](%/text_encoder/proj/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:97:0
  %/text_encoder/Constant_7_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 192  192 [ CPULongType{2} ], onnx_name="/text_encoder/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:915:0
  %/text_encoder/Split_output_0 : Float(*, 192, *, strides=[38400, 100, 1], requires_grad=0, device=cpu), %/text_encoder/Split_output_1 : Float(*, 192, *, strides=[38400, 100, 1], requires_grad=0, device=cpu) = onnx::Split[axis=1, onnx_name="/text_encoder/Split"](%/text_encoder/Mul_2_output_0, %/text_encoder/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.TextEncoder::text_encoder # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:915:0
  %/duration_predictor/pre/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/pre/Conv"](%/text_encoder/encoder/Mul_7_output_0, %duration_predictor.pre.weight, %duration_predictor.pre.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/torch.nn.modules.conv.Conv1d::pre # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/cond/Conv_output_0 : Float(1, 192, 1, strides=[192, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/cond/Conv"](%/Unsqueeze_output_0, %duration_predictor.cond.weight, %duration_predictor.cond.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/torch.nn.modules.conv.Conv1d::cond # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/Add_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/Add"](%/duration_predictor/pre/Conv_output_0, %/duration_predictor/cond/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:233:0
  %/duration_predictor/convs/Mul_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul"](%/duration_predictor/Add_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/convs/convs_sep.0/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=192, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/duration_predictor/convs/convs_sep.0/Conv"](%/duration_predictor/convs/Mul_output_0, %duration_predictor.convs.convs_sep.0.weight, %duration_predictor.convs.convs_sep.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/convs/norms_1.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_1.0/Transpose"](%/duration_predictor/convs/convs_sep.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/convs/norms_1.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_1.0/ReduceMean"](%/duration_predictor/convs/norms_1.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/convs/norms_1.0/Sub"](%/duration_predictor/convs/norms_1.0/Transpose_output_0, %/duration_predictor/convs/norms_1.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/convs/norms_1.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/convs/norms_1.0/Pow"](%/duration_predictor/convs/norms_1.0/Sub_output_0, %/duration_predictor/convs/norms_1.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_1.0/ReduceMean_1"](%/duration_predictor/convs/norms_1.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/convs/norms_1.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_1.0/Add"](%/duration_predictor/convs/norms_1.0/ReduceMean_1_output_0, %/duration_predictor/convs/norms_1.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/convs/norms_1.0/Sqrt"](%/duration_predictor/convs/norms_1.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/norms_1.0/Div"](%/duration_predictor/convs/norms_1.0/Sub_output_0, %/duration_predictor/convs/norms_1.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/norms_1.0/Mul"](%/duration_predictor/convs/norms_1.0/Div_output_0, %duration_predictor.convs.norms_1.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_1.0/Add_1"](%/duration_predictor/convs/norms_1.0/Mul_output_0, %duration_predictor.convs.norms_1.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_1.0/Transpose_1"](%/duration_predictor/convs/norms_1.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/convs/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/convs/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Div_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/Div"](%/duration_predictor/convs/norms_1.0/Transpose_1_output_0, %/duration_predictor/convs/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Erf_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/convs/Erf"](%/duration_predictor/convs/Div_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/convs/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Add_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/Add"](%/duration_predictor/convs/Erf_output_0, %/duration_predictor/convs/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Mul_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_1"](%/duration_predictor/convs/norms_1.0/Transpose_1_output_0, %/duration_predictor/convs/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/convs/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_2"](%/duration_predictor/convs/Mul_1_output_0, %/duration_predictor/convs/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/convs_1x1.0/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/convs/convs_1x1.0/Conv"](%/duration_predictor/convs/Mul_2_output_0, %duration_predictor.convs.convs_1x1.0.weight, %duration_predictor.convs.convs_1x1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/convs/norms_2.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_2.0/Transpose"](%/duration_predictor/convs/convs_1x1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/convs/norms_2.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_2.0/ReduceMean"](%/duration_predictor/convs/norms_2.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/convs/norms_2.0/Sub"](%/duration_predictor/convs/norms_2.0/Transpose_output_0, %/duration_predictor/convs/norms_2.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/convs/norms_2.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/convs/norms_2.0/Pow"](%/duration_predictor/convs/norms_2.0/Sub_output_0, %/duration_predictor/convs/norms_2.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_2.0/ReduceMean_1"](%/duration_predictor/convs/norms_2.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/convs/norms_2.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_2.0/Add"](%/duration_predictor/convs/norms_2.0/ReduceMean_1_output_0, %/duration_predictor/convs/norms_2.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/convs/norms_2.0/Sqrt"](%/duration_predictor/convs/norms_2.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/norms_2.0/Div"](%/duration_predictor/convs/norms_2.0/Sub_output_0, %/duration_predictor/convs/norms_2.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/norms_2.0/Mul"](%/duration_predictor/convs/norms_2.0/Div_output_0, %duration_predictor.convs.norms_2.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_2.0/Add_1"](%/duration_predictor/convs/norms_2.0/Mul_output_0, %duration_predictor.convs.norms_2.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_2.0/Transpose_1"](%/duration_predictor/convs/norms_2.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/convs/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/convs/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Div_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/Div_1"](%/duration_predictor/convs/norms_2.0/Transpose_1_output_0, %/duration_predictor/convs/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Erf_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/convs/Erf_1"](%/duration_predictor/convs/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Constant_4_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/convs/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Add_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/Add_1"](%/duration_predictor/convs/Erf_1_output_0, %/duration_predictor/convs/Constant_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Mul_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_3"](%/duration_predictor/convs/norms_2.0/Transpose_1_output_0, %/duration_predictor/convs/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Constant_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/convs/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Mul_4_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_4"](%/duration_predictor/convs/Mul_3_output_0, %/duration_predictor/convs/Constant_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Add_2_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/Add_2"](%/duration_predictor/Add_output_0, %/duration_predictor/convs/Mul_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/convs/Mul_5_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_5"](%/duration_predictor/convs/Add_2_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/convs/convs_sep.1/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=192, kernel_shape=[3], pads=[3, 3], strides=[1], onnx_name="/duration_predictor/convs/convs_sep.1/Conv"](%/duration_predictor/convs/Mul_5_output_0, %duration_predictor.convs.convs_sep.1.weight, %duration_predictor.convs.convs_sep.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/convs/norms_1.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_1.1/Transpose"](%/duration_predictor/convs/convs_sep.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/convs/norms_1.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_1.1/ReduceMean"](%/duration_predictor/convs/norms_1.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/convs/norms_1.1/Sub"](%/duration_predictor/convs/norms_1.1/Transpose_output_0, %/duration_predictor/convs/norms_1.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/convs/norms_1.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/convs/norms_1.1/Pow"](%/duration_predictor/convs/norms_1.1/Sub_output_0, %/duration_predictor/convs/norms_1.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_1.1/ReduceMean_1"](%/duration_predictor/convs/norms_1.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/convs/norms_1.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_1.1/Add"](%/duration_predictor/convs/norms_1.1/ReduceMean_1_output_0, %/duration_predictor/convs/norms_1.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/convs/norms_1.1/Sqrt"](%/duration_predictor/convs/norms_1.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/norms_1.1/Div"](%/duration_predictor/convs/norms_1.1/Sub_output_0, %/duration_predictor/convs/norms_1.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/norms_1.1/Mul"](%/duration_predictor/convs/norms_1.1/Div_output_0, %duration_predictor.convs.norms_1.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_1.1/Add_1"](%/duration_predictor/convs/norms_1.1/Mul_output_0, %duration_predictor.convs.norms_1.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_1.1/Transpose_1"](%/duration_predictor/convs/norms_1.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/convs/Constant_6_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/convs/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Div_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/Div_2"](%/duration_predictor/convs/norms_1.1/Transpose_1_output_0, %/duration_predictor/convs/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Erf_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/convs/Erf_2"](%/duration_predictor/convs/Div_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/convs/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Add_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/Add_3"](%/duration_predictor/convs/Erf_2_output_0, %/duration_predictor/convs/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Mul_6_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_6"](%/duration_predictor/convs/norms_1.1/Transpose_1_output_0, %/duration_predictor/convs/Add_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/convs/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Mul_7_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_7"](%/duration_predictor/convs/Mul_6_output_0, %/duration_predictor/convs/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/convs_1x1.1/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/convs/convs_1x1.1/Conv"](%/duration_predictor/convs/Mul_7_output_0, %duration_predictor.convs.convs_1x1.1.weight, %duration_predictor.convs.convs_1x1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/convs/norms_2.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_2.1/Transpose"](%/duration_predictor/convs/convs_1x1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/convs/norms_2.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_2.1/ReduceMean"](%/duration_predictor/convs/norms_2.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/convs/norms_2.1/Sub"](%/duration_predictor/convs/norms_2.1/Transpose_output_0, %/duration_predictor/convs/norms_2.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/convs/norms_2.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/convs/norms_2.1/Pow"](%/duration_predictor/convs/norms_2.1/Sub_output_0, %/duration_predictor/convs/norms_2.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_2.1/ReduceMean_1"](%/duration_predictor/convs/norms_2.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/convs/norms_2.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_2.1/Add"](%/duration_predictor/convs/norms_2.1/ReduceMean_1_output_0, %/duration_predictor/convs/norms_2.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/convs/norms_2.1/Sqrt"](%/duration_predictor/convs/norms_2.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/norms_2.1/Div"](%/duration_predictor/convs/norms_2.1/Sub_output_0, %/duration_predictor/convs/norms_2.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/norms_2.1/Mul"](%/duration_predictor/convs/norms_2.1/Div_output_0, %duration_predictor.convs.norms_2.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_2.1/Add_1"](%/duration_predictor/convs/norms_2.1/Mul_output_0, %duration_predictor.convs.norms_2.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_2.1/Transpose_1"](%/duration_predictor/convs/norms_2.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/convs/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/convs/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Div_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/Div_3"](%/duration_predictor/convs/norms_2.1/Transpose_1_output_0, %/duration_predictor/convs/Constant_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Erf_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/convs/Erf_3"](%/duration_predictor/convs/Div_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/convs/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Add_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/Add_4"](%/duration_predictor/convs/Erf_3_output_0, %/duration_predictor/convs/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Mul_8_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_8"](%/duration_predictor/convs/norms_2.1/Transpose_1_output_0, %/duration_predictor/convs/Add_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Constant_11_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/convs/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Mul_9_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_9"](%/duration_predictor/convs/Mul_8_output_0, %/duration_predictor/convs/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Add_5_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/Add_5"](%/duration_predictor/convs/Add_2_output_0, %/duration_predictor/convs/Mul_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/convs/Mul_10_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_10"](%/duration_predictor/convs/Add_5_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/convs/convs_sep.2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[9], group=192, kernel_shape=[3], pads=[9, 9], strides=[1], onnx_name="/duration_predictor/convs/convs_sep.2/Conv"](%/duration_predictor/convs/Mul_10_output_0, %duration_predictor.convs.convs_sep.2.weight, %duration_predictor.convs.convs_sep.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/convs/norms_1.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_1.2/Transpose"](%/duration_predictor/convs/convs_sep.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/convs/norms_1.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_1.2/ReduceMean"](%/duration_predictor/convs/norms_1.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/convs/norms_1.2/Sub"](%/duration_predictor/convs/norms_1.2/Transpose_output_0, %/duration_predictor/convs/norms_1.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/convs/norms_1.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/convs/norms_1.2/Pow"](%/duration_predictor/convs/norms_1.2/Sub_output_0, %/duration_predictor/convs/norms_1.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_1.2/ReduceMean_1"](%/duration_predictor/convs/norms_1.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/convs/norms_1.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_1.2/Add"](%/duration_predictor/convs/norms_1.2/ReduceMean_1_output_0, %/duration_predictor/convs/norms_1.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/convs/norms_1.2/Sqrt"](%/duration_predictor/convs/norms_1.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/norms_1.2/Div"](%/duration_predictor/convs/norms_1.2/Sub_output_0, %/duration_predictor/convs/norms_1.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/norms_1.2/Mul"](%/duration_predictor/convs/norms_1.2/Div_output_0, %duration_predictor.convs.norms_1.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_1.2/Add_1"](%/duration_predictor/convs/norms_1.2/Mul_output_0, %duration_predictor.convs.norms_1.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_1.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_1.2/Transpose_1"](%/duration_predictor/convs/norms_1.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/convs/Constant_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/convs/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Div_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/Div_4"](%/duration_predictor/convs/norms_1.2/Transpose_1_output_0, %/duration_predictor/convs/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Erf_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/convs/Erf_4"](%/duration_predictor/convs/Div_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/convs/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Add_6_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/Add_6"](%/duration_predictor/convs/Erf_4_output_0, %/duration_predictor/convs/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Mul_11_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_11"](%/duration_predictor/convs/norms_1.2/Transpose_1_output_0, %/duration_predictor/convs/Add_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/convs/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/Mul_12_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_12"](%/duration_predictor/convs/Mul_11_output_0, %/duration_predictor/convs/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/convs/convs_1x1.2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/convs/convs_1x1.2/Conv"](%/duration_predictor/convs/Mul_12_output_0, %duration_predictor.convs.convs_1x1.2.weight, %duration_predictor.convs.convs_1x1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/convs/norms_2.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_2.2/Transpose"](%/duration_predictor/convs/convs_1x1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/convs/norms_2.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_2.2/ReduceMean"](%/duration_predictor/convs/norms_2.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/convs/norms_2.2/Sub"](%/duration_predictor/convs/norms_2.2/Transpose_output_0, %/duration_predictor/convs/norms_2.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/convs/norms_2.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/convs/norms_2.2/Pow"](%/duration_predictor/convs/norms_2.2/Sub_output_0, %/duration_predictor/convs/norms_2.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/convs/norms_2.2/ReduceMean_1"](%/duration_predictor/convs/norms_2.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/convs/norms_2.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_2.2/Add"](%/duration_predictor/convs/norms_2.2/ReduceMean_1_output_0, %/duration_predictor/convs/norms_2.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/convs/norms_2.2/Sqrt"](%/duration_predictor/convs/norms_2.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/norms_2.2/Div"](%/duration_predictor/convs/norms_2.2/Sub_output_0, %/duration_predictor/convs/norms_2.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/norms_2.2/Mul"](%/duration_predictor/convs/norms_2.2/Div_output_0, %duration_predictor.convs.norms_2.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/norms_2.2/Add_1"](%/duration_predictor/convs/norms_2.2/Mul_output_0, %duration_predictor.convs.norms_2.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/convs/norms_2.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/convs/norms_2.2/Transpose_1"](%/duration_predictor/convs/norms_2.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/convs/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/convs/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Div_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/convs/Div_5"](%/duration_predictor/convs/norms_2.2/Transpose_1_output_0, %/duration_predictor/convs/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Erf_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/convs/Erf_5"](%/duration_predictor/convs/Div_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/convs/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Add_7_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/Add_7"](%/duration_predictor/convs/Erf_5_output_0, %/duration_predictor/convs/Constant_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Mul_13_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_13"](%/duration_predictor/convs/norms_2.2/Transpose_1_output_0, %/duration_predictor/convs/Add_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Constant_17_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/convs/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Mul_14_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_14"](%/duration_predictor/convs/Mul_13_output_0, %/duration_predictor/convs/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/convs/Add_8_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/convs/Add_8"](%/duration_predictor/convs/Add_5_output_0, %/duration_predictor/convs/Mul_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/convs/Mul_15_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/convs/Mul_15"](%/duration_predictor/convs/Add_8_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:63:0
  %/duration_predictor/proj/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/proj/Conv"](%/duration_predictor/convs/Mul_15_output_0, %duration_predictor.proj.weight, %duration_predictor.proj.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/torch.nn.modules.conv.Conv1d::proj # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/Mul_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/Mul"](%/duration_predictor/proj/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:239:0
  %/duration_predictor/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/Shape"](%/duration_predictor/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/Gather"](%/duration_predictor/Shape_output_0, %/duration_predictor/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/Shape_1"](%/duration_predictor/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/Gather_1"](%/duration_predictor/Shape_1_output_0, %/duration_predictor/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %onnx::Unsqueeze_4342 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/Unsqueeze"](%/duration_predictor/Gather_output_0, %onnx::Unsqueeze_4342), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor
  %/duration_predictor/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor
  %onnx::Unsqueeze_4346 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/Unsqueeze_1"](%/duration_predictor/Gather_1_output_0, %onnx::Unsqueeze_4346), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor
  %/duration_predictor/Concat_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/Concat"](%/duration_predictor/Unsqueeze_output_0, %/duration_predictor/Constant_2_output_0, %/duration_predictor/Unsqueeze_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/ConstantOfShape_output_0 : Float(*, *, *, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/ConstantOfShape"](%/duration_predictor/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/RandomNormalLike_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::RandomNormalLike[dtype=1, onnx_name="/duration_predictor/RandomNormalLike"](%/duration_predictor/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/Cast_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name="/duration_predictor/Cast"](%/duration_predictor/RandomNormalLike_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.8}, onnx_name="/duration_predictor/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/Mul_1_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/Mul_1"](%/duration_predictor/Cast_output_0, %/duration_predictor/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:287:0
  %/duration_predictor/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Slice_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/Slice"](%/duration_predictor/Mul_1_output_0, %/duration_predictor/Constant_5_output_0, %/duration_predictor/Constant_6_output_0, %/duration_predictor/Constant_4_output_0, %/duration_predictor/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %onnx::Split_4359 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ]]()
  %/duration_predictor/flows.4/Split_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu), %/duration_predictor/flows.4/Split_output_1 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Split[axis=1, onnx_name="/duration_predictor/flows.4/Split"](%/duration_predictor/Slice_output_0, %onnx::Split_4359), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:917:0
  %/duration_predictor/flows.4/pre/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.4/pre/Conv"](%/duration_predictor/flows.4/Split_output_0, %duration_predictor.flows.4.pre.weight, %duration_predictor.flows.4.pre.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/torch.nn.modules.conv.Conv1d::pre # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.4/convs/Add_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add"](%/duration_predictor/flows.4/pre/Conv_output_0, %/duration_predictor/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:53:0
  %/duration_predictor/flows.4/convs/Mul_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul"](%/duration_predictor/flows.4/convs/Add_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/flows.4/convs/convs_sep.0/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=192, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/duration_predictor/flows.4/convs/convs_sep.0/Conv"](%/duration_predictor/flows.4/convs/Mul_output_0, %duration_predictor.flows.4.convs.convs_sep.0.weight, %duration_predictor.flows.4.convs.convs_sep.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.4/convs/norms_1.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Transpose"](%/duration_predictor/flows.4/convs/convs_sep.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.4/convs/norms_1.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_1.0/ReduceMean"](%/duration_predictor/flows.4/convs/norms_1.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Sub"](%/duration_predictor/flows.4/convs/norms_1.0/Transpose_output_0, %/duration_predictor/flows.4/convs/norms_1.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Pow"](%/duration_predictor/flows.4/convs/norms_1.0/Sub_output_0, %/duration_predictor/flows.4/convs/norms_1.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_1.0/ReduceMean_1"](%/duration_predictor/flows.4/convs/norms_1.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Add"](%/duration_predictor/flows.4/convs/norms_1.0/ReduceMean_1_output_0, %/duration_predictor/flows.4/convs/norms_1.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Sqrt"](%/duration_predictor/flows.4/convs/norms_1.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Div"](%/duration_predictor/flows.4/convs/norms_1.0/Sub_output_0, %/duration_predictor/flows.4/convs/norms_1.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Mul"](%/duration_predictor/flows.4/convs/norms_1.0/Div_output_0, %duration_predictor.flows.4.convs.norms_1.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Add_1"](%/duration_predictor/flows.4/convs/norms_1.0/Mul_output_0, %duration_predictor.flows.4.convs.norms_1.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_1.0/Transpose_1"](%/duration_predictor/flows.4/convs/norms_1.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.4/convs/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.4/convs/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Div_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/Div"](%/duration_predictor/flows.4/convs/norms_1.0/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Erf_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.4/convs/Erf"](%/duration_predictor/flows.4/convs/Div_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/convs/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Add_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add_1"](%/duration_predictor/flows.4/convs/Erf_output_0, %/duration_predictor/flows.4/convs/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Mul_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_1"](%/duration_predictor/flows.4/convs/norms_1.0/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.4/convs/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_2"](%/duration_predictor/flows.4/convs/Mul_1_output_0, %/duration_predictor/flows.4/convs/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/convs_1x1.0/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.4/convs/convs_1x1.0/Conv"](%/duration_predictor/flows.4/convs/Mul_2_output_0, %duration_predictor.flows.4.convs.convs_1x1.0.weight, %duration_predictor.flows.4.convs.convs_1x1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.4/convs/norms_2.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Transpose"](%/duration_predictor/flows.4/convs/convs_1x1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.4/convs/norms_2.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_2.0/ReduceMean"](%/duration_predictor/flows.4/convs/norms_2.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Sub"](%/duration_predictor/flows.4/convs/norms_2.0/Transpose_output_0, %/duration_predictor/flows.4/convs/norms_2.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Pow"](%/duration_predictor/flows.4/convs/norms_2.0/Sub_output_0, %/duration_predictor/flows.4/convs/norms_2.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_2.0/ReduceMean_1"](%/duration_predictor/flows.4/convs/norms_2.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Add"](%/duration_predictor/flows.4/convs/norms_2.0/ReduceMean_1_output_0, %/duration_predictor/flows.4/convs/norms_2.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Sqrt"](%/duration_predictor/flows.4/convs/norms_2.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Div"](%/duration_predictor/flows.4/convs/norms_2.0/Sub_output_0, %/duration_predictor/flows.4/convs/norms_2.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Mul"](%/duration_predictor/flows.4/convs/norms_2.0/Div_output_0, %duration_predictor.flows.4.convs.norms_2.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Add_1"](%/duration_predictor/flows.4/convs/norms_2.0/Mul_output_0, %duration_predictor.flows.4.convs.norms_2.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_2.0/Transpose_1"](%/duration_predictor/flows.4/convs/norms_2.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.4/convs/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.4/convs/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Div_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/Div_1"](%/duration_predictor/flows.4/convs/norms_2.0/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Erf_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.4/convs/Erf_1"](%/duration_predictor/flows.4/convs/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Constant_4_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/convs/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Add_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add_2"](%/duration_predictor/flows.4/convs/Erf_1_output_0, %/duration_predictor/flows.4/convs/Constant_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Mul_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_3"](%/duration_predictor/flows.4/convs/norms_2.0/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Constant_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.4/convs/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Mul_4_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_4"](%/duration_predictor/flows.4/convs/Mul_3_output_0, %/duration_predictor/flows.4/convs/Constant_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Add_3_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add_3"](%/duration_predictor/flows.4/convs/Add_output_0, %/duration_predictor/flows.4/convs/Mul_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/flows.4/convs/Mul_5_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_5"](%/duration_predictor/flows.4/convs/Add_3_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/flows.4/convs/convs_sep.1/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=192, kernel_shape=[3], pads=[3, 3], strides=[1], onnx_name="/duration_predictor/flows.4/convs/convs_sep.1/Conv"](%/duration_predictor/flows.4/convs/Mul_5_output_0, %duration_predictor.flows.4.convs.convs_sep.1.weight, %duration_predictor.flows.4.convs.convs_sep.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.4/convs/norms_1.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Transpose"](%/duration_predictor/flows.4/convs/convs_sep.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.4/convs/norms_1.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_1.1/ReduceMean"](%/duration_predictor/flows.4/convs/norms_1.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Sub"](%/duration_predictor/flows.4/convs/norms_1.1/Transpose_output_0, %/duration_predictor/flows.4/convs/norms_1.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Pow"](%/duration_predictor/flows.4/convs/norms_1.1/Sub_output_0, %/duration_predictor/flows.4/convs/norms_1.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_1.1/ReduceMean_1"](%/duration_predictor/flows.4/convs/norms_1.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Add"](%/duration_predictor/flows.4/convs/norms_1.1/ReduceMean_1_output_0, %/duration_predictor/flows.4/convs/norms_1.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Sqrt"](%/duration_predictor/flows.4/convs/norms_1.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Div"](%/duration_predictor/flows.4/convs/norms_1.1/Sub_output_0, %/duration_predictor/flows.4/convs/norms_1.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Mul"](%/duration_predictor/flows.4/convs/norms_1.1/Div_output_0, %duration_predictor.flows.4.convs.norms_1.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Add_1"](%/duration_predictor/flows.4/convs/norms_1.1/Mul_output_0, %duration_predictor.flows.4.convs.norms_1.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_1.1/Transpose_1"](%/duration_predictor/flows.4/convs/norms_1.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.4/convs/Constant_6_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.4/convs/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Div_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/Div_2"](%/duration_predictor/flows.4/convs/norms_1.1/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Erf_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.4/convs/Erf_2"](%/duration_predictor/flows.4/convs/Div_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/convs/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Add_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add_4"](%/duration_predictor/flows.4/convs/Erf_2_output_0, %/duration_predictor/flows.4/convs/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Mul_6_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_6"](%/duration_predictor/flows.4/convs/norms_1.1/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Add_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.4/convs/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Mul_7_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_7"](%/duration_predictor/flows.4/convs/Mul_6_output_0, %/duration_predictor/flows.4/convs/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/convs_1x1.1/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.4/convs/convs_1x1.1/Conv"](%/duration_predictor/flows.4/convs/Mul_7_output_0, %duration_predictor.flows.4.convs.convs_1x1.1.weight, %duration_predictor.flows.4.convs.convs_1x1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.4/convs/norms_2.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Transpose"](%/duration_predictor/flows.4/convs/convs_1x1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.4/convs/norms_2.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_2.1/ReduceMean"](%/duration_predictor/flows.4/convs/norms_2.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Sub"](%/duration_predictor/flows.4/convs/norms_2.1/Transpose_output_0, %/duration_predictor/flows.4/convs/norms_2.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Pow"](%/duration_predictor/flows.4/convs/norms_2.1/Sub_output_0, %/duration_predictor/flows.4/convs/norms_2.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_2.1/ReduceMean_1"](%/duration_predictor/flows.4/convs/norms_2.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Add"](%/duration_predictor/flows.4/convs/norms_2.1/ReduceMean_1_output_0, %/duration_predictor/flows.4/convs/norms_2.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Sqrt"](%/duration_predictor/flows.4/convs/norms_2.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Div"](%/duration_predictor/flows.4/convs/norms_2.1/Sub_output_0, %/duration_predictor/flows.4/convs/norms_2.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Mul"](%/duration_predictor/flows.4/convs/norms_2.1/Div_output_0, %duration_predictor.flows.4.convs.norms_2.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Add_1"](%/duration_predictor/flows.4/convs/norms_2.1/Mul_output_0, %duration_predictor.flows.4.convs.norms_2.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_2.1/Transpose_1"](%/duration_predictor/flows.4/convs/norms_2.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.4/convs/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.4/convs/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Div_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/Div_3"](%/duration_predictor/flows.4/convs/norms_2.1/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Constant_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Erf_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.4/convs/Erf_3"](%/duration_predictor/flows.4/convs/Div_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/convs/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Add_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add_5"](%/duration_predictor/flows.4/convs/Erf_3_output_0, %/duration_predictor/flows.4/convs/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Mul_8_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_8"](%/duration_predictor/flows.4/convs/norms_2.1/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Add_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Constant_11_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.4/convs/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Mul_9_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_9"](%/duration_predictor/flows.4/convs/Mul_8_output_0, %/duration_predictor/flows.4/convs/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Add_6_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add_6"](%/duration_predictor/flows.4/convs/Add_3_output_0, %/duration_predictor/flows.4/convs/Mul_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/flows.4/convs/Mul_10_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_10"](%/duration_predictor/flows.4/convs/Add_6_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/flows.4/convs/convs_sep.2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[9], group=192, kernel_shape=[3], pads=[9, 9], strides=[1], onnx_name="/duration_predictor/flows.4/convs/convs_sep.2/Conv"](%/duration_predictor/flows.4/convs/Mul_10_output_0, %duration_predictor.flows.4.convs.convs_sep.2.weight, %duration_predictor.flows.4.convs.convs_sep.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.4/convs/norms_1.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Transpose"](%/duration_predictor/flows.4/convs/convs_sep.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.4/convs/norms_1.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_1.2/ReduceMean"](%/duration_predictor/flows.4/convs/norms_1.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Sub"](%/duration_predictor/flows.4/convs/norms_1.2/Transpose_output_0, %/duration_predictor/flows.4/convs/norms_1.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Pow"](%/duration_predictor/flows.4/convs/norms_1.2/Sub_output_0, %/duration_predictor/flows.4/convs/norms_1.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_1.2/ReduceMean_1"](%/duration_predictor/flows.4/convs/norms_1.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Add"](%/duration_predictor/flows.4/convs/norms_1.2/ReduceMean_1_output_0, %/duration_predictor/flows.4/convs/norms_1.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Sqrt"](%/duration_predictor/flows.4/convs/norms_1.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Div"](%/duration_predictor/flows.4/convs/norms_1.2/Sub_output_0, %/duration_predictor/flows.4/convs/norms_1.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Mul"](%/duration_predictor/flows.4/convs/norms_1.2/Div_output_0, %duration_predictor.flows.4.convs.norms_1.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Add_1"](%/duration_predictor/flows.4/convs/norms_1.2/Mul_output_0, %duration_predictor.flows.4.convs.norms_1.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_1.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_1.2/Transpose_1"](%/duration_predictor/flows.4/convs/norms_1.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.4/convs/Constant_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.4/convs/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Div_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/Div_4"](%/duration_predictor/flows.4/convs/norms_1.2/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Erf_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.4/convs/Erf_4"](%/duration_predictor/flows.4/convs/Div_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/convs/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Add_7_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add_7"](%/duration_predictor/flows.4/convs/Erf_4_output_0, %/duration_predictor/flows.4/convs/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Mul_11_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_11"](%/duration_predictor/flows.4/convs/norms_1.2/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Add_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.4/convs/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/Mul_12_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_12"](%/duration_predictor/flows.4/convs/Mul_11_output_0, %/duration_predictor/flows.4/convs/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.4/convs/convs_1x1.2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.4/convs/convs_1x1.2/Conv"](%/duration_predictor/flows.4/convs/Mul_12_output_0, %duration_predictor.flows.4.convs.convs_1x1.2.weight, %duration_predictor.flows.4.convs.convs_1x1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.4/convs/norms_2.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Transpose"](%/duration_predictor/flows.4/convs/convs_1x1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.4/convs/norms_2.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_2.2/ReduceMean"](%/duration_predictor/flows.4/convs/norms_2.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Sub"](%/duration_predictor/flows.4/convs/norms_2.2/Transpose_output_0, %/duration_predictor/flows.4/convs/norms_2.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Pow"](%/duration_predictor/flows.4/convs/norms_2.2/Sub_output_0, %/duration_predictor/flows.4/convs/norms_2.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.4/convs/norms_2.2/ReduceMean_1"](%/duration_predictor/flows.4/convs/norms_2.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Add"](%/duration_predictor/flows.4/convs/norms_2.2/ReduceMean_1_output_0, %/duration_predictor/flows.4/convs/norms_2.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Sqrt"](%/duration_predictor/flows.4/convs/norms_2.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Div"](%/duration_predictor/flows.4/convs/norms_2.2/Sub_output_0, %/duration_predictor/flows.4/convs/norms_2.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Mul"](%/duration_predictor/flows.4/convs/norms_2.2/Div_output_0, %duration_predictor.flows.4.convs.norms_2.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Add_1"](%/duration_predictor/flows.4/convs/norms_2.2/Mul_output_0, %duration_predictor.flows.4.convs.norms_2.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.4/convs/norms_2.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.4/convs/norms_2.2/Transpose_1"](%/duration_predictor/flows.4/convs/norms_2.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.4/convs/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.4/convs/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Div_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/convs/Div_5"](%/duration_predictor/flows.4/convs/norms_2.2/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Erf_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.4/convs/Erf_5"](%/duration_predictor/flows.4/convs/Div_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/convs/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Add_8_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add_8"](%/duration_predictor/flows.4/convs/Erf_5_output_0, %/duration_predictor/flows.4/convs/Constant_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Mul_13_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_13"](%/duration_predictor/flows.4/convs/norms_2.2/Transpose_1_output_0, %/duration_predictor/flows.4/convs/Add_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Constant_17_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.4/convs/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Mul_14_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_14"](%/duration_predictor/flows.4/convs/Mul_13_output_0, %/duration_predictor/flows.4/convs/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.4/convs/Add_9_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/convs/Add_9"](%/duration_predictor/flows.4/convs/Add_6_output_0, %/duration_predictor/flows.4/convs/Mul_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/flows.4/convs/Mul_15_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/convs/Mul_15"](%/duration_predictor/flows.4/convs/Add_9_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:63:0
  %/duration_predictor/flows.4/proj/Conv_output_0 : Float(*, 29, *, strides=[2900, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.4/proj/Conv"](%/duration_predictor/flows.4/convs/Mul_15_output_0, %duration_predictor.flows.4.proj.weight, %duration_predictor.flows.4.proj.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4/torch.nn.modules.conv.Conv1d::proj # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.4/Mul_output_0 : Float(*, 29, *, strides=[2900, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul"](%/duration_predictor/flows.4/proj/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:124:0
  %/duration_predictor/flows.4/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape"](%/duration_predictor/flows.4/Split_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.4/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.4/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.4/Gather"](%/duration_predictor/flows.4/Shape_output_0, %/duration_predictor/flows.4/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.4/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_1"](%/duration_predictor/flows.4/Split_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.4/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.4/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.4/Gather_1"](%/duration_predictor/flows.4/Shape_1_output_0, %/duration_predictor/flows.4/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.4/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_2"](%/duration_predictor/flows.4/Split_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.4/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.4/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.4/Gather_2"](%/duration_predictor/flows.4/Shape_2_output_0, %/duration_predictor/flows.4/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %onnx::Unsqueeze_4514 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/flows.4/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze"](%/duration_predictor/flows.4/Gather_output_0, %onnx::Unsqueeze_4514), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4
  %onnx::Unsqueeze_4516 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/flows.4/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_1"](%/duration_predictor/flows.4/Gather_1_output_0, %onnx::Unsqueeze_4516), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4
  %/duration_predictor/flows.4/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4
  %onnx::Unsqueeze_4520 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/flows.4/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_2"](%/duration_predictor/flows.4/Gather_2_output_0, %onnx::Unsqueeze_4520), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4
  %/duration_predictor/flows.4/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat"](%/duration_predictor/flows.4/Unsqueeze_output_0, %/duration_predictor/flows.4/Unsqueeze_1_output_0, %/duration_predictor/flows.4/Constant_3_output_0, %/duration_predictor/flows.4/Unsqueeze_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:127:0
  %/duration_predictor/flows.4/Reshape_output_0 : Float(*, *, *, *, strides=[2900, 2900, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape"](%/duration_predictor/flows.4/Mul_output_0, %/duration_predictor/flows.4/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:127:0
  %/duration_predictor/flows.4/Transpose_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/duration_predictor/flows.4/Transpose"](%/duration_predictor/flows.4/Reshape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:127:0
  %/duration_predictor/flows.4/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/duration_predictor/flows.4/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.4/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.4/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.4/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.4/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.4/Slice_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice"](%/duration_predictor/flows.4/Transpose_output_0, %/duration_predictor/flows.4/Constant_5_output_0, %/duration_predictor/flows.4/Constant_6_output_0, %/duration_predictor/flows.4/Constant_4_output_0, %/duration_predictor/flows.4/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.4/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={13.8564}, onnx_name="/duration_predictor/flows.4/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.4/Div_output_0 : Float(*, *, *, *, strides=[1000, 1000, 1, 100], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/Div"](%/duration_predictor/flows.4/Slice_output_0, %/duration_predictor/flows.4/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.4/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/duration_predictor/flows.4/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.4/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.4/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.4/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={20}, onnx_name="/duration_predictor/flows.4/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.4/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.4/Slice_1_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_1"](%/duration_predictor/flows.4/Transpose_output_0, %/duration_predictor/flows.4/Constant_10_output_0, %/duration_predictor/flows.4/Constant_11_output_0, %/duration_predictor/flows.4/Constant_9_output_0, %/duration_predictor/flows.4/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.4/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={13.8564}, onnx_name="/duration_predictor/flows.4/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.4/Div_1_output_0 : Float(*, *, *, *, strides=[1000, 1000, 1, 100], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/Div_1"](%/duration_predictor/flows.4/Slice_1_output_0, %/duration_predictor/flows.4/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.4/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/duration_predictor/flows.4/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.4/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={20}, onnx_name="/duration_predictor/flows.4/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.4/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.4/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.4/Slice_2_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_2"](%/duration_predictor/flows.4/Transpose_output_0, %/duration_predictor/flows.4/Constant_15_output_0, %/duration_predictor/flows.4/Constant_16_output_0, %/duration_predictor/flows.4/Constant_14_output_0, %/duration_predictor/flows.4/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.4/Constant_18_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-5}, onnx_name="/duration_predictor/flows.4/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.4/GreaterOrEqual_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::GreaterOrEqual[onnx_name="/duration_predictor/flows.4/GreaterOrEqual"](%/duration_predictor/flows.4/Split_output_1, %/duration_predictor/flows.4/Constant_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.4/Constant_19_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/duration_predictor/flows.4/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.4/LessOrEqual_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::LessOrEqual[onnx_name="/duration_predictor/flows.4/LessOrEqual"](%/duration_predictor/flows.4/Split_output_1, %/duration_predictor/flows.4/Constant_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.4/And_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::And[onnx_name="/duration_predictor/flows.4/And"](%/duration_predictor/flows.4/GreaterOrEqual_output_0, %/duration_predictor/flows.4/LessOrEqual_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.4/Not_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::Not[onnx_name="/duration_predictor/flows.4/Not"](%/duration_predictor/flows.4/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:63:0
  %/duration_predictor/flows.4/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/duration_predictor/flows.4/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_21_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.4/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/ConstantOfShape_output_0 : Long(6, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.4/ConstantOfShape"](%/duration_predictor/flows.4/Constant_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Concat_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_1"](%/duration_predictor/flows.4/Constant_21_output_0, %/duration_predictor/flows.4/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.4/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Reshape_1_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_1"](%/duration_predictor/flows.4/Concat_1_output_0, %/duration_predictor/flows.4/Constant_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Slice_3_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_3"](%/duration_predictor/flows.4/Reshape_1_output_0, %/duration_predictor/flows.4/Constant_24_output_0, %/duration_predictor/flows.4/Constant_25_output_0, %/duration_predictor/flows.4/Constant_23_output_0, %/duration_predictor/flows.4/Constant_26_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Transpose_1_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_1"](%/duration_predictor/flows.4/Slice_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Reshape_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_2"](%/duration_predictor/flows.4/Transpose_1_output_0, %/duration_predictor/flows.4/Constant_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Cast_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.4/Cast"](%/duration_predictor/flows.4/Reshape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Pad_output_0 : Float(*, *, *, *, strides=[1100, 1100, 11, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/duration_predictor/flows.4/Pad"](%/duration_predictor/flows.4/Slice_2_output_0, %/duration_predictor/flows.4/Cast_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Gather_3_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Gather[axis=3, onnx_name="/duration_predictor/flows.4/Gather_3"](%/duration_predictor/flows.4/Pad_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_3"](%/duration_predictor/flows.4/Gather_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/ConstantOfShape_1_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0.539742}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_1"](%/duration_predictor/flows.4/Shape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_4"](%/duration_predictor/flows.4/Gather_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Expand_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand"](%/duration_predictor/flows.4/ConstantOfShape_1_output_0, %/duration_predictor/flows.4/Shape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %onnx::Gather_4591 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/Pad_output_0)
  %onnx::Gather_4592 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_4593 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_4591, %onnx::Gather_4592)
  %onnx::Range_4594 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_4593)
  %onnx::Range_4595 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_4596 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_4597 : Long(*, device=cpu) = onnx::Range(%onnx::Range_4595, %onnx::Range_4594, %onnx::Range_4596)
  %onnx::Gather_4598 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/Pad_output_0)
  %onnx::Gather_4599 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Cast_4600 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_4598, %onnx::Gather_4599)
  %onnx::Range_4601 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_4600)
  %onnx::Range_4602 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_4603 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_4604 : Long(*, device=cpu) = onnx::Range(%onnx::Range_4602, %onnx::Range_4601, %onnx::Range_4603)
  %onnx::Gather_4605 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/Pad_output_0)
  %onnx::Gather_4606 : Long(device=cpu) = onnx::Constant[value={2}]()
  %onnx::Cast_4607 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_4605, %onnx::Gather_4606)
  %onnx::Range_4608 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_4607)
  %onnx::Range_4609 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_4610 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_4611 : Long(*, device=cpu) = onnx::Range(%onnx::Range_4609, %onnx::Range_4608, %onnx::Range_4610)
  %onnx::Expand_4612 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()
  %onnx::Reshape_4613 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1  1 [ CPULongType{4} ]]()
  %onnx::Add_4614 : Long(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_4597, %onnx::Reshape_4613)
  %onnx::Reshape_4615 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1 [ CPULongType{3} ]]()
  %onnx::Add_4616 : Long(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_4604, %onnx::Reshape_4615)
  %onnx::Reshape_4617 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_4618 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_4611, %onnx::Reshape_4617)
  %/duration_predictor/flows.4/Add_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add"](%onnx::Add_4614, %onnx::Add_4616), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Add_1_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_1"](%/duration_predictor/flows.4/Add_output_0, %onnx::Add_4618), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Add_2_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_2"](%/duration_predictor/flows.4/Add_1_output_0, %/duration_predictor/flows.4/Constant_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_5"](%/duration_predictor/flows.4/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Shape_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_6"](%/duration_predictor/flows.4/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/ConstantOfShape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_2"](%/duration_predictor/flows.4/Shape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_29_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Mul_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_1"](%/duration_predictor/flows.4/ConstantOfShape_2_output_0, %/duration_predictor/flows.4/Constant_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Equal_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal"](%/duration_predictor/flows.4/Shape_5_output_0, %/duration_predictor/flows.4/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Where_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where"](%/duration_predictor/flows.4/Equal_output_0, %/duration_predictor/flows.4/ConstantOfShape_2_output_0, %/duration_predictor/flows.4/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Expand_1_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_1"](%onnx::Add_4614, %/duration_predictor/flows.4/Where_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Unsqueeze_3_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_3"](%/duration_predictor/flows.4/Expand_1_output_0, %/duration_predictor/flows.4/Constant_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Shape_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_7"](%/duration_predictor/flows.4/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/ConstantOfShape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_3"](%/duration_predictor/flows.4/Shape_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Mul_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_2"](%/duration_predictor/flows.4/ConstantOfShape_3_output_0, %/duration_predictor/flows.4/Constant_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Equal_1_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_1"](%/duration_predictor/flows.4/Shape_5_output_0, %/duration_predictor/flows.4/Mul_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_1"](%/duration_predictor/flows.4/Equal_1_output_0, %/duration_predictor/flows.4/ConstantOfShape_3_output_0, %/duration_predictor/flows.4/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Expand_2_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_2"](%onnx::Add_4616, %/duration_predictor/flows.4/Where_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Unsqueeze_4_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_4"](%/duration_predictor/flows.4/Expand_2_output_0, %/duration_predictor/flows.4/Constant_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Shape_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_8"](%/duration_predictor/flows.4/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/ConstantOfShape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_4"](%/duration_predictor/flows.4/Shape_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_33_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Mul_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_3"](%/duration_predictor/flows.4/ConstantOfShape_4_output_0, %/duration_predictor/flows.4/Constant_33_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Equal_2_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_2"](%/duration_predictor/flows.4/Shape_5_output_0, %/duration_predictor/flows.4/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Where_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_2"](%/duration_predictor/flows.4/Equal_2_output_0, %/duration_predictor/flows.4/ConstantOfShape_4_output_0, %/duration_predictor/flows.4/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Expand_3_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_3"](%onnx::Add_4618, %/duration_predictor/flows.4/Where_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Unsqueeze_5_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_5"](%/duration_predictor/flows.4/Expand_3_output_0, %/duration_predictor/flows.4/Constant_34_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Shape_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_9"](%/duration_predictor/flows.4/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/ConstantOfShape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_5"](%/duration_predictor/flows.4/Shape_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Mul_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_4"](%/duration_predictor/flows.4/ConstantOfShape_5_output_0, %/duration_predictor/flows.4/Constant_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Equal_3_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_3"](%/duration_predictor/flows.4/Shape_5_output_0, %/duration_predictor/flows.4/Mul_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Where_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_3"](%/duration_predictor/flows.4/Equal_3_output_0, %/duration_predictor/flows.4/ConstantOfShape_5_output_0, %/duration_predictor/flows.4/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Expand_4_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_4"](%onnx::Expand_4612, %/duration_predictor/flows.4/Where_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Unsqueeze_6_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_6"](%/duration_predictor/flows.4/Expand_4_output_0, %/duration_predictor/flows.4/Constant_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Concat_2_output_0 : Long(*, *, *, *, 4, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.4/Concat_2"](%/duration_predictor/flows.4/Unsqueeze_3_output_0, %/duration_predictor/flows.4/Unsqueeze_4_output_0, %/duration_predictor/flows.4/Unsqueeze_5_output_0, %/duration_predictor/flows.4/Unsqueeze_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_10"](%/duration_predictor/flows.4/Pad_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/duration_predictor/flows.4/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Slice_4_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_4"](%/duration_predictor/flows.4/Shape_10_output_0, %/duration_predictor/flows.4/Constant_38_output_0, %/duration_predictor/flows.4/Constant_39_output_0, %/duration_predictor/flows.4/Constant_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_3"](%/duration_predictor/flows.4/Shape_5_output_0, %/duration_predictor/flows.4/Slice_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Reshape_3_output_0 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_3"](%/duration_predictor/flows.4/Expand_output_0, %/duration_predictor/flows.4/Concat_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/ScatterND_output_0 : Float(*, *, *, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND"](%/duration_predictor/flows.4/Pad_output_0, %/duration_predictor/flows.4/Concat_2_output_0, %/duration_predictor/flows.4/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.4/Gather_4_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Gather[axis=3, onnx_name="/duration_predictor/flows.4/Gather_4"](%/duration_predictor/flows.4/ScatterND_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Shape_11_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_11"](%/duration_predictor/flows.4/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/ConstantOfShape_6_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0.539742}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_6"](%/duration_predictor/flows.4/Shape_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Shape_12_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_12"](%/duration_predictor/flows.4/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Expand_5_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_5"](%/duration_predictor/flows.4/ConstantOfShape_6_output_0, %/duration_predictor/flows.4/Shape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %onnx::Gather_4674 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/ScatterND_output_0)
  %onnx::Gather_4675 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_4676 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_4674, %onnx::Gather_4675)
  %onnx::Range_4677 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_4676)
  %onnx::Range_4678 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_4679 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_4680 : Long(*, device=cpu) = onnx::Range(%onnx::Range_4678, %onnx::Range_4677, %onnx::Range_4679)
  %onnx::Gather_4681 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/ScatterND_output_0)
  %onnx::Gather_4682 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Cast_4683 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_4681, %onnx::Gather_4682)
  %onnx::Range_4684 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_4683)
  %onnx::Range_4685 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_4686 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_4687 : Long(*, device=cpu) = onnx::Range(%onnx::Range_4685, %onnx::Range_4684, %onnx::Range_4686)
  %onnx::Gather_4688 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/ScatterND_output_0)
  %onnx::Gather_4689 : Long(device=cpu) = onnx::Constant[value={2}]()
  %onnx::Cast_4690 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_4688, %onnx::Gather_4689)
  %onnx::Range_4691 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_4690)
  %onnx::Range_4692 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_4693 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_4694 : Long(*, device=cpu) = onnx::Range(%onnx::Range_4692, %onnx::Range_4691, %onnx::Range_4693)
  %onnx::Expand_4695 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_4696 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1  1 [ CPULongType{4} ]]()
  %onnx::Add_4697 : Long(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_4680, %onnx::Reshape_4696)
  %onnx::Reshape_4698 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1 [ CPULongType{3} ]]()
  %onnx::Add_4699 : Long(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_4687, %onnx::Reshape_4698)
  %onnx::Reshape_4700 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_4701 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_4694, %onnx::Reshape_4700)
  %/duration_predictor/flows.4/Add_3_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_3"](%onnx::Add_4697, %onnx::Add_4699), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Add_4_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_4"](%/duration_predictor/flows.4/Add_3_output_0, %onnx::Add_4701), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_40"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Add_5_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_5"](%/duration_predictor/flows.4/Add_4_output_0, %/duration_predictor/flows.4/Constant_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Shape_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_13"](%/duration_predictor/flows.4/Add_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_14"](%/duration_predictor/flows.4/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/ConstantOfShape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_7"](%/duration_predictor/flows.4/Shape_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_41_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_41"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Mul_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_5"](%/duration_predictor/flows.4/ConstantOfShape_7_output_0, %/duration_predictor/flows.4/Constant_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Equal_4_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_4"](%/duration_predictor/flows.4/Shape_13_output_0, %/duration_predictor/flows.4/Mul_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Where_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_4"](%/duration_predictor/flows.4/Equal_4_output_0, %/duration_predictor/flows.4/ConstantOfShape_7_output_0, %/duration_predictor/flows.4/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Expand_6_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_6"](%onnx::Add_4697, %/duration_predictor/flows.4/Where_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_42"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Unsqueeze_7_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_7"](%/duration_predictor/flows.4/Expand_6_output_0, %/duration_predictor/flows.4/Constant_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Shape_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_15"](%/duration_predictor/flows.4/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/ConstantOfShape_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_8"](%/duration_predictor/flows.4/Shape_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_43_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_43"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Mul_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_6"](%/duration_predictor/flows.4/ConstantOfShape_8_output_0, %/duration_predictor/flows.4/Constant_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Equal_5_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_5"](%/duration_predictor/flows.4/Shape_13_output_0, %/duration_predictor/flows.4/Mul_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Where_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_5"](%/duration_predictor/flows.4/Equal_5_output_0, %/duration_predictor/flows.4/ConstantOfShape_8_output_0, %/duration_predictor/flows.4/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Expand_7_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_7"](%onnx::Add_4699, %/duration_predictor/flows.4/Where_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_44"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Unsqueeze_8_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_8"](%/duration_predictor/flows.4/Expand_7_output_0, %/duration_predictor/flows.4/Constant_44_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Shape_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_16"](%/duration_predictor/flows.4/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/ConstantOfShape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_9"](%/duration_predictor/flows.4/Shape_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_45_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_45"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Mul_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_7"](%/duration_predictor/flows.4/ConstantOfShape_9_output_0, %/duration_predictor/flows.4/Constant_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Equal_6_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_6"](%/duration_predictor/flows.4/Shape_13_output_0, %/duration_predictor/flows.4/Mul_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Where_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_6"](%/duration_predictor/flows.4/Equal_6_output_0, %/duration_predictor/flows.4/ConstantOfShape_9_output_0, %/duration_predictor/flows.4/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Expand_8_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_8"](%onnx::Add_4701, %/duration_predictor/flows.4/Where_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_46"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Unsqueeze_9_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_9"](%/duration_predictor/flows.4/Expand_8_output_0, %/duration_predictor/flows.4/Constant_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Shape_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_17"](%/duration_predictor/flows.4/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/ConstantOfShape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_10"](%/duration_predictor/flows.4/Shape_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_47_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_47"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Mul_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_8"](%/duration_predictor/flows.4/ConstantOfShape_10_output_0, %/duration_predictor/flows.4/Constant_47_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Equal_7_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_7"](%/duration_predictor/flows.4/Shape_13_output_0, %/duration_predictor/flows.4/Mul_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Where_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_7"](%/duration_predictor/flows.4/Equal_7_output_0, %/duration_predictor/flows.4/ConstantOfShape_10_output_0, %/duration_predictor/flows.4/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Expand_9_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_9"](%onnx::Expand_4695, %/duration_predictor/flows.4/Where_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_48_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_48"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Unsqueeze_10_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_10"](%/duration_predictor/flows.4/Expand_9_output_0, %/duration_predictor/flows.4/Constant_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Concat_4_output_0 : Long(*, *, *, *, 4, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.4/Concat_4"](%/duration_predictor/flows.4/Unsqueeze_7_output_0, %/duration_predictor/flows.4/Unsqueeze_8_output_0, %/duration_predictor/flows.4/Unsqueeze_9_output_0, %/duration_predictor/flows.4/Unsqueeze_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Shape_18_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_18"](%/duration_predictor/flows.4/ScatterND_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_49"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/duration_predictor/flows.4/Constant_50"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_51"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Slice_5_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_5"](%/duration_predictor/flows.4/Shape_18_output_0, %/duration_predictor/flows.4/Constant_50_output_0, %/duration_predictor/flows.4/Constant_51_output_0, %/duration_predictor/flows.4/Constant_49_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_5"](%/duration_predictor/flows.4/Shape_13_output_0, %/duration_predictor/flows.4/Slice_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/Reshape_4_output_0 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_4"](%/duration_predictor/flows.4/Expand_5_output_0, %/duration_predictor/flows.4/Concat_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/ScatterND_1_output_0 : Float(*, *, *, *, strides=[1100, 1100, 11, 1], requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND_1"](%/duration_predictor/flows.4/ScatterND_output_0, %/duration_predictor/flows.4/Concat_4_output_0, %/duration_predictor/flows.4/Reshape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.4/NonZero_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.4/NonZero"](%/duration_predictor/flows.4/Not_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Transpose_2_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_2"](%/duration_predictor/flows.4/NonZero_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/GatherND_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.4/GatherND"](%/duration_predictor/flows.4/Split_output_1, %/duration_predictor/flows.4/Transpose_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Shape_19_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_19"](%/duration_predictor/flows.4/Split_output_1), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:65:0
  %/duration_predictor/flows.4/ConstantOfShape_11_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_11"](%/duration_predictor/flows.4/Shape_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:65:0
  %/duration_predictor/flows.4/NonZero_1_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.4/NonZero_1"](%/duration_predictor/flows.4/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:80:0
  %/duration_predictor/flows.4/Transpose_3_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_3"](%/duration_predictor/flows.4/NonZero_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:80:0
  %/duration_predictor/flows.4/GatherND_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.4/GatherND_1"](%/duration_predictor/flows.4/Split_output_1, %/duration_predictor/flows.4/Transpose_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:80:0
  %/duration_predictor/flows.4/NonZero_2_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.4/NonZero_2"](%/duration_predictor/flows.4/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:81:0
  %/duration_predictor/flows.4/Transpose_4_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_4"](%/duration_predictor/flows.4/NonZero_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:81:0
  %/duration_predictor/flows.4/GatherND_2_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.4/GatherND_2"](%/duration_predictor/flows.4/Div_output_0, %/duration_predictor/flows.4/Transpose_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:81:0
  %/duration_predictor/flows.4/NonZero_3_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.4/NonZero_3"](%/duration_predictor/flows.4/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:82:0
  %/duration_predictor/flows.4/Transpose_5_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_5"](%/duration_predictor/flows.4/NonZero_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:82:0
  %/duration_predictor/flows.4/GatherND_3_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.4/GatherND_3"](%/duration_predictor/flows.4/Div_1_output_0, %/duration_predictor/flows.4/Transpose_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:82:0
  %/duration_predictor/flows.4/NonZero_4_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.4/NonZero_4"](%/duration_predictor/flows.4/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:83:0
  %/duration_predictor/flows.4/Transpose_6_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_6"](%/duration_predictor/flows.4/NonZero_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:83:0
  %/duration_predictor/flows.4/GatherND_4_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.4/GatherND_4"](%/duration_predictor/flows.4/ScatterND_1_output_0, %/duration_predictor/flows.4/Transpose_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:83:0
  %/duration_predictor/flows.4/Shape_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_20"](%/duration_predictor/flows.4/GatherND_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:114:0
  %/duration_predictor/flows.4/Constant_52_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_52"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:114:0
  %/duration_predictor/flows.4/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.4/Gather_5"](%/duration_predictor/flows.4/Shape_20_output_0, %/duration_predictor/flows.4/Constant_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:114:0
  %/duration_predictor/flows.4/Softmax_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/duration_predictor/flows.4/Softmax"](%/duration_predictor/flows.4/GatherND_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/duration_predictor/flows.4/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/duration_predictor/flows.4/Cast_1"](%/duration_predictor/flows.4/Gather_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.4/Constant_53_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.4/Constant_53"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.4/Mul_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_9"](%/duration_predictor/flows.4/Cast_1_output_0, %/duration_predictor/flows.4/Constant_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.4/Constant_54_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_54"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:962:0
  %/duration_predictor/flows.4/Sub_output_0 : Float(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub"](%/duration_predictor/flows.4/Constant_54_output_0, %/duration_predictor/flows.4/Mul_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:962:0
  %/duration_predictor/flows.4/Mul_10_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_10"](%/duration_predictor/flows.4/Sub_output_0, %/duration_predictor/flows.4/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.4/Constant_55_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.4/Constant_55"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.4/Add_6_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_6"](%/duration_predictor/flows.4/Mul_10_output_0, %/duration_predictor/flows.4/Constant_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.4/Constant_56_output_0 : Int(device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_56"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:123:0
  %/duration_predictor/flows.4/CumSum_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::CumSum[onnx_name="/duration_predictor/flows.4/CumSum"](%/duration_predictor/flows.4/Add_6_output_0, %/duration_predictor/flows.4/Constant_56_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:123:0
  %/duration_predictor/flows.4/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_57"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_58_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  0 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.4/Constant_58"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/ConstantOfShape_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_12"](%/duration_predictor/flows.4/Constant_57_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_6"](%/duration_predictor/flows.4/Constant_58_output_0, %/duration_predictor/flows.4/ConstantOfShape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_59_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.4/Constant_59"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Reshape_5_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_5"](%/duration_predictor/flows.4/Concat_6_output_0, %/duration_predictor/flows.4/Constant_59_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_60_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_60"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_61_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_61"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_62_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_62"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_63_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_63"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Slice_6_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_6"](%/duration_predictor/flows.4/Reshape_5_output_0, %/duration_predictor/flows.4/Constant_61_output_0, %/duration_predictor/flows.4/Constant_62_output_0, %/duration_predictor/flows.4/Constant_60_output_0, %/duration_predictor/flows.4/Constant_63_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Transpose_7_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_7"](%/duration_predictor/flows.4/Slice_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_64_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_64"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Reshape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_6"](%/duration_predictor/flows.4/Transpose_7_output_0, %/duration_predictor/flows.4/Constant_64_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Cast_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.4/Cast_2"](%/duration_predictor/flows.4/Reshape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_65_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_65"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Pad_1_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/duration_predictor/flows.4/Pad_1"](%/duration_predictor/flows.4/CumSum_output_0, %/duration_predictor/flows.4/Cast_2_output_0, %/duration_predictor/flows.4/Constant_65_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_66_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.4/Constant_66"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.4/Mul_11_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_11"](%/duration_predictor/flows.4/Pad_1_output_0, %/duration_predictor/flows.4/Constant_66_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.4/Constant_67_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-5}, onnx_name="/duration_predictor/flows.4/Constant_67"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.4/Add_7_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_7"](%/duration_predictor/flows.4/Mul_11_output_0, %/duration_predictor/flows.4/Constant_67_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.4/Gather_6_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_6"](%/duration_predictor/flows.4/Add_7_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Shape_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_21"](%/duration_predictor/flows.4/Gather_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/ConstantOfShape_13_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={-5}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_13"](%/duration_predictor/flows.4/Shape_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Shape_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_22"](%/duration_predictor/flows.4/Gather_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Expand_10_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_10"](%/duration_predictor/flows.4/ConstantOfShape_13_output_0, %/duration_predictor/flows.4/Shape_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %onnx::Gather_4816 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/Add_7_output_0)
  %onnx::Gather_4817 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_4818 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_4816, %onnx::Gather_4817)
  %onnx::Range_4819 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_4818)
  %onnx::Range_4820 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_4821 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_4822 : Long(*, device=cpu) = onnx::Range(%onnx::Range_4820, %onnx::Range_4819, %onnx::Range_4821)
  %onnx::Expand_4823 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()
  %onnx::Reshape_4824 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_4825 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_4822, %onnx::Reshape_4824)
  %/duration_predictor/flows.4/Constant_68_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_68"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Add_8_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_8"](%onnx::Add_4825, %/duration_predictor/flows.4/Constant_68_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Shape_23_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_23"](%/duration_predictor/flows.4/Add_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Shape_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_24"](%/duration_predictor/flows.4/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/ConstantOfShape_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_14"](%/duration_predictor/flows.4/Shape_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Constant_69_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_69"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Mul_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_12"](%/duration_predictor/flows.4/ConstantOfShape_14_output_0, %/duration_predictor/flows.4/Constant_69_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Equal_8_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_8"](%/duration_predictor/flows.4/Shape_23_output_0, %/duration_predictor/flows.4/Mul_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Where_8_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_8"](%/duration_predictor/flows.4/Equal_8_output_0, %/duration_predictor/flows.4/ConstantOfShape_14_output_0, %/duration_predictor/flows.4/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Expand_11_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_11"](%onnx::Add_4825, %/duration_predictor/flows.4/Where_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_70"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Unsqueeze_11_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_11"](%/duration_predictor/flows.4/Expand_11_output_0, %/duration_predictor/flows.4/Constant_70_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Shape_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_25"](%/duration_predictor/flows.4/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/ConstantOfShape_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_15"](%/duration_predictor/flows.4/Shape_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Constant_71_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_71"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Mul_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_13"](%/duration_predictor/flows.4/ConstantOfShape_15_output_0, %/duration_predictor/flows.4/Constant_71_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Equal_9_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_9"](%/duration_predictor/flows.4/Shape_23_output_0, %/duration_predictor/flows.4/Mul_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Where_9_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_9"](%/duration_predictor/flows.4/Equal_9_output_0, %/duration_predictor/flows.4/ConstantOfShape_15_output_0, %/duration_predictor/flows.4/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Expand_12_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_12"](%onnx::Expand_4823, %/duration_predictor/flows.4/Where_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_72"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Unsqueeze_12_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_12"](%/duration_predictor/flows.4/Expand_12_output_0, %/duration_predictor/flows.4/Constant_72_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Concat_7_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.4/Concat_7"](%/duration_predictor/flows.4/Unsqueeze_11_output_0, %/duration_predictor/flows.4/Unsqueeze_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Shape_26_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_26"](%/duration_predictor/flows.4/Add_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Constant_73_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_73"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Constant_74_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_74"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Constant_75_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_75"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Slice_7_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_7"](%/duration_predictor/flows.4/Shape_26_output_0, %/duration_predictor/flows.4/Constant_74_output_0, %/duration_predictor/flows.4/Constant_75_output_0, %/duration_predictor/flows.4/Constant_73_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Concat_8_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_8"](%/duration_predictor/flows.4/Shape_23_output_0, %/duration_predictor/flows.4/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Reshape_7_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_7"](%/duration_predictor/flows.4/Expand_10_output_0, %/duration_predictor/flows.4/Concat_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/ScatterND_2_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND_2"](%/duration_predictor/flows.4/Add_7_output_0, %/duration_predictor/flows.4/Concat_7_output_0, %/duration_predictor/flows.4/Reshape_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.4/Gather_7_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_7"](%/duration_predictor/flows.4/ScatterND_2_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Shape_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_27"](%/duration_predictor/flows.4/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/ConstantOfShape_16_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={5}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_16"](%/duration_predictor/flows.4/Shape_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Shape_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_28"](%/duration_predictor/flows.4/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Expand_13_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_13"](%/duration_predictor/flows.4/ConstantOfShape_16_output_0, %/duration_predictor/flows.4/Shape_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %onnx::Gather_4861 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/ScatterND_2_output_0)
  %onnx::Gather_4862 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_4863 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_4861, %onnx::Gather_4862)
  %onnx::Range_4864 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_4863)
  %onnx::Range_4865 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_4866 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_4867 : Long(*, device=cpu) = onnx::Range(%onnx::Range_4865, %onnx::Range_4864, %onnx::Range_4866)
  %onnx::Expand_4868 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_4869 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_4870 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_4867, %onnx::Reshape_4869)
  %/duration_predictor/flows.4/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_76"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Add_9_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_9"](%onnx::Add_4870, %/duration_predictor/flows.4/Constant_76_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Shape_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_29"](%/duration_predictor/flows.4/Add_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Shape_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_30"](%/duration_predictor/flows.4/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/ConstantOfShape_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_17"](%/duration_predictor/flows.4/Shape_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Constant_77_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_77"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Mul_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_14"](%/duration_predictor/flows.4/ConstantOfShape_17_output_0, %/duration_predictor/flows.4/Constant_77_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Equal_10_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_10"](%/duration_predictor/flows.4/Shape_29_output_0, %/duration_predictor/flows.4/Mul_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Where_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_10"](%/duration_predictor/flows.4/Equal_10_output_0, %/duration_predictor/flows.4/ConstantOfShape_17_output_0, %/duration_predictor/flows.4/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Expand_14_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_14"](%onnx::Add_4870, %/duration_predictor/flows.4/Where_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_78"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Unsqueeze_13_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_13"](%/duration_predictor/flows.4/Expand_14_output_0, %/duration_predictor/flows.4/Constant_78_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Shape_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_31"](%/duration_predictor/flows.4/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/ConstantOfShape_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_18"](%/duration_predictor/flows.4/Shape_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Constant_79_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_79"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Mul_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_15"](%/duration_predictor/flows.4/ConstantOfShape_18_output_0, %/duration_predictor/flows.4/Constant_79_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Equal_11_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_11"](%/duration_predictor/flows.4/Shape_29_output_0, %/duration_predictor/flows.4/Mul_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Where_11_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_11"](%/duration_predictor/flows.4/Equal_11_output_0, %/duration_predictor/flows.4/ConstantOfShape_18_output_0, %/duration_predictor/flows.4/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Expand_15_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_15"](%onnx::Expand_4868, %/duration_predictor/flows.4/Where_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Constant_80_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_80"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Unsqueeze_14_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_14"](%/duration_predictor/flows.4/Expand_15_output_0, %/duration_predictor/flows.4/Constant_80_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Concat_9_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.4/Concat_9"](%/duration_predictor/flows.4/Unsqueeze_13_output_0, %/duration_predictor/flows.4/Unsqueeze_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Shape_32_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_32"](%/duration_predictor/flows.4/ScatterND_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_81"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Constant_82_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_82"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Constant_83_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_83"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Slice_8_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_8"](%/duration_predictor/flows.4/Shape_32_output_0, %/duration_predictor/flows.4/Constant_82_output_0, %/duration_predictor/flows.4/Constant_83_output_0, %/duration_predictor/flows.4/Constant_81_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Concat_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_10"](%/duration_predictor/flows.4/Shape_29_output_0, %/duration_predictor/flows.4/Slice_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Reshape_8_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_8"](%/duration_predictor/flows.4/Expand_13_output_0, %/duration_predictor/flows.4/Concat_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/ScatterND_3_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND_3"](%/duration_predictor/flows.4/ScatterND_2_output_0, %/duration_predictor/flows.4/Concat_9_output_0, %/duration_predictor/flows.4/Reshape_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.4/Constant_84_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_84"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Constant_85_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_85"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Constant_86_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_86"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Constant_87_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_87"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Slice_9_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_9"](%/duration_predictor/flows.4/ScatterND_3_output_0, %/duration_predictor/flows.4/Constant_85_output_0, %/duration_predictor/flows.4/Constant_86_output_0, %/duration_predictor/flows.4/Constant_84_output_0, %/duration_predictor/flows.4/Constant_87_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Constant_88_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_88"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Constant_89_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_89"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Constant_90_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_90"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Constant_91_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_91"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Slice_10_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_10"](%/duration_predictor/flows.4/ScatterND_3_output_0, %/duration_predictor/flows.4/Constant_89_output_0, %/duration_predictor/flows.4/Constant_90_output_0, %/duration_predictor/flows.4/Constant_88_output_0, %/duration_predictor/flows.4/Constant_91_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Sub_1_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub_1"](%/duration_predictor/flows.4/Slice_9_output_0, %/duration_predictor/flows.4/Slice_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.4/Softplus_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Softplus[onnx_name="/duration_predictor/flows.4/Softplus"](%/duration_predictor/flows.4/GatherND_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:130:0
  %/duration_predictor/flows.4/Constant_92_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.4/Constant_92"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:130:0
  %/duration_predictor/flows.4/Add_10_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_10"](%/duration_predictor/flows.4/Softplus_output_0, %/duration_predictor/flows.4/Constant_92_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:130:0
  %/duration_predictor/flows.4/Softmax_1_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/duration_predictor/flows.4/Softmax_1"](%/duration_predictor/flows.4/GatherND_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/duration_predictor/flows.4/Mul_16_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_16"](%/duration_predictor/flows.4/Sub_output_0, %/duration_predictor/flows.4/Softmax_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:133:0
  %/duration_predictor/flows.4/Constant_93_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.4/Constant_93"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:133:0
  %/duration_predictor/flows.4/Add_11_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_11"](%/duration_predictor/flows.4/Mul_16_output_0, %/duration_predictor/flows.4/Constant_93_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:133:0
  %/duration_predictor/flows.4/Constant_94_output_0 : Int(device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_94"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:134:0
  %/duration_predictor/flows.4/CumSum_1_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::CumSum[onnx_name="/duration_predictor/flows.4/CumSum_1"](%/duration_predictor/flows.4/Add_11_output_0, %/duration_predictor/flows.4/Constant_94_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:134:0
  %/duration_predictor/flows.4/Constant_95_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_95"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_96_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  0 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.4/Constant_96"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/ConstantOfShape_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_19"](%/duration_predictor/flows.4/Constant_95_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Concat_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_11"](%/duration_predictor/flows.4/Constant_96_output_0, %/duration_predictor/flows.4/ConstantOfShape_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_97_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.4/Constant_97"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Reshape_9_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_9"](%/duration_predictor/flows.4/Concat_11_output_0, %/duration_predictor/flows.4/Constant_97_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_98_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_98"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_99_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_99"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_100_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_100"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_101_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_101"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Slice_11_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_11"](%/duration_predictor/flows.4/Reshape_9_output_0, %/duration_predictor/flows.4/Constant_99_output_0, %/duration_predictor/flows.4/Constant_100_output_0, %/duration_predictor/flows.4/Constant_98_output_0, %/duration_predictor/flows.4/Constant_101_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Transpose_8_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_8"](%/duration_predictor/flows.4/Slice_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_102_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_102"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Reshape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_10"](%/duration_predictor/flows.4/Transpose_8_output_0, %/duration_predictor/flows.4/Constant_102_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Cast_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.4/Cast_3"](%/duration_predictor/flows.4/Reshape_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_103_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_103"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Pad_2_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/duration_predictor/flows.4/Pad_2"](%/duration_predictor/flows.4/CumSum_1_output_0, %/duration_predictor/flows.4/Cast_3_output_0, %/duration_predictor/flows.4/Constant_103_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.4/Constant_104_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.4/Constant_104"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.4/Mul_17_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_17"](%/duration_predictor/flows.4/Pad_2_output_0, %/duration_predictor/flows.4/Constant_104_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.4/Constant_105_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-5}, onnx_name="/duration_predictor/flows.4/Constant_105"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.4/Add_12_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_12"](%/duration_predictor/flows.4/Mul_17_output_0, %/duration_predictor/flows.4/Constant_105_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.4/Gather_8_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_8"](%/duration_predictor/flows.4/Add_12_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Shape_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_33"](%/duration_predictor/flows.4/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/ConstantOfShape_20_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={-5}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_20"](%/duration_predictor/flows.4/Shape_33_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Shape_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_34"](%/duration_predictor/flows.4/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Expand_16_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_16"](%/duration_predictor/flows.4/ConstantOfShape_20_output_0, %/duration_predictor/flows.4/Shape_34_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %onnx::Gather_4961 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/Add_12_output_0)
  %onnx::Gather_4962 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_4963 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_4961, %onnx::Gather_4962)
  %onnx::Range_4964 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_4963)
  %onnx::Range_4965 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_4966 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_4967 : Long(*, device=cpu) = onnx::Range(%onnx::Range_4965, %onnx::Range_4964, %onnx::Range_4966)
  %onnx::Expand_4968 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()
  %onnx::Reshape_4969 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_4970 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_4967, %onnx::Reshape_4969)
  %/duration_predictor/flows.4/Constant_106_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_106"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Add_13_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_13"](%onnx::Add_4970, %/duration_predictor/flows.4/Constant_106_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Shape_35_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_35"](%/duration_predictor/flows.4/Add_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Shape_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_36"](%/duration_predictor/flows.4/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/ConstantOfShape_21_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_21"](%/duration_predictor/flows.4/Shape_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Constant_107_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_107"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Mul_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_18"](%/duration_predictor/flows.4/ConstantOfShape_21_output_0, %/duration_predictor/flows.4/Constant_107_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Equal_12_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_12"](%/duration_predictor/flows.4/Shape_35_output_0, %/duration_predictor/flows.4/Mul_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Where_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_12"](%/duration_predictor/flows.4/Equal_12_output_0, %/duration_predictor/flows.4/ConstantOfShape_21_output_0, %/duration_predictor/flows.4/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Expand_17_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_17"](%onnx::Add_4970, %/duration_predictor/flows.4/Where_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_108"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Unsqueeze_15_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_15"](%/duration_predictor/flows.4/Expand_17_output_0, %/duration_predictor/flows.4/Constant_108_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Shape_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_37"](%/duration_predictor/flows.4/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/ConstantOfShape_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_22"](%/duration_predictor/flows.4/Shape_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Constant_109_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_109"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Mul_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_19"](%/duration_predictor/flows.4/ConstantOfShape_22_output_0, %/duration_predictor/flows.4/Constant_109_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Equal_13_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_13"](%/duration_predictor/flows.4/Shape_35_output_0, %/duration_predictor/flows.4/Mul_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Where_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_13"](%/duration_predictor/flows.4/Equal_13_output_0, %/duration_predictor/flows.4/ConstantOfShape_22_output_0, %/duration_predictor/flows.4/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Expand_18_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_18"](%onnx::Expand_4968, %/duration_predictor/flows.4/Where_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_110"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Unsqueeze_16_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_16"](%/duration_predictor/flows.4/Expand_18_output_0, %/duration_predictor/flows.4/Constant_110_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Concat_12_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.4/Concat_12"](%/duration_predictor/flows.4/Unsqueeze_15_output_0, %/duration_predictor/flows.4/Unsqueeze_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Shape_38_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_38"](%/duration_predictor/flows.4/Add_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Constant_111_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_111"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Constant_112_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_112"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Constant_113_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_113"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Slice_12_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_12"](%/duration_predictor/flows.4/Shape_38_output_0, %/duration_predictor/flows.4/Constant_112_output_0, %/duration_predictor/flows.4/Constant_113_output_0, %/duration_predictor/flows.4/Constant_111_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Concat_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_13"](%/duration_predictor/flows.4/Shape_35_output_0, %/duration_predictor/flows.4/Slice_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Reshape_11_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_11"](%/duration_predictor/flows.4/Expand_16_output_0, %/duration_predictor/flows.4/Concat_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/ScatterND_4_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND_4"](%/duration_predictor/flows.4/Add_12_output_0, %/duration_predictor/flows.4/Concat_12_output_0, %/duration_predictor/flows.4/Reshape_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.4/Gather_9_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_9"](%/duration_predictor/flows.4/ScatterND_4_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Shape_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_39"](%/duration_predictor/flows.4/Gather_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/ConstantOfShape_23_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={5}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_23"](%/duration_predictor/flows.4/Shape_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Shape_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_40"](%/duration_predictor/flows.4/Gather_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Expand_19_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_19"](%/duration_predictor/flows.4/ConstantOfShape_23_output_0, %/duration_predictor/flows.4/Shape_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %onnx::Gather_5006 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/ScatterND_4_output_0)
  %onnx::Gather_5007 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5008 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5006, %onnx::Gather_5007)
  %onnx::Range_5009 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5008)
  %onnx::Range_5010 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5011 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5012 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5010, %onnx::Range_5009, %onnx::Range_5011)
  %onnx::Expand_5013 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_5014 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5015 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5012, %onnx::Reshape_5014)
  %/duration_predictor/flows.4/Constant_114_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_114"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Add_14_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_14"](%onnx::Add_5015, %/duration_predictor/flows.4/Constant_114_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Shape_41_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_41"](%/duration_predictor/flows.4/Add_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Shape_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_42"](%/duration_predictor/flows.4/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/ConstantOfShape_24_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_24"](%/duration_predictor/flows.4/Shape_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Constant_115_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_115"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Mul_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_20"](%/duration_predictor/flows.4/ConstantOfShape_24_output_0, %/duration_predictor/flows.4/Constant_115_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Equal_14_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_14"](%/duration_predictor/flows.4/Shape_41_output_0, %/duration_predictor/flows.4/Mul_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Where_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_14"](%/duration_predictor/flows.4/Equal_14_output_0, %/duration_predictor/flows.4/ConstantOfShape_24_output_0, %/duration_predictor/flows.4/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Expand_20_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_20"](%onnx::Add_5015, %/duration_predictor/flows.4/Where_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Constant_116_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_116"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Unsqueeze_17_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_17"](%/duration_predictor/flows.4/Expand_20_output_0, %/duration_predictor/flows.4/Constant_116_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Shape_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_43"](%/duration_predictor/flows.4/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/ConstantOfShape_25_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_25"](%/duration_predictor/flows.4/Shape_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Constant_117_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_117"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Mul_21_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_21"](%/duration_predictor/flows.4/ConstantOfShape_25_output_0, %/duration_predictor/flows.4/Constant_117_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Equal_15_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_15"](%/duration_predictor/flows.4/Shape_41_output_0, %/duration_predictor/flows.4/Mul_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Where_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_15"](%/duration_predictor/flows.4/Equal_15_output_0, %/duration_predictor/flows.4/ConstantOfShape_25_output_0, %/duration_predictor/flows.4/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Expand_21_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_21"](%onnx::Expand_5013, %/duration_predictor/flows.4/Where_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Constant_118_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_118"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Unsqueeze_18_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_18"](%/duration_predictor/flows.4/Expand_21_output_0, %/duration_predictor/flows.4/Constant_118_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Concat_14_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.4/Concat_14"](%/duration_predictor/flows.4/Unsqueeze_17_output_0, %/duration_predictor/flows.4/Unsqueeze_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Shape_44_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_44"](%/duration_predictor/flows.4/ScatterND_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Constant_119_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_119"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Constant_120_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_120"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Constant_121_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_121"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Slice_13_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_13"](%/duration_predictor/flows.4/Shape_44_output_0, %/duration_predictor/flows.4/Constant_120_output_0, %/duration_predictor/flows.4/Constant_121_output_0, %/duration_predictor/flows.4/Constant_119_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Concat_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_15"](%/duration_predictor/flows.4/Shape_41_output_0, %/duration_predictor/flows.4/Slice_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Reshape_12_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_12"](%/duration_predictor/flows.4/Expand_19_output_0, %/duration_predictor/flows.4/Concat_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/ScatterND_5_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND_5"](%/duration_predictor/flows.4/ScatterND_4_output_0, %/duration_predictor/flows.4/Concat_14_output_0, %/duration_predictor/flows.4/Reshape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.4/Constant_122_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_122"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Constant_123_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_123"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Constant_124_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_124"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Constant_125_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_125"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Slice_14_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_14"](%/duration_predictor/flows.4/ScatterND_5_output_0, %/duration_predictor/flows.4/Constant_123_output_0, %/duration_predictor/flows.4/Constant_124_output_0, %/duration_predictor/flows.4/Constant_122_output_0, %/duration_predictor/flows.4/Constant_125_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Constant_126_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_126"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Constant_127_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_127"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Constant_128_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_128"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Constant_129_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_129"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Slice_15_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_15"](%/duration_predictor/flows.4/ScatterND_5_output_0, %/duration_predictor/flows.4/Constant_127_output_0, %/duration_predictor/flows.4/Constant_128_output_0, %/duration_predictor/flows.4/Constant_126_output_0, %/duration_predictor/flows.4/Constant_129_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Sub_2_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub_2"](%/duration_predictor/flows.4/Slice_14_output_0, %/duration_predictor/flows.4/Slice_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.4/Gather_10_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_10"](%/duration_predictor/flows.4/ScatterND_5_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_130_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/duration_predictor/flows.4/Constant_130"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Add_15_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_15"](%/duration_predictor/flows.4/Gather_10_output_0, %/duration_predictor/flows.4/Constant_130_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_45"](%/duration_predictor/flows.4/Gather_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Expand_22_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_22"](%/duration_predictor/flows.4/Add_15_output_0, %/duration_predictor/flows.4/Shape_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %onnx::Gather_5070 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/ScatterND_5_output_0)
  %onnx::Gather_5071 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5072 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5070, %onnx::Gather_5071)
  %onnx::Range_5073 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5072)
  %onnx::Range_5074 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5075 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5076 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5074, %onnx::Range_5073, %onnx::Range_5075)
  %onnx::Expand_5077 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_5078 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5079 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5076, %onnx::Reshape_5078)
  %/duration_predictor/flows.4/Constant_131_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_131"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Add_16_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_16"](%onnx::Add_5079, %/duration_predictor/flows.4/Constant_131_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_46_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_46"](%/duration_predictor/flows.4/Add_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_47_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_47"](%/duration_predictor/flows.4/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/ConstantOfShape_26_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_26"](%/duration_predictor/flows.4/Shape_47_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_132_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_132"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Mul_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_22"](%/duration_predictor/flows.4/ConstantOfShape_26_output_0, %/duration_predictor/flows.4/Constant_132_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Equal_16_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_16"](%/duration_predictor/flows.4/Shape_46_output_0, %/duration_predictor/flows.4/Mul_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Where_16_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_16"](%/duration_predictor/flows.4/Equal_16_output_0, %/duration_predictor/flows.4/ConstantOfShape_26_output_0, %/duration_predictor/flows.4/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Expand_23_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_23"](%onnx::Add_5079, %/duration_predictor/flows.4/Where_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_133_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_133"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Unsqueeze_19_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_19"](%/duration_predictor/flows.4/Expand_23_output_0, %/duration_predictor/flows.4/Constant_133_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_48_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_48"](%/duration_predictor/flows.4/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/ConstantOfShape_27_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_27"](%/duration_predictor/flows.4/Shape_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_134_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_134"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Mul_23_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_23"](%/duration_predictor/flows.4/ConstantOfShape_27_output_0, %/duration_predictor/flows.4/Constant_134_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Equal_17_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_17"](%/duration_predictor/flows.4/Shape_46_output_0, %/duration_predictor/flows.4/Mul_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Where_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_17"](%/duration_predictor/flows.4/Equal_17_output_0, %/duration_predictor/flows.4/ConstantOfShape_27_output_0, %/duration_predictor/flows.4/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Expand_24_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_24"](%onnx::Expand_5077, %/duration_predictor/flows.4/Where_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_135_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_135"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Unsqueeze_20_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_20"](%/duration_predictor/flows.4/Expand_24_output_0, %/duration_predictor/flows.4/Constant_135_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Concat_16_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.4/Concat_16"](%/duration_predictor/flows.4/Unsqueeze_19_output_0, %/duration_predictor/flows.4/Unsqueeze_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_49_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_49"](%/duration_predictor/flows.4/ScatterND_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_136_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_136"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_137_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_137"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_138_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_138"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Slice_16_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_16"](%/duration_predictor/flows.4/Shape_49_output_0, %/duration_predictor/flows.4/Constant_137_output_0, %/duration_predictor/flows.4/Constant_138_output_0, %/duration_predictor/flows.4/Constant_136_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Concat_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_17"](%/duration_predictor/flows.4/Shape_46_output_0, %/duration_predictor/flows.4/Slice_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Reshape_13_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_13"](%/duration_predictor/flows.4/Expand_22_output_0, %/duration_predictor/flows.4/Concat_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/ScatterND_6_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND_6"](%/duration_predictor/flows.4/ScatterND_5_output_0, %/duration_predictor/flows.4/Concat_16_output_0, %/duration_predictor/flows.4/Reshape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Gather_11_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_11"](%/duration_predictor/flows.4/ScatterND_6_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_50"](%/duration_predictor/flows.4/Gather_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Expand_25_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_25"](%/duration_predictor/flows.4/Add_15_output_0, %/duration_predictor/flows.4/Shape_50_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %onnx::Gather_5113 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.4/ScatterND_6_output_0)
  %onnx::Gather_5114 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5115 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5113, %onnx::Gather_5114)
  %onnx::Range_5116 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5115)
  %onnx::Range_5117 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5118 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5119 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5117, %onnx::Range_5116, %onnx::Range_5118)
  %onnx::Expand_5120 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_5121 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5122 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5119, %onnx::Reshape_5121)
  %/duration_predictor/flows.4/Constant_139_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_139"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Add_17_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_17"](%onnx::Add_5122, %/duration_predictor/flows.4/Constant_139_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_51_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_51"](%/duration_predictor/flows.4/Add_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_52"](%/duration_predictor/flows.4/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/ConstantOfShape_28_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_28"](%/duration_predictor/flows.4/Shape_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_140_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_140"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Mul_24_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_24"](%/duration_predictor/flows.4/ConstantOfShape_28_output_0, %/duration_predictor/flows.4/Constant_140_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Equal_18_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_18"](%/duration_predictor/flows.4/Shape_51_output_0, %/duration_predictor/flows.4/Mul_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Where_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_18"](%/duration_predictor/flows.4/Equal_18_output_0, %/duration_predictor/flows.4/ConstantOfShape_28_output_0, %/duration_predictor/flows.4/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Expand_26_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_26"](%onnx::Add_5122, %/duration_predictor/flows.4/Where_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_141"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Unsqueeze_21_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_21"](%/duration_predictor/flows.4/Expand_26_output_0, %/duration_predictor/flows.4/Constant_141_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_53"](%/duration_predictor/flows.4/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/ConstantOfShape_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.4/ConstantOfShape_29"](%/duration_predictor/flows.4/Shape_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_142_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_142"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Mul_25_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_25"](%/duration_predictor/flows.4/ConstantOfShape_29_output_0, %/duration_predictor/flows.4/Constant_142_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Equal_19_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.4/Equal_19"](%/duration_predictor/flows.4/Shape_51_output_0, %/duration_predictor/flows.4/Mul_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Where_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.4/Where_19"](%/duration_predictor/flows.4/Equal_19_output_0, %/duration_predictor/flows.4/ConstantOfShape_29_output_0, %/duration_predictor/flows.4/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Expand_27_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_27"](%onnx::Expand_5120, %/duration_predictor/flows.4/Where_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_143"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Unsqueeze_22_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_22"](%/duration_predictor/flows.4/Expand_27_output_0, %/duration_predictor/flows.4/Constant_143_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Concat_18_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.4/Concat_18"](%/duration_predictor/flows.4/Unsqueeze_21_output_0, %/duration_predictor/flows.4/Unsqueeze_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Shape_54_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_54"](%/duration_predictor/flows.4/ScatterND_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_144_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_144"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_145_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_145"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_146_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_146"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Slice_17_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_17"](%/duration_predictor/flows.4/Shape_54_output_0, %/duration_predictor/flows.4/Constant_145_output_0, %/duration_predictor/flows.4/Constant_146_output_0, %/duration_predictor/flows.4/Constant_144_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Concat_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.4/Concat_19"](%/duration_predictor/flows.4/Shape_51_output_0, %/duration_predictor/flows.4/Slice_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Reshape_14_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_14"](%/duration_predictor/flows.4/Expand_25_output_0, %/duration_predictor/flows.4/Concat_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/ScatterND_7_output_0 : Float(*, *, requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND_7"](%/duration_predictor/flows.4/ScatterND_6_output_0, %/duration_predictor/flows.4/Concat_18_output_0, %/duration_predictor/flows.4/Reshape_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.4/Constant_147_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_147"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.4/Unsqueeze_23_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_23"](%/duration_predictor/flows.4/GatherND_1_output_0, %/duration_predictor/flows.4/Constant_147_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.4/GreaterOrEqual_1_output_0 : Bool(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::GreaterOrEqual[onnx_name="/duration_predictor/flows.4/GreaterOrEqual_1"](%/duration_predictor/flows.4/Unsqueeze_23_output_0, %/duration_predictor/flows.4/ScatterND_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %onnx::ReduceSum_5156 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()
  %/duration_predictor/flows.4/Cast_4_output_0 : Long(*, *, device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.4/Cast_4"](%/duration_predictor/flows.4/GreaterOrEqual_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.4/ReduceSum_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::ReduceSum[keepdims=0, onnx_name="/duration_predictor/flows.4/ReduceSum"](%/duration_predictor/flows.4/Cast_4_output_0, %onnx::ReduceSum_5156), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.4/Constant_148_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_148"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.4/Sub_3_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub_3"](%/duration_predictor/flows.4/ReduceSum_output_0, %/duration_predictor/flows.4/Constant_148_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.4/Constant_149_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_149"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:142:0
  %/duration_predictor/flows.4/Unsqueeze_24_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_24"](%/duration_predictor/flows.4/Sub_3_output_0, %/duration_predictor/flows.4/Constant_149_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:142:0
  %/duration_predictor/flows.4/GatherElements_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.4/GatherElements"](%/duration_predictor/flows.4/ScatterND_3_output_0, %/duration_predictor/flows.4/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:146:0
  %/duration_predictor/flows.4/Gather_12_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_12"](%/duration_predictor/flows.4/GatherElements_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:146:0
  %/duration_predictor/flows.4/GatherElements_1_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.4/GatherElements_1"](%/duration_predictor/flows.4/Sub_1_output_0, %/duration_predictor/flows.4/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:147:0
  %/duration_predictor/flows.4/Gather_13_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_13"](%/duration_predictor/flows.4/GatherElements_1_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:147:0
  %/duration_predictor/flows.4/GatherElements_2_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.4/GatherElements_2"](%/duration_predictor/flows.4/ScatterND_7_output_0, %/duration_predictor/flows.4/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:149:0
  %/duration_predictor/flows.4/Gather_14_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_14"](%/duration_predictor/flows.4/GatherElements_2_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:149:0
  %/duration_predictor/flows.4/Div_2_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/Div_2"](%/duration_predictor/flows.4/Sub_2_output_0, %/duration_predictor/flows.4/Sub_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:150:0
  %/duration_predictor/flows.4/GatherElements_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.4/GatherElements_3"](%/duration_predictor/flows.4/Div_2_output_0, %/duration_predictor/flows.4/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:151:0
  %/duration_predictor/flows.4/Gather_15_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_15"](%/duration_predictor/flows.4/GatherElements_3_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:151:0
  %/duration_predictor/flows.4/GatherElements_4_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.4/GatherElements_4"](%/duration_predictor/flows.4/Add_10_output_0, %/duration_predictor/flows.4/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:153:0
  %/duration_predictor/flows.4/Gather_16_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_16"](%/duration_predictor/flows.4/GatherElements_4_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:153:0
  %/duration_predictor/flows.4/Constant_150_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_150"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.4/Constant_151_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_151"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.4/Constant_152_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.4/Constant_152"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.4/Constant_153_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.4/Constant_153"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.4/Slice_18_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_18"](%/duration_predictor/flows.4/Add_10_output_0, %/duration_predictor/flows.4/Constant_151_output_0, %/duration_predictor/flows.4/Constant_152_output_0, %/duration_predictor/flows.4/Constant_150_output_0, %/duration_predictor/flows.4/Constant_153_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.4/GatherElements_5_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.4/GatherElements_5"](%/duration_predictor/flows.4/Slice_18_output_0, %/duration_predictor/flows.4/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.4/Gather_17_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_17"](%/duration_predictor/flows.4/GatherElements_5_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.4/GatherElements_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.4/GatherElements_6"](%/duration_predictor/flows.4/Sub_2_output_0, %/duration_predictor/flows.4/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:156:0
  %/duration_predictor/flows.4/Gather_18_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.4/Gather_18"](%/duration_predictor/flows.4/GatherElements_6_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:156:0
  %/duration_predictor/flows.4/Sub_4_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub_4"](%/duration_predictor/flows.4/GatherND_1_output_0, %/duration_predictor/flows.4/Gather_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:159:0
  %/duration_predictor/flows.4/Add_18_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_18"](%/duration_predictor/flows.4/Gather_16_output_0, %/duration_predictor/flows.4/Gather_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.4/Constant_154_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_154"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.4/Mul_26_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_26"](%/duration_predictor/flows.4/Gather_15_output_0, %/duration_predictor/flows.4/Constant_154_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.4/Sub_5_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub_5"](%/duration_predictor/flows.4/Add_18_output_0, %/duration_predictor/flows.4/Mul_26_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.4/Mul_27_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_27"](%/duration_predictor/flows.4/Sub_4_output_0, %/duration_predictor/flows.4/Sub_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:159:0
  %/duration_predictor/flows.4/Sub_6_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub_6"](%/duration_predictor/flows.4/Gather_15_output_0, %/duration_predictor/flows.4/Gather_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:161:0
  %/duration_predictor/flows.4/Mul_28_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_28"](%/duration_predictor/flows.4/Gather_18_output_0, %/duration_predictor/flows.4/Sub_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:161:0
  %/duration_predictor/flows.4/Add_19_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_19"](%/duration_predictor/flows.4/Mul_27_output_0, %/duration_predictor/flows.4/Mul_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:159:0
  %/duration_predictor/flows.4/Mul_29_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_29"](%/duration_predictor/flows.4/Gather_18_output_0, %/duration_predictor/flows.4/Gather_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:162:0
  %/duration_predictor/flows.4/Sub_7_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub_7"](%/duration_predictor/flows.4/Mul_29_output_0, %/duration_predictor/flows.4/Mul_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:162:0
  %/duration_predictor/flows.4/Neg_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/duration_predictor/flows.4/Neg"](%/duration_predictor/flows.4/Gather_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:165:0
  %/duration_predictor/flows.4/Mul_30_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_30"](%/duration_predictor/flows.4/Neg_output_0, %/duration_predictor/flows.4/Sub_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:165:0
  %/duration_predictor/flows.4/Constant_155_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_155"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.4/Pow_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.4/Pow"](%/duration_predictor/flows.4/Sub_7_output_0, %/duration_predictor/flows.4/Constant_155_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.4/Constant_156_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/duration_predictor/flows.4/Constant_156"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.4/Mul_31_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_31"](%/duration_predictor/flows.4/Add_19_output_0, %/duration_predictor/flows.4/Constant_156_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.4/Mul_32_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_32"](%/duration_predictor/flows.4/Mul_31_output_0, %/duration_predictor/flows.4/Mul_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.4/Sub_8_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub_8"](%/duration_predictor/flows.4/Pow_output_0, %/duration_predictor/flows.4/Mul_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.4/Constant_157_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.4/Constant_157"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.4/Mul_33_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_33"](%/duration_predictor/flows.4/Mul_30_output_0, %/duration_predictor/flows.4/Constant_157_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.4/Neg_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/duration_predictor/flows.4/Neg_1"](%/duration_predictor/flows.4/Sub_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.4/Sqrt_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.4/Sqrt"](%/duration_predictor/flows.4/Sub_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.4/Sub_9_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.4/Sub_9"](%/duration_predictor/flows.4/Neg_1_output_0, %/duration_predictor/flows.4/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.4/Div_3_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.4/Div_3"](%/duration_predictor/flows.4/Mul_33_output_0, %/duration_predictor/flows.4/Sub_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.4/Mul_34_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_34"](%/duration_predictor/flows.4/Div_3_output_0, %/duration_predictor/flows.4/Gather_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:171:0
  %/duration_predictor/flows.4/Add_20_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.4/Add_20"](%/duration_predictor/flows.4/Mul_34_output_0, %/duration_predictor/flows.4/Gather_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:171:0
  %/duration_predictor/flows.4/Shape_55_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_55"](%/duration_predictor/flows.4/ConstantOfShape_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Expand_28_output_0 : Bool(*, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_28"](%/duration_predictor/flows.4/Not_output_0, %/duration_predictor/flows.4/Shape_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/NonZero_5_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.4/NonZero_5"](%/duration_predictor/flows.4/Expand_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Transpose_9_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_9"](%/duration_predictor/flows.4/NonZero_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Constant_158_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_158"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Reshape_15_output_0 : Float(*, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_15"](%/duration_predictor/flows.4/GatherND_output_0, %/duration_predictor/flows.4/Constant_158_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Shape_56_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_56"](%/duration_predictor/flows.4/Transpose_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Constant_159_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_159"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Gather_19_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.4/Gather_19"](%/duration_predictor/flows.4/Shape_56_output_0, %/duration_predictor/flows.4/Constant_159_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Constant_160_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_160"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Constant_161_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_161"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Constant_162_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_162"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_25"](%/duration_predictor/flows.4/Gather_19_output_0, %/duration_predictor/flows.4/Constant_162_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Slice_19_output_0 : Float(*, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_19"](%/duration_predictor/flows.4/Reshape_15_output_0, %/duration_predictor/flows.4/Constant_161_output_0, %/duration_predictor/flows.4/Unsqueeze_25_output_0, %/duration_predictor/flows.4/Constant_160_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/ScatterND_8_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND_8"](%/duration_predictor/flows.4/ConstantOfShape_11_output_0, %/duration_predictor/flows.4/Transpose_9_output_0, %/duration_predictor/flows.4/Slice_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.4/Shape_57_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_57"](%/duration_predictor/flows.4/ScatterND_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Expand_29_output_0 : Bool(*, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.4/Expand_29"](%/duration_predictor/flows.4/And_output_0, %/duration_predictor/flows.4/Shape_57_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/NonZero_6_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.4/NonZero_6"](%/duration_predictor/flows.4/Expand_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Transpose_10_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.4/Transpose_10"](%/duration_predictor/flows.4/NonZero_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Constant_163_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.4/Constant_163"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Reshape_16_output_0 : Float(*, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.4/Reshape_16"](%/duration_predictor/flows.4/Add_20_output_0, %/duration_predictor/flows.4/Constant_163_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Shape_58_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.4/Shape_58"](%/duration_predictor/flows.4/Transpose_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Constant_164_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_164"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Gather_20_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.4/Gather_20"](%/duration_predictor/flows.4/Shape_58_output_0, %/duration_predictor/flows.4/Constant_164_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Constant_165_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_165"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Constant_166_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_166"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Constant_167_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.4/Constant_167"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.4/Unsqueeze_26"](%/duration_predictor/flows.4/Gather_20_output_0, %/duration_predictor/flows.4/Constant_167_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Slice_20_output_0 : Float(*, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.4/Slice_20"](%/duration_predictor/flows.4/Reshape_16_output_0, %/duration_predictor/flows.4/Constant_166_output_0, %/duration_predictor/flows.4/Unsqueeze_26_output_0, %/duration_predictor/flows.4/Constant_165_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/ScatterND_9_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.4/ScatterND_9"](%/duration_predictor/flows.4/ScatterND_8_output_0, %/duration_predictor/flows.4/Transpose_10_output_0, %/duration_predictor/flows.4/Slice_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.4/Concat_20_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name="/duration_predictor/flows.4/Concat_20"](%/duration_predictor/flows.4/Split_output_0, %/duration_predictor/flows.4/ScatterND_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:143:0
  %/duration_predictor/flows.4/Mul_35_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.4/Mul_35"](%/duration_predictor/flows.4/Concat_20_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.4 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:143:0
  %/duration_predictor/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Slice_1_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/Slice_1"](%/duration_predictor/flows.4/Mul_35_output_0, %/duration_predictor/Constant_9_output_0, %/duration_predictor/Constant_10_output_0, %/duration_predictor/Constant_8_output_0, %/duration_predictor/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/flows.3/Split_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu), %/duration_predictor/flows.3/Split_output_1 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Split[axis=1, onnx_name="/duration_predictor/flows.3/Split"](%/duration_predictor/Slice_1_output_0, %onnx::Split_4359), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:917:0
  %/duration_predictor/flows.3/pre/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.3/pre/Conv"](%/duration_predictor/flows.3/Split_output_0, %duration_predictor.flows.3.pre.weight, %duration_predictor.flows.3.pre.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/torch.nn.modules.conv.Conv1d::pre # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.3/convs/Add_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add"](%/duration_predictor/flows.3/pre/Conv_output_0, %/duration_predictor/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:53:0
  %/duration_predictor/flows.3/convs/Mul_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul"](%/duration_predictor/flows.3/convs/Add_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/flows.3/convs/convs_sep.0/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=192, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/duration_predictor/flows.3/convs/convs_sep.0/Conv"](%/duration_predictor/flows.3/convs/Mul_output_0, %duration_predictor.flows.3.convs.convs_sep.0.weight, %duration_predictor.flows.3.convs.convs_sep.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.3/convs/norms_1.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Transpose"](%/duration_predictor/flows.3/convs/convs_sep.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.3/convs/norms_1.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_1.0/ReduceMean"](%/duration_predictor/flows.3/convs/norms_1.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Sub"](%/duration_predictor/flows.3/convs/norms_1.0/Transpose_output_0, %/duration_predictor/flows.3/convs/norms_1.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Pow"](%/duration_predictor/flows.3/convs/norms_1.0/Sub_output_0, %/duration_predictor/flows.3/convs/norms_1.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_1.0/ReduceMean_1"](%/duration_predictor/flows.3/convs/norms_1.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Add"](%/duration_predictor/flows.3/convs/norms_1.0/ReduceMean_1_output_0, %/duration_predictor/flows.3/convs/norms_1.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Sqrt"](%/duration_predictor/flows.3/convs/norms_1.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Div"](%/duration_predictor/flows.3/convs/norms_1.0/Sub_output_0, %/duration_predictor/flows.3/convs/norms_1.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Mul"](%/duration_predictor/flows.3/convs/norms_1.0/Div_output_0, %duration_predictor.flows.3.convs.norms_1.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Add_1"](%/duration_predictor/flows.3/convs/norms_1.0/Mul_output_0, %duration_predictor.flows.3.convs.norms_1.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_1.0/Transpose_1"](%/duration_predictor/flows.3/convs/norms_1.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.3/convs/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.3/convs/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Div_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/Div"](%/duration_predictor/flows.3/convs/norms_1.0/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Erf_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.3/convs/Erf"](%/duration_predictor/flows.3/convs/Div_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/convs/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Add_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add_1"](%/duration_predictor/flows.3/convs/Erf_output_0, %/duration_predictor/flows.3/convs/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Mul_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_1"](%/duration_predictor/flows.3/convs/norms_1.0/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.3/convs/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_2"](%/duration_predictor/flows.3/convs/Mul_1_output_0, %/duration_predictor/flows.3/convs/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/convs_1x1.0/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.3/convs/convs_1x1.0/Conv"](%/duration_predictor/flows.3/convs/Mul_2_output_0, %duration_predictor.flows.3.convs.convs_1x1.0.weight, %duration_predictor.flows.3.convs.convs_1x1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.3/convs/norms_2.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Transpose"](%/duration_predictor/flows.3/convs/convs_1x1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.3/convs/norms_2.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_2.0/ReduceMean"](%/duration_predictor/flows.3/convs/norms_2.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Sub"](%/duration_predictor/flows.3/convs/norms_2.0/Transpose_output_0, %/duration_predictor/flows.3/convs/norms_2.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Pow"](%/duration_predictor/flows.3/convs/norms_2.0/Sub_output_0, %/duration_predictor/flows.3/convs/norms_2.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_2.0/ReduceMean_1"](%/duration_predictor/flows.3/convs/norms_2.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Add"](%/duration_predictor/flows.3/convs/norms_2.0/ReduceMean_1_output_0, %/duration_predictor/flows.3/convs/norms_2.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Sqrt"](%/duration_predictor/flows.3/convs/norms_2.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Div"](%/duration_predictor/flows.3/convs/norms_2.0/Sub_output_0, %/duration_predictor/flows.3/convs/norms_2.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Mul"](%/duration_predictor/flows.3/convs/norms_2.0/Div_output_0, %duration_predictor.flows.3.convs.norms_2.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Add_1"](%/duration_predictor/flows.3/convs/norms_2.0/Mul_output_0, %duration_predictor.flows.3.convs.norms_2.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_2.0/Transpose_1"](%/duration_predictor/flows.3/convs/norms_2.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.3/convs/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.3/convs/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Div_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/Div_1"](%/duration_predictor/flows.3/convs/norms_2.0/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Erf_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.3/convs/Erf_1"](%/duration_predictor/flows.3/convs/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Constant_4_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/convs/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Add_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add_2"](%/duration_predictor/flows.3/convs/Erf_1_output_0, %/duration_predictor/flows.3/convs/Constant_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Mul_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_3"](%/duration_predictor/flows.3/convs/norms_2.0/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Constant_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.3/convs/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Mul_4_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_4"](%/duration_predictor/flows.3/convs/Mul_3_output_0, %/duration_predictor/flows.3/convs/Constant_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Add_3_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add_3"](%/duration_predictor/flows.3/convs/Add_output_0, %/duration_predictor/flows.3/convs/Mul_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/flows.3/convs/Mul_5_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_5"](%/duration_predictor/flows.3/convs/Add_3_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/flows.3/convs/convs_sep.1/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=192, kernel_shape=[3], pads=[3, 3], strides=[1], onnx_name="/duration_predictor/flows.3/convs/convs_sep.1/Conv"](%/duration_predictor/flows.3/convs/Mul_5_output_0, %duration_predictor.flows.3.convs.convs_sep.1.weight, %duration_predictor.flows.3.convs.convs_sep.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.3/convs/norms_1.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Transpose"](%/duration_predictor/flows.3/convs/convs_sep.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.3/convs/norms_1.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_1.1/ReduceMean"](%/duration_predictor/flows.3/convs/norms_1.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Sub"](%/duration_predictor/flows.3/convs/norms_1.1/Transpose_output_0, %/duration_predictor/flows.3/convs/norms_1.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Pow"](%/duration_predictor/flows.3/convs/norms_1.1/Sub_output_0, %/duration_predictor/flows.3/convs/norms_1.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_1.1/ReduceMean_1"](%/duration_predictor/flows.3/convs/norms_1.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Add"](%/duration_predictor/flows.3/convs/norms_1.1/ReduceMean_1_output_0, %/duration_predictor/flows.3/convs/norms_1.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Sqrt"](%/duration_predictor/flows.3/convs/norms_1.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Div"](%/duration_predictor/flows.3/convs/norms_1.1/Sub_output_0, %/duration_predictor/flows.3/convs/norms_1.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Mul"](%/duration_predictor/flows.3/convs/norms_1.1/Div_output_0, %duration_predictor.flows.3.convs.norms_1.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Add_1"](%/duration_predictor/flows.3/convs/norms_1.1/Mul_output_0, %duration_predictor.flows.3.convs.norms_1.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_1.1/Transpose_1"](%/duration_predictor/flows.3/convs/norms_1.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.3/convs/Constant_6_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.3/convs/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Div_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/Div_2"](%/duration_predictor/flows.3/convs/norms_1.1/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Erf_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.3/convs/Erf_2"](%/duration_predictor/flows.3/convs/Div_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/convs/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Add_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add_4"](%/duration_predictor/flows.3/convs/Erf_2_output_0, %/duration_predictor/flows.3/convs/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Mul_6_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_6"](%/duration_predictor/flows.3/convs/norms_1.1/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Add_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.3/convs/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Mul_7_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_7"](%/duration_predictor/flows.3/convs/Mul_6_output_0, %/duration_predictor/flows.3/convs/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/convs_1x1.1/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.3/convs/convs_1x1.1/Conv"](%/duration_predictor/flows.3/convs/Mul_7_output_0, %duration_predictor.flows.3.convs.convs_1x1.1.weight, %duration_predictor.flows.3.convs.convs_1x1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.3/convs/norms_2.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Transpose"](%/duration_predictor/flows.3/convs/convs_1x1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.3/convs/norms_2.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_2.1/ReduceMean"](%/duration_predictor/flows.3/convs/norms_2.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Sub"](%/duration_predictor/flows.3/convs/norms_2.1/Transpose_output_0, %/duration_predictor/flows.3/convs/norms_2.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Pow"](%/duration_predictor/flows.3/convs/norms_2.1/Sub_output_0, %/duration_predictor/flows.3/convs/norms_2.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_2.1/ReduceMean_1"](%/duration_predictor/flows.3/convs/norms_2.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Add"](%/duration_predictor/flows.3/convs/norms_2.1/ReduceMean_1_output_0, %/duration_predictor/flows.3/convs/norms_2.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Sqrt"](%/duration_predictor/flows.3/convs/norms_2.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Div"](%/duration_predictor/flows.3/convs/norms_2.1/Sub_output_0, %/duration_predictor/flows.3/convs/norms_2.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Mul"](%/duration_predictor/flows.3/convs/norms_2.1/Div_output_0, %duration_predictor.flows.3.convs.norms_2.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Add_1"](%/duration_predictor/flows.3/convs/norms_2.1/Mul_output_0, %duration_predictor.flows.3.convs.norms_2.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_2.1/Transpose_1"](%/duration_predictor/flows.3/convs/norms_2.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.3/convs/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.3/convs/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Div_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/Div_3"](%/duration_predictor/flows.3/convs/norms_2.1/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Constant_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Erf_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.3/convs/Erf_3"](%/duration_predictor/flows.3/convs/Div_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/convs/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Add_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add_5"](%/duration_predictor/flows.3/convs/Erf_3_output_0, %/duration_predictor/flows.3/convs/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Mul_8_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_8"](%/duration_predictor/flows.3/convs/norms_2.1/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Add_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Constant_11_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.3/convs/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Mul_9_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_9"](%/duration_predictor/flows.3/convs/Mul_8_output_0, %/duration_predictor/flows.3/convs/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Add_6_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add_6"](%/duration_predictor/flows.3/convs/Add_3_output_0, %/duration_predictor/flows.3/convs/Mul_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/flows.3/convs/Mul_10_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_10"](%/duration_predictor/flows.3/convs/Add_6_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/flows.3/convs/convs_sep.2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[9], group=192, kernel_shape=[3], pads=[9, 9], strides=[1], onnx_name="/duration_predictor/flows.3/convs/convs_sep.2/Conv"](%/duration_predictor/flows.3/convs/Mul_10_output_0, %duration_predictor.flows.3.convs.convs_sep.2.weight, %duration_predictor.flows.3.convs.convs_sep.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.3/convs/norms_1.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Transpose"](%/duration_predictor/flows.3/convs/convs_sep.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.3/convs/norms_1.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_1.2/ReduceMean"](%/duration_predictor/flows.3/convs/norms_1.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Sub"](%/duration_predictor/flows.3/convs/norms_1.2/Transpose_output_0, %/duration_predictor/flows.3/convs/norms_1.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Pow"](%/duration_predictor/flows.3/convs/norms_1.2/Sub_output_0, %/duration_predictor/flows.3/convs/norms_1.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_1.2/ReduceMean_1"](%/duration_predictor/flows.3/convs/norms_1.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Add"](%/duration_predictor/flows.3/convs/norms_1.2/ReduceMean_1_output_0, %/duration_predictor/flows.3/convs/norms_1.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Sqrt"](%/duration_predictor/flows.3/convs/norms_1.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Div"](%/duration_predictor/flows.3/convs/norms_1.2/Sub_output_0, %/duration_predictor/flows.3/convs/norms_1.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Mul"](%/duration_predictor/flows.3/convs/norms_1.2/Div_output_0, %duration_predictor.flows.3.convs.norms_1.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Add_1"](%/duration_predictor/flows.3/convs/norms_1.2/Mul_output_0, %duration_predictor.flows.3.convs.norms_1.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_1.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_1.2/Transpose_1"](%/duration_predictor/flows.3/convs/norms_1.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.3/convs/Constant_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.3/convs/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Div_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/Div_4"](%/duration_predictor/flows.3/convs/norms_1.2/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Erf_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.3/convs/Erf_4"](%/duration_predictor/flows.3/convs/Div_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/convs/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Add_7_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add_7"](%/duration_predictor/flows.3/convs/Erf_4_output_0, %/duration_predictor/flows.3/convs/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Mul_11_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_11"](%/duration_predictor/flows.3/convs/norms_1.2/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Add_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.3/convs/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/Mul_12_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_12"](%/duration_predictor/flows.3/convs/Mul_11_output_0, %/duration_predictor/flows.3/convs/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.3/convs/convs_1x1.2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.3/convs/convs_1x1.2/Conv"](%/duration_predictor/flows.3/convs/Mul_12_output_0, %duration_predictor.flows.3.convs.convs_1x1.2.weight, %duration_predictor.flows.3.convs.convs_1x1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.3/convs/norms_2.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Transpose"](%/duration_predictor/flows.3/convs/convs_1x1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.3/convs/norms_2.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_2.2/ReduceMean"](%/duration_predictor/flows.3/convs/norms_2.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Sub"](%/duration_predictor/flows.3/convs/norms_2.2/Transpose_output_0, %/duration_predictor/flows.3/convs/norms_2.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Pow"](%/duration_predictor/flows.3/convs/norms_2.2/Sub_output_0, %/duration_predictor/flows.3/convs/norms_2.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.3/convs/norms_2.2/ReduceMean_1"](%/duration_predictor/flows.3/convs/norms_2.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Add"](%/duration_predictor/flows.3/convs/norms_2.2/ReduceMean_1_output_0, %/duration_predictor/flows.3/convs/norms_2.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Sqrt"](%/duration_predictor/flows.3/convs/norms_2.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Div"](%/duration_predictor/flows.3/convs/norms_2.2/Sub_output_0, %/duration_predictor/flows.3/convs/norms_2.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Mul"](%/duration_predictor/flows.3/convs/norms_2.2/Div_output_0, %duration_predictor.flows.3.convs.norms_2.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Add_1"](%/duration_predictor/flows.3/convs/norms_2.2/Mul_output_0, %duration_predictor.flows.3.convs.norms_2.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.3/convs/norms_2.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.3/convs/norms_2.2/Transpose_1"](%/duration_predictor/flows.3/convs/norms_2.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.3/convs/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.3/convs/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Div_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/convs/Div_5"](%/duration_predictor/flows.3/convs/norms_2.2/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Erf_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.3/convs/Erf_5"](%/duration_predictor/flows.3/convs/Div_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/convs/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Add_8_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add_8"](%/duration_predictor/flows.3/convs/Erf_5_output_0, %/duration_predictor/flows.3/convs/Constant_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Mul_13_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_13"](%/duration_predictor/flows.3/convs/norms_2.2/Transpose_1_output_0, %/duration_predictor/flows.3/convs/Add_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Constant_17_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.3/convs/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Mul_14_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_14"](%/duration_predictor/flows.3/convs/Mul_13_output_0, %/duration_predictor/flows.3/convs/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.3/convs/Add_9_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/convs/Add_9"](%/duration_predictor/flows.3/convs/Add_6_output_0, %/duration_predictor/flows.3/convs/Mul_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/flows.3/convs/Mul_15_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/convs/Mul_15"](%/duration_predictor/flows.3/convs/Add_9_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:63:0
  %/duration_predictor/flows.3/proj/Conv_output_0 : Float(*, 29, *, strides=[2900, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.3/proj/Conv"](%/duration_predictor/flows.3/convs/Mul_15_output_0, %duration_predictor.flows.3.proj.weight, %duration_predictor.flows.3.proj.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3/torch.nn.modules.conv.Conv1d::proj # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.3/Mul_output_0 : Float(*, 29, *, strides=[2900, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul"](%/duration_predictor/flows.3/proj/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:124:0
  %/duration_predictor/flows.3/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape"](%/duration_predictor/flows.3/Split_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.3/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.3/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.3/Gather"](%/duration_predictor/flows.3/Shape_output_0, %/duration_predictor/flows.3/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.3/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_1"](%/duration_predictor/flows.3/Split_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.3/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.3/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.3/Gather_1"](%/duration_predictor/flows.3/Shape_1_output_0, %/duration_predictor/flows.3/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.3/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_2"](%/duration_predictor/flows.3/Split_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.3/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.3/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.3/Gather_2"](%/duration_predictor/flows.3/Shape_2_output_0, %/duration_predictor/flows.3/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %onnx::Unsqueeze_5405 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/flows.3/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze"](%/duration_predictor/flows.3/Gather_output_0, %onnx::Unsqueeze_5405), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3
  %onnx::Unsqueeze_5407 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/flows.3/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_1"](%/duration_predictor/flows.3/Gather_1_output_0, %onnx::Unsqueeze_5407), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3
  %/duration_predictor/flows.3/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3
  %onnx::Unsqueeze_5411 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/flows.3/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_2"](%/duration_predictor/flows.3/Gather_2_output_0, %onnx::Unsqueeze_5411), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3
  %/duration_predictor/flows.3/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat"](%/duration_predictor/flows.3/Unsqueeze_output_0, %/duration_predictor/flows.3/Unsqueeze_1_output_0, %/duration_predictor/flows.3/Constant_3_output_0, %/duration_predictor/flows.3/Unsqueeze_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:127:0
  %/duration_predictor/flows.3/Reshape_output_0 : Float(*, *, *, *, strides=[2900, 2900, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape"](%/duration_predictor/flows.3/Mul_output_0, %/duration_predictor/flows.3/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:127:0
  %/duration_predictor/flows.3/Transpose_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/duration_predictor/flows.3/Transpose"](%/duration_predictor/flows.3/Reshape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:127:0
  %/duration_predictor/flows.3/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/duration_predictor/flows.3/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.3/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.3/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.3/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.3/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.3/Slice_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice"](%/duration_predictor/flows.3/Transpose_output_0, %/duration_predictor/flows.3/Constant_5_output_0, %/duration_predictor/flows.3/Constant_6_output_0, %/duration_predictor/flows.3/Constant_4_output_0, %/duration_predictor/flows.3/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.3/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={13.8564}, onnx_name="/duration_predictor/flows.3/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.3/Div_output_0 : Float(*, *, *, *, strides=[1000, 1000, 1, 100], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/Div"](%/duration_predictor/flows.3/Slice_output_0, %/duration_predictor/flows.3/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.3/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/duration_predictor/flows.3/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.3/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.3/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.3/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={20}, onnx_name="/duration_predictor/flows.3/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.3/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.3/Slice_1_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_1"](%/duration_predictor/flows.3/Transpose_output_0, %/duration_predictor/flows.3/Constant_10_output_0, %/duration_predictor/flows.3/Constant_11_output_0, %/duration_predictor/flows.3/Constant_9_output_0, %/duration_predictor/flows.3/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.3/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={13.8564}, onnx_name="/duration_predictor/flows.3/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.3/Div_1_output_0 : Float(*, *, *, *, strides=[1000, 1000, 1, 100], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/Div_1"](%/duration_predictor/flows.3/Slice_1_output_0, %/duration_predictor/flows.3/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.3/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/duration_predictor/flows.3/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.3/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={20}, onnx_name="/duration_predictor/flows.3/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.3/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.3/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.3/Slice_2_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_2"](%/duration_predictor/flows.3/Transpose_output_0, %/duration_predictor/flows.3/Constant_15_output_0, %/duration_predictor/flows.3/Constant_16_output_0, %/duration_predictor/flows.3/Constant_14_output_0, %/duration_predictor/flows.3/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.3/Constant_18_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-5}, onnx_name="/duration_predictor/flows.3/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.3/GreaterOrEqual_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::GreaterOrEqual[onnx_name="/duration_predictor/flows.3/GreaterOrEqual"](%/duration_predictor/flows.3/Split_output_1, %/duration_predictor/flows.3/Constant_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.3/Constant_19_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/duration_predictor/flows.3/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.3/LessOrEqual_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::LessOrEqual[onnx_name="/duration_predictor/flows.3/LessOrEqual"](%/duration_predictor/flows.3/Split_output_1, %/duration_predictor/flows.3/Constant_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.3/And_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::And[onnx_name="/duration_predictor/flows.3/And"](%/duration_predictor/flows.3/GreaterOrEqual_output_0, %/duration_predictor/flows.3/LessOrEqual_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.3/Not_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::Not[onnx_name="/duration_predictor/flows.3/Not"](%/duration_predictor/flows.3/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:63:0
  %/duration_predictor/flows.3/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/duration_predictor/flows.3/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_21_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.3/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/ConstantOfShape_output_0 : Long(6, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.3/ConstantOfShape"](%/duration_predictor/flows.3/Constant_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Concat_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_1"](%/duration_predictor/flows.3/Constant_21_output_0, %/duration_predictor/flows.3/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.3/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Reshape_1_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_1"](%/duration_predictor/flows.3/Concat_1_output_0, %/duration_predictor/flows.3/Constant_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Slice_3_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_3"](%/duration_predictor/flows.3/Reshape_1_output_0, %/duration_predictor/flows.3/Constant_24_output_0, %/duration_predictor/flows.3/Constant_25_output_0, %/duration_predictor/flows.3/Constant_23_output_0, %/duration_predictor/flows.3/Constant_26_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Transpose_1_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_1"](%/duration_predictor/flows.3/Slice_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Reshape_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_2"](%/duration_predictor/flows.3/Transpose_1_output_0, %/duration_predictor/flows.3/Constant_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Cast_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.3/Cast"](%/duration_predictor/flows.3/Reshape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Pad_output_0 : Float(*, *, *, *, strides=[1100, 1100, 11, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/duration_predictor/flows.3/Pad"](%/duration_predictor/flows.3/Slice_2_output_0, %/duration_predictor/flows.3/Cast_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Gather_3_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Gather[axis=3, onnx_name="/duration_predictor/flows.3/Gather_3"](%/duration_predictor/flows.3/Pad_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_3"](%/duration_predictor/flows.3/Gather_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/ConstantOfShape_1_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0.539742}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_1"](%/duration_predictor/flows.3/Shape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_4"](%/duration_predictor/flows.3/Gather_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Expand_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand"](%/duration_predictor/flows.3/ConstantOfShape_1_output_0, %/duration_predictor/flows.3/Shape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %onnx::Gather_5480 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/Pad_output_0)
  %onnx::Gather_5481 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5482 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5480, %onnx::Gather_5481)
  %onnx::Range_5483 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5482)
  %onnx::Range_5484 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5485 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5486 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5484, %onnx::Range_5483, %onnx::Range_5485)
  %onnx::Gather_5487 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/Pad_output_0)
  %onnx::Gather_5488 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Cast_5489 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5487, %onnx::Gather_5488)
  %onnx::Range_5490 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5489)
  %onnx::Range_5491 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5492 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5493 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5491, %onnx::Range_5490, %onnx::Range_5492)
  %onnx::Gather_5494 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/Pad_output_0)
  %onnx::Gather_5495 : Long(device=cpu) = onnx::Constant[value={2}]()
  %onnx::Cast_5496 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5494, %onnx::Gather_5495)
  %onnx::Range_5497 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5496)
  %onnx::Range_5498 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5499 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5500 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5498, %onnx::Range_5497, %onnx::Range_5499)
  %onnx::Expand_5501 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()
  %onnx::Reshape_5502 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1  1 [ CPULongType{4} ]]()
  %onnx::Add_5503 : Long(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5486, %onnx::Reshape_5502)
  %onnx::Reshape_5504 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1 [ CPULongType{3} ]]()
  %onnx::Add_5505 : Long(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5493, %onnx::Reshape_5504)
  %onnx::Reshape_5506 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5507 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5500, %onnx::Reshape_5506)
  %/duration_predictor/flows.3/Add_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add"](%onnx::Add_5503, %onnx::Add_5505), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Add_1_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_1"](%/duration_predictor/flows.3/Add_output_0, %onnx::Add_5507), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Add_2_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_2"](%/duration_predictor/flows.3/Add_1_output_0, %/duration_predictor/flows.3/Constant_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_5"](%/duration_predictor/flows.3/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Shape_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_6"](%/duration_predictor/flows.3/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/ConstantOfShape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_2"](%/duration_predictor/flows.3/Shape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_29_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Mul_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_1"](%/duration_predictor/flows.3/ConstantOfShape_2_output_0, %/duration_predictor/flows.3/Constant_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Equal_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal"](%/duration_predictor/flows.3/Shape_5_output_0, %/duration_predictor/flows.3/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Where_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where"](%/duration_predictor/flows.3/Equal_output_0, %/duration_predictor/flows.3/ConstantOfShape_2_output_0, %/duration_predictor/flows.3/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Expand_1_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_1"](%onnx::Add_5503, %/duration_predictor/flows.3/Where_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Unsqueeze_3_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_3"](%/duration_predictor/flows.3/Expand_1_output_0, %/duration_predictor/flows.3/Constant_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Shape_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_7"](%/duration_predictor/flows.3/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/ConstantOfShape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_3"](%/duration_predictor/flows.3/Shape_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Mul_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_2"](%/duration_predictor/flows.3/ConstantOfShape_3_output_0, %/duration_predictor/flows.3/Constant_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Equal_1_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_1"](%/duration_predictor/flows.3/Shape_5_output_0, %/duration_predictor/flows.3/Mul_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_1"](%/duration_predictor/flows.3/Equal_1_output_0, %/duration_predictor/flows.3/ConstantOfShape_3_output_0, %/duration_predictor/flows.3/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Expand_2_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_2"](%onnx::Add_5505, %/duration_predictor/flows.3/Where_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Unsqueeze_4_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_4"](%/duration_predictor/flows.3/Expand_2_output_0, %/duration_predictor/flows.3/Constant_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Shape_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_8"](%/duration_predictor/flows.3/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/ConstantOfShape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_4"](%/duration_predictor/flows.3/Shape_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_33_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Mul_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_3"](%/duration_predictor/flows.3/ConstantOfShape_4_output_0, %/duration_predictor/flows.3/Constant_33_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Equal_2_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_2"](%/duration_predictor/flows.3/Shape_5_output_0, %/duration_predictor/flows.3/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Where_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_2"](%/duration_predictor/flows.3/Equal_2_output_0, %/duration_predictor/flows.3/ConstantOfShape_4_output_0, %/duration_predictor/flows.3/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Expand_3_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_3"](%onnx::Add_5507, %/duration_predictor/flows.3/Where_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Unsqueeze_5_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_5"](%/duration_predictor/flows.3/Expand_3_output_0, %/duration_predictor/flows.3/Constant_34_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Shape_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_9"](%/duration_predictor/flows.3/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/ConstantOfShape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_5"](%/duration_predictor/flows.3/Shape_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Mul_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_4"](%/duration_predictor/flows.3/ConstantOfShape_5_output_0, %/duration_predictor/flows.3/Constant_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Equal_3_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_3"](%/duration_predictor/flows.3/Shape_5_output_0, %/duration_predictor/flows.3/Mul_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Where_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_3"](%/duration_predictor/flows.3/Equal_3_output_0, %/duration_predictor/flows.3/ConstantOfShape_5_output_0, %/duration_predictor/flows.3/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Expand_4_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_4"](%onnx::Expand_5501, %/duration_predictor/flows.3/Where_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Unsqueeze_6_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_6"](%/duration_predictor/flows.3/Expand_4_output_0, %/duration_predictor/flows.3/Constant_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Concat_2_output_0 : Long(*, *, *, *, 4, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.3/Concat_2"](%/duration_predictor/flows.3/Unsqueeze_3_output_0, %/duration_predictor/flows.3/Unsqueeze_4_output_0, %/duration_predictor/flows.3/Unsqueeze_5_output_0, %/duration_predictor/flows.3/Unsqueeze_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_10"](%/duration_predictor/flows.3/Pad_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/duration_predictor/flows.3/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Slice_4_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_4"](%/duration_predictor/flows.3/Shape_10_output_0, %/duration_predictor/flows.3/Constant_38_output_0, %/duration_predictor/flows.3/Constant_39_output_0, %/duration_predictor/flows.3/Constant_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_3"](%/duration_predictor/flows.3/Shape_5_output_0, %/duration_predictor/flows.3/Slice_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Reshape_3_output_0 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_3"](%/duration_predictor/flows.3/Expand_output_0, %/duration_predictor/flows.3/Concat_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/ScatterND_output_0 : Float(*, *, *, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND"](%/duration_predictor/flows.3/Pad_output_0, %/duration_predictor/flows.3/Concat_2_output_0, %/duration_predictor/flows.3/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.3/Gather_4_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Gather[axis=3, onnx_name="/duration_predictor/flows.3/Gather_4"](%/duration_predictor/flows.3/ScatterND_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Shape_11_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_11"](%/duration_predictor/flows.3/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/ConstantOfShape_6_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0.539742}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_6"](%/duration_predictor/flows.3/Shape_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Shape_12_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_12"](%/duration_predictor/flows.3/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Expand_5_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_5"](%/duration_predictor/flows.3/ConstantOfShape_6_output_0, %/duration_predictor/flows.3/Shape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %onnx::Gather_5563 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/ScatterND_output_0)
  %onnx::Gather_5564 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5565 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5563, %onnx::Gather_5564)
  %onnx::Range_5566 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5565)
  %onnx::Range_5567 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5568 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5569 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5567, %onnx::Range_5566, %onnx::Range_5568)
  %onnx::Gather_5570 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/ScatterND_output_0)
  %onnx::Gather_5571 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Cast_5572 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5570, %onnx::Gather_5571)
  %onnx::Range_5573 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5572)
  %onnx::Range_5574 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5575 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5576 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5574, %onnx::Range_5573, %onnx::Range_5575)
  %onnx::Gather_5577 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/ScatterND_output_0)
  %onnx::Gather_5578 : Long(device=cpu) = onnx::Constant[value={2}]()
  %onnx::Cast_5579 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5577, %onnx::Gather_5578)
  %onnx::Range_5580 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5579)
  %onnx::Range_5581 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5582 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5583 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5581, %onnx::Range_5580, %onnx::Range_5582)
  %onnx::Expand_5584 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_5585 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1  1 [ CPULongType{4} ]]()
  %onnx::Add_5586 : Long(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5569, %onnx::Reshape_5585)
  %onnx::Reshape_5587 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1 [ CPULongType{3} ]]()
  %onnx::Add_5588 : Long(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5576, %onnx::Reshape_5587)
  %onnx::Reshape_5589 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5590 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5583, %onnx::Reshape_5589)
  %/duration_predictor/flows.3/Add_3_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_3"](%onnx::Add_5586, %onnx::Add_5588), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Add_4_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_4"](%/duration_predictor/flows.3/Add_3_output_0, %onnx::Add_5590), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_40"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Add_5_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_5"](%/duration_predictor/flows.3/Add_4_output_0, %/duration_predictor/flows.3/Constant_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Shape_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_13"](%/duration_predictor/flows.3/Add_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_14"](%/duration_predictor/flows.3/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/ConstantOfShape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_7"](%/duration_predictor/flows.3/Shape_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_41_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_41"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Mul_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_5"](%/duration_predictor/flows.3/ConstantOfShape_7_output_0, %/duration_predictor/flows.3/Constant_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Equal_4_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_4"](%/duration_predictor/flows.3/Shape_13_output_0, %/duration_predictor/flows.3/Mul_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Where_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_4"](%/duration_predictor/flows.3/Equal_4_output_0, %/duration_predictor/flows.3/ConstantOfShape_7_output_0, %/duration_predictor/flows.3/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Expand_6_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_6"](%onnx::Add_5586, %/duration_predictor/flows.3/Where_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_42"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Unsqueeze_7_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_7"](%/duration_predictor/flows.3/Expand_6_output_0, %/duration_predictor/flows.3/Constant_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Shape_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_15"](%/duration_predictor/flows.3/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/ConstantOfShape_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_8"](%/duration_predictor/flows.3/Shape_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_43_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_43"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Mul_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_6"](%/duration_predictor/flows.3/ConstantOfShape_8_output_0, %/duration_predictor/flows.3/Constant_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Equal_5_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_5"](%/duration_predictor/flows.3/Shape_13_output_0, %/duration_predictor/flows.3/Mul_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Where_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_5"](%/duration_predictor/flows.3/Equal_5_output_0, %/duration_predictor/flows.3/ConstantOfShape_8_output_0, %/duration_predictor/flows.3/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Expand_7_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_7"](%onnx::Add_5588, %/duration_predictor/flows.3/Where_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_44"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Unsqueeze_8_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_8"](%/duration_predictor/flows.3/Expand_7_output_0, %/duration_predictor/flows.3/Constant_44_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Shape_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_16"](%/duration_predictor/flows.3/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/ConstantOfShape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_9"](%/duration_predictor/flows.3/Shape_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_45_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_45"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Mul_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_7"](%/duration_predictor/flows.3/ConstantOfShape_9_output_0, %/duration_predictor/flows.3/Constant_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Equal_6_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_6"](%/duration_predictor/flows.3/Shape_13_output_0, %/duration_predictor/flows.3/Mul_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Where_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_6"](%/duration_predictor/flows.3/Equal_6_output_0, %/duration_predictor/flows.3/ConstantOfShape_9_output_0, %/duration_predictor/flows.3/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Expand_8_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_8"](%onnx::Add_5590, %/duration_predictor/flows.3/Where_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_46"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Unsqueeze_9_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_9"](%/duration_predictor/flows.3/Expand_8_output_0, %/duration_predictor/flows.3/Constant_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Shape_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_17"](%/duration_predictor/flows.3/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/ConstantOfShape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_10"](%/duration_predictor/flows.3/Shape_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_47_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_47"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Mul_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_8"](%/duration_predictor/flows.3/ConstantOfShape_10_output_0, %/duration_predictor/flows.3/Constant_47_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Equal_7_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_7"](%/duration_predictor/flows.3/Shape_13_output_0, %/duration_predictor/flows.3/Mul_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Where_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_7"](%/duration_predictor/flows.3/Equal_7_output_0, %/duration_predictor/flows.3/ConstantOfShape_10_output_0, %/duration_predictor/flows.3/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Expand_9_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_9"](%onnx::Expand_5584, %/duration_predictor/flows.3/Where_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_48_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_48"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Unsqueeze_10_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_10"](%/duration_predictor/flows.3/Expand_9_output_0, %/duration_predictor/flows.3/Constant_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Concat_4_output_0 : Long(*, *, *, *, 4, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.3/Concat_4"](%/duration_predictor/flows.3/Unsqueeze_7_output_0, %/duration_predictor/flows.3/Unsqueeze_8_output_0, %/duration_predictor/flows.3/Unsqueeze_9_output_0, %/duration_predictor/flows.3/Unsqueeze_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Shape_18_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_18"](%/duration_predictor/flows.3/ScatterND_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_49"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/duration_predictor/flows.3/Constant_50"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_51"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Slice_5_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_5"](%/duration_predictor/flows.3/Shape_18_output_0, %/duration_predictor/flows.3/Constant_50_output_0, %/duration_predictor/flows.3/Constant_51_output_0, %/duration_predictor/flows.3/Constant_49_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_5"](%/duration_predictor/flows.3/Shape_13_output_0, %/duration_predictor/flows.3/Slice_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/Reshape_4_output_0 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_4"](%/duration_predictor/flows.3/Expand_5_output_0, %/duration_predictor/flows.3/Concat_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/ScatterND_1_output_0 : Float(*, *, *, *, strides=[1100, 1100, 11, 1], requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND_1"](%/duration_predictor/flows.3/ScatterND_output_0, %/duration_predictor/flows.3/Concat_4_output_0, %/duration_predictor/flows.3/Reshape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.3/NonZero_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.3/NonZero"](%/duration_predictor/flows.3/Not_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Transpose_2_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_2"](%/duration_predictor/flows.3/NonZero_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/GatherND_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.3/GatherND"](%/duration_predictor/flows.3/Split_output_1, %/duration_predictor/flows.3/Transpose_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Shape_19_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_19"](%/duration_predictor/flows.3/Split_output_1), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:65:0
  %/duration_predictor/flows.3/ConstantOfShape_11_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_11"](%/duration_predictor/flows.3/Shape_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:65:0
  %/duration_predictor/flows.3/NonZero_1_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.3/NonZero_1"](%/duration_predictor/flows.3/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:80:0
  %/duration_predictor/flows.3/Transpose_3_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_3"](%/duration_predictor/flows.3/NonZero_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:80:0
  %/duration_predictor/flows.3/GatherND_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.3/GatherND_1"](%/duration_predictor/flows.3/Split_output_1, %/duration_predictor/flows.3/Transpose_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:80:0
  %/duration_predictor/flows.3/NonZero_2_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.3/NonZero_2"](%/duration_predictor/flows.3/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:81:0
  %/duration_predictor/flows.3/Transpose_4_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_4"](%/duration_predictor/flows.3/NonZero_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:81:0
  %/duration_predictor/flows.3/GatherND_2_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.3/GatherND_2"](%/duration_predictor/flows.3/Div_output_0, %/duration_predictor/flows.3/Transpose_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:81:0
  %/duration_predictor/flows.3/NonZero_3_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.3/NonZero_3"](%/duration_predictor/flows.3/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:82:0
  %/duration_predictor/flows.3/Transpose_5_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_5"](%/duration_predictor/flows.3/NonZero_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:82:0
  %/duration_predictor/flows.3/GatherND_3_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.3/GatherND_3"](%/duration_predictor/flows.3/Div_1_output_0, %/duration_predictor/flows.3/Transpose_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:82:0
  %/duration_predictor/flows.3/NonZero_4_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.3/NonZero_4"](%/duration_predictor/flows.3/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:83:0
  %/duration_predictor/flows.3/Transpose_6_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_6"](%/duration_predictor/flows.3/NonZero_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:83:0
  %/duration_predictor/flows.3/GatherND_4_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.3/GatherND_4"](%/duration_predictor/flows.3/ScatterND_1_output_0, %/duration_predictor/flows.3/Transpose_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:83:0
  %/duration_predictor/flows.3/Shape_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_20"](%/duration_predictor/flows.3/GatherND_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:114:0
  %/duration_predictor/flows.3/Constant_52_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_52"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:114:0
  %/duration_predictor/flows.3/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.3/Gather_5"](%/duration_predictor/flows.3/Shape_20_output_0, %/duration_predictor/flows.3/Constant_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:114:0
  %/duration_predictor/flows.3/Softmax_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/duration_predictor/flows.3/Softmax"](%/duration_predictor/flows.3/GatherND_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/duration_predictor/flows.3/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/duration_predictor/flows.3/Cast_1"](%/duration_predictor/flows.3/Gather_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.3/Constant_53_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.3/Constant_53"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.3/Mul_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_9"](%/duration_predictor/flows.3/Cast_1_output_0, %/duration_predictor/flows.3/Constant_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.3/Constant_54_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_54"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:962:0
  %/duration_predictor/flows.3/Sub_output_0 : Float(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub"](%/duration_predictor/flows.3/Constant_54_output_0, %/duration_predictor/flows.3/Mul_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:962:0
  %/duration_predictor/flows.3/Mul_10_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_10"](%/duration_predictor/flows.3/Sub_output_0, %/duration_predictor/flows.3/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.3/Constant_55_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.3/Constant_55"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.3/Add_6_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_6"](%/duration_predictor/flows.3/Mul_10_output_0, %/duration_predictor/flows.3/Constant_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.3/Constant_56_output_0 : Int(device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_56"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:123:0
  %/duration_predictor/flows.3/CumSum_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::CumSum[onnx_name="/duration_predictor/flows.3/CumSum"](%/duration_predictor/flows.3/Add_6_output_0, %/duration_predictor/flows.3/Constant_56_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:123:0
  %/duration_predictor/flows.3/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_57"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_58_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  0 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.3/Constant_58"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/ConstantOfShape_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_12"](%/duration_predictor/flows.3/Constant_57_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_6"](%/duration_predictor/flows.3/Constant_58_output_0, %/duration_predictor/flows.3/ConstantOfShape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_59_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.3/Constant_59"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Reshape_5_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_5"](%/duration_predictor/flows.3/Concat_6_output_0, %/duration_predictor/flows.3/Constant_59_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_60_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_60"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_61_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_61"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_62_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_62"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_63_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_63"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Slice_6_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_6"](%/duration_predictor/flows.3/Reshape_5_output_0, %/duration_predictor/flows.3/Constant_61_output_0, %/duration_predictor/flows.3/Constant_62_output_0, %/duration_predictor/flows.3/Constant_60_output_0, %/duration_predictor/flows.3/Constant_63_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Transpose_7_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_7"](%/duration_predictor/flows.3/Slice_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_64_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_64"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Reshape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_6"](%/duration_predictor/flows.3/Transpose_7_output_0, %/duration_predictor/flows.3/Constant_64_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Cast_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.3/Cast_2"](%/duration_predictor/flows.3/Reshape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_65_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_65"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Pad_1_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/duration_predictor/flows.3/Pad_1"](%/duration_predictor/flows.3/CumSum_output_0, %/duration_predictor/flows.3/Cast_2_output_0, %/duration_predictor/flows.3/Constant_65_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_66_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.3/Constant_66"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.3/Mul_11_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_11"](%/duration_predictor/flows.3/Pad_1_output_0, %/duration_predictor/flows.3/Constant_66_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.3/Constant_67_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-5}, onnx_name="/duration_predictor/flows.3/Constant_67"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.3/Add_7_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_7"](%/duration_predictor/flows.3/Mul_11_output_0, %/duration_predictor/flows.3/Constant_67_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.3/Gather_6_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_6"](%/duration_predictor/flows.3/Add_7_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Shape_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_21"](%/duration_predictor/flows.3/Gather_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/ConstantOfShape_13_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={-5}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_13"](%/duration_predictor/flows.3/Shape_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Shape_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_22"](%/duration_predictor/flows.3/Gather_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Expand_10_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_10"](%/duration_predictor/flows.3/ConstantOfShape_13_output_0, %/duration_predictor/flows.3/Shape_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %onnx::Gather_5704 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/Add_7_output_0)
  %onnx::Gather_5705 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5706 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5704, %onnx::Gather_5705)
  %onnx::Range_5707 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5706)
  %onnx::Range_5708 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5709 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5710 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5708, %onnx::Range_5707, %onnx::Range_5709)
  %onnx::Expand_5711 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()
  %onnx::Reshape_5712 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5713 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5710, %onnx::Reshape_5712)
  %/duration_predictor/flows.3/Constant_68_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_68"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Add_8_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_8"](%onnx::Add_5713, %/duration_predictor/flows.3/Constant_68_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Shape_23_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_23"](%/duration_predictor/flows.3/Add_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Shape_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_24"](%/duration_predictor/flows.3/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/ConstantOfShape_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_14"](%/duration_predictor/flows.3/Shape_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Constant_69_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_69"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Mul_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_12"](%/duration_predictor/flows.3/ConstantOfShape_14_output_0, %/duration_predictor/flows.3/Constant_69_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Equal_8_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_8"](%/duration_predictor/flows.3/Shape_23_output_0, %/duration_predictor/flows.3/Mul_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Where_8_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_8"](%/duration_predictor/flows.3/Equal_8_output_0, %/duration_predictor/flows.3/ConstantOfShape_14_output_0, %/duration_predictor/flows.3/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Expand_11_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_11"](%onnx::Add_5713, %/duration_predictor/flows.3/Where_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_70"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Unsqueeze_11_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_11"](%/duration_predictor/flows.3/Expand_11_output_0, %/duration_predictor/flows.3/Constant_70_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Shape_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_25"](%/duration_predictor/flows.3/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/ConstantOfShape_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_15"](%/duration_predictor/flows.3/Shape_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Constant_71_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_71"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Mul_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_13"](%/duration_predictor/flows.3/ConstantOfShape_15_output_0, %/duration_predictor/flows.3/Constant_71_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Equal_9_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_9"](%/duration_predictor/flows.3/Shape_23_output_0, %/duration_predictor/flows.3/Mul_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Where_9_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_9"](%/duration_predictor/flows.3/Equal_9_output_0, %/duration_predictor/flows.3/ConstantOfShape_15_output_0, %/duration_predictor/flows.3/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Expand_12_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_12"](%onnx::Expand_5711, %/duration_predictor/flows.3/Where_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_72"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Unsqueeze_12_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_12"](%/duration_predictor/flows.3/Expand_12_output_0, %/duration_predictor/flows.3/Constant_72_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Concat_7_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.3/Concat_7"](%/duration_predictor/flows.3/Unsqueeze_11_output_0, %/duration_predictor/flows.3/Unsqueeze_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Shape_26_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_26"](%/duration_predictor/flows.3/Add_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Constant_73_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_73"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Constant_74_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_74"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Constant_75_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_75"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Slice_7_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_7"](%/duration_predictor/flows.3/Shape_26_output_0, %/duration_predictor/flows.3/Constant_74_output_0, %/duration_predictor/flows.3/Constant_75_output_0, %/duration_predictor/flows.3/Constant_73_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Concat_8_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_8"](%/duration_predictor/flows.3/Shape_23_output_0, %/duration_predictor/flows.3/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Reshape_7_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_7"](%/duration_predictor/flows.3/Expand_10_output_0, %/duration_predictor/flows.3/Concat_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/ScatterND_2_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND_2"](%/duration_predictor/flows.3/Add_7_output_0, %/duration_predictor/flows.3/Concat_7_output_0, %/duration_predictor/flows.3/Reshape_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.3/Gather_7_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_7"](%/duration_predictor/flows.3/ScatterND_2_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Shape_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_27"](%/duration_predictor/flows.3/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/ConstantOfShape_16_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={5}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_16"](%/duration_predictor/flows.3/Shape_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Shape_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_28"](%/duration_predictor/flows.3/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Expand_13_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_13"](%/duration_predictor/flows.3/ConstantOfShape_16_output_0, %/duration_predictor/flows.3/Shape_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %onnx::Gather_5749 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/ScatterND_2_output_0)
  %onnx::Gather_5750 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5751 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5749, %onnx::Gather_5750)
  %onnx::Range_5752 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5751)
  %onnx::Range_5753 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5754 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5755 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5753, %onnx::Range_5752, %onnx::Range_5754)
  %onnx::Expand_5756 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_5757 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5758 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5755, %onnx::Reshape_5757)
  %/duration_predictor/flows.3/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_76"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Add_9_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_9"](%onnx::Add_5758, %/duration_predictor/flows.3/Constant_76_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Shape_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_29"](%/duration_predictor/flows.3/Add_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Shape_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_30"](%/duration_predictor/flows.3/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/ConstantOfShape_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_17"](%/duration_predictor/flows.3/Shape_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Constant_77_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_77"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Mul_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_14"](%/duration_predictor/flows.3/ConstantOfShape_17_output_0, %/duration_predictor/flows.3/Constant_77_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Equal_10_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_10"](%/duration_predictor/flows.3/Shape_29_output_0, %/duration_predictor/flows.3/Mul_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Where_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_10"](%/duration_predictor/flows.3/Equal_10_output_0, %/duration_predictor/flows.3/ConstantOfShape_17_output_0, %/duration_predictor/flows.3/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Expand_14_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_14"](%onnx::Add_5758, %/duration_predictor/flows.3/Where_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_78"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Unsqueeze_13_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_13"](%/duration_predictor/flows.3/Expand_14_output_0, %/duration_predictor/flows.3/Constant_78_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Shape_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_31"](%/duration_predictor/flows.3/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/ConstantOfShape_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_18"](%/duration_predictor/flows.3/Shape_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Constant_79_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_79"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Mul_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_15"](%/duration_predictor/flows.3/ConstantOfShape_18_output_0, %/duration_predictor/flows.3/Constant_79_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Equal_11_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_11"](%/duration_predictor/flows.3/Shape_29_output_0, %/duration_predictor/flows.3/Mul_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Where_11_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_11"](%/duration_predictor/flows.3/Equal_11_output_0, %/duration_predictor/flows.3/ConstantOfShape_18_output_0, %/duration_predictor/flows.3/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Expand_15_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_15"](%onnx::Expand_5756, %/duration_predictor/flows.3/Where_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Constant_80_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_80"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Unsqueeze_14_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_14"](%/duration_predictor/flows.3/Expand_15_output_0, %/duration_predictor/flows.3/Constant_80_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Concat_9_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.3/Concat_9"](%/duration_predictor/flows.3/Unsqueeze_13_output_0, %/duration_predictor/flows.3/Unsqueeze_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Shape_32_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_32"](%/duration_predictor/flows.3/ScatterND_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_81"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Constant_82_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_82"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Constant_83_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_83"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Slice_8_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_8"](%/duration_predictor/flows.3/Shape_32_output_0, %/duration_predictor/flows.3/Constant_82_output_0, %/duration_predictor/flows.3/Constant_83_output_0, %/duration_predictor/flows.3/Constant_81_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Concat_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_10"](%/duration_predictor/flows.3/Shape_29_output_0, %/duration_predictor/flows.3/Slice_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Reshape_8_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_8"](%/duration_predictor/flows.3/Expand_13_output_0, %/duration_predictor/flows.3/Concat_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/ScatterND_3_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND_3"](%/duration_predictor/flows.3/ScatterND_2_output_0, %/duration_predictor/flows.3/Concat_9_output_0, %/duration_predictor/flows.3/Reshape_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.3/Constant_84_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_84"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Constant_85_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_85"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Constant_86_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_86"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Constant_87_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_87"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Slice_9_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_9"](%/duration_predictor/flows.3/ScatterND_3_output_0, %/duration_predictor/flows.3/Constant_85_output_0, %/duration_predictor/flows.3/Constant_86_output_0, %/duration_predictor/flows.3/Constant_84_output_0, %/duration_predictor/flows.3/Constant_87_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Constant_88_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_88"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Constant_89_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_89"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Constant_90_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_90"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Constant_91_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_91"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Slice_10_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_10"](%/duration_predictor/flows.3/ScatterND_3_output_0, %/duration_predictor/flows.3/Constant_89_output_0, %/duration_predictor/flows.3/Constant_90_output_0, %/duration_predictor/flows.3/Constant_88_output_0, %/duration_predictor/flows.3/Constant_91_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Sub_1_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub_1"](%/duration_predictor/flows.3/Slice_9_output_0, %/duration_predictor/flows.3/Slice_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.3/Softplus_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Softplus[onnx_name="/duration_predictor/flows.3/Softplus"](%/duration_predictor/flows.3/GatherND_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:130:0
  %/duration_predictor/flows.3/Constant_92_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.3/Constant_92"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:130:0
  %/duration_predictor/flows.3/Add_10_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_10"](%/duration_predictor/flows.3/Softplus_output_0, %/duration_predictor/flows.3/Constant_92_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:130:0
  %/duration_predictor/flows.3/Softmax_1_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/duration_predictor/flows.3/Softmax_1"](%/duration_predictor/flows.3/GatherND_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/duration_predictor/flows.3/Mul_16_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_16"](%/duration_predictor/flows.3/Sub_output_0, %/duration_predictor/flows.3/Softmax_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:133:0
  %/duration_predictor/flows.3/Constant_93_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.3/Constant_93"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:133:0
  %/duration_predictor/flows.3/Add_11_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_11"](%/duration_predictor/flows.3/Mul_16_output_0, %/duration_predictor/flows.3/Constant_93_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:133:0
  %/duration_predictor/flows.3/Constant_94_output_0 : Int(device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_94"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:134:0
  %/duration_predictor/flows.3/CumSum_1_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::CumSum[onnx_name="/duration_predictor/flows.3/CumSum_1"](%/duration_predictor/flows.3/Add_11_output_0, %/duration_predictor/flows.3/Constant_94_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:134:0
  %/duration_predictor/flows.3/Constant_95_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_95"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_96_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  0 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.3/Constant_96"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/ConstantOfShape_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_19"](%/duration_predictor/flows.3/Constant_95_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Concat_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_11"](%/duration_predictor/flows.3/Constant_96_output_0, %/duration_predictor/flows.3/ConstantOfShape_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_97_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.3/Constant_97"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Reshape_9_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_9"](%/duration_predictor/flows.3/Concat_11_output_0, %/duration_predictor/flows.3/Constant_97_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_98_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_98"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_99_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_99"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_100_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_100"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_101_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_101"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Slice_11_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_11"](%/duration_predictor/flows.3/Reshape_9_output_0, %/duration_predictor/flows.3/Constant_99_output_0, %/duration_predictor/flows.3/Constant_100_output_0, %/duration_predictor/flows.3/Constant_98_output_0, %/duration_predictor/flows.3/Constant_101_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Transpose_8_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_8"](%/duration_predictor/flows.3/Slice_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_102_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_102"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Reshape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_10"](%/duration_predictor/flows.3/Transpose_8_output_0, %/duration_predictor/flows.3/Constant_102_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Cast_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.3/Cast_3"](%/duration_predictor/flows.3/Reshape_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_103_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_103"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Pad_2_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/duration_predictor/flows.3/Pad_2"](%/duration_predictor/flows.3/CumSum_1_output_0, %/duration_predictor/flows.3/Cast_3_output_0, %/duration_predictor/flows.3/Constant_103_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.3/Constant_104_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.3/Constant_104"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.3/Mul_17_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_17"](%/duration_predictor/flows.3/Pad_2_output_0, %/duration_predictor/flows.3/Constant_104_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.3/Constant_105_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-5}, onnx_name="/duration_predictor/flows.3/Constant_105"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.3/Add_12_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_12"](%/duration_predictor/flows.3/Mul_17_output_0, %/duration_predictor/flows.3/Constant_105_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.3/Gather_8_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_8"](%/duration_predictor/flows.3/Add_12_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Shape_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_33"](%/duration_predictor/flows.3/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/ConstantOfShape_20_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={-5}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_20"](%/duration_predictor/flows.3/Shape_33_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Shape_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_34"](%/duration_predictor/flows.3/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Expand_16_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_16"](%/duration_predictor/flows.3/ConstantOfShape_20_output_0, %/duration_predictor/flows.3/Shape_34_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %onnx::Gather_5849 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/Add_12_output_0)
  %onnx::Gather_5850 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5851 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5849, %onnx::Gather_5850)
  %onnx::Range_5852 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5851)
  %onnx::Range_5853 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5854 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5855 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5853, %onnx::Range_5852, %onnx::Range_5854)
  %onnx::Expand_5856 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()
  %onnx::Reshape_5857 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5858 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5855, %onnx::Reshape_5857)
  %/duration_predictor/flows.3/Constant_106_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_106"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Add_13_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_13"](%onnx::Add_5858, %/duration_predictor/flows.3/Constant_106_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Shape_35_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_35"](%/duration_predictor/flows.3/Add_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Shape_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_36"](%/duration_predictor/flows.3/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/ConstantOfShape_21_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_21"](%/duration_predictor/flows.3/Shape_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Constant_107_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_107"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Mul_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_18"](%/duration_predictor/flows.3/ConstantOfShape_21_output_0, %/duration_predictor/flows.3/Constant_107_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Equal_12_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_12"](%/duration_predictor/flows.3/Shape_35_output_0, %/duration_predictor/flows.3/Mul_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Where_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_12"](%/duration_predictor/flows.3/Equal_12_output_0, %/duration_predictor/flows.3/ConstantOfShape_21_output_0, %/duration_predictor/flows.3/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Expand_17_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_17"](%onnx::Add_5858, %/duration_predictor/flows.3/Where_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_108"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Unsqueeze_15_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_15"](%/duration_predictor/flows.3/Expand_17_output_0, %/duration_predictor/flows.3/Constant_108_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Shape_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_37"](%/duration_predictor/flows.3/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/ConstantOfShape_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_22"](%/duration_predictor/flows.3/Shape_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Constant_109_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_109"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Mul_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_19"](%/duration_predictor/flows.3/ConstantOfShape_22_output_0, %/duration_predictor/flows.3/Constant_109_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Equal_13_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_13"](%/duration_predictor/flows.3/Shape_35_output_0, %/duration_predictor/flows.3/Mul_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Where_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_13"](%/duration_predictor/flows.3/Equal_13_output_0, %/duration_predictor/flows.3/ConstantOfShape_22_output_0, %/duration_predictor/flows.3/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Expand_18_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_18"](%onnx::Expand_5856, %/duration_predictor/flows.3/Where_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_110"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Unsqueeze_16_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_16"](%/duration_predictor/flows.3/Expand_18_output_0, %/duration_predictor/flows.3/Constant_110_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Concat_12_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.3/Concat_12"](%/duration_predictor/flows.3/Unsqueeze_15_output_0, %/duration_predictor/flows.3/Unsqueeze_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Shape_38_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_38"](%/duration_predictor/flows.3/Add_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Constant_111_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_111"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Constant_112_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_112"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Constant_113_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_113"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Slice_12_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_12"](%/duration_predictor/flows.3/Shape_38_output_0, %/duration_predictor/flows.3/Constant_112_output_0, %/duration_predictor/flows.3/Constant_113_output_0, %/duration_predictor/flows.3/Constant_111_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Concat_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_13"](%/duration_predictor/flows.3/Shape_35_output_0, %/duration_predictor/flows.3/Slice_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Reshape_11_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_11"](%/duration_predictor/flows.3/Expand_16_output_0, %/duration_predictor/flows.3/Concat_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/ScatterND_4_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND_4"](%/duration_predictor/flows.3/Add_12_output_0, %/duration_predictor/flows.3/Concat_12_output_0, %/duration_predictor/flows.3/Reshape_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.3/Gather_9_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_9"](%/duration_predictor/flows.3/ScatterND_4_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Shape_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_39"](%/duration_predictor/flows.3/Gather_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/ConstantOfShape_23_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={5}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_23"](%/duration_predictor/flows.3/Shape_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Shape_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_40"](%/duration_predictor/flows.3/Gather_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Expand_19_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_19"](%/duration_predictor/flows.3/ConstantOfShape_23_output_0, %/duration_predictor/flows.3/Shape_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %onnx::Gather_5894 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/ScatterND_4_output_0)
  %onnx::Gather_5895 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5896 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5894, %onnx::Gather_5895)
  %onnx::Range_5897 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5896)
  %onnx::Range_5898 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5899 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5900 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5898, %onnx::Range_5897, %onnx::Range_5899)
  %onnx::Expand_5901 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_5902 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5903 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5900, %onnx::Reshape_5902)
  %/duration_predictor/flows.3/Constant_114_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_114"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Add_14_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_14"](%onnx::Add_5903, %/duration_predictor/flows.3/Constant_114_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Shape_41_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_41"](%/duration_predictor/flows.3/Add_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Shape_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_42"](%/duration_predictor/flows.3/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/ConstantOfShape_24_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_24"](%/duration_predictor/flows.3/Shape_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Constant_115_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_115"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Mul_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_20"](%/duration_predictor/flows.3/ConstantOfShape_24_output_0, %/duration_predictor/flows.3/Constant_115_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Equal_14_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_14"](%/duration_predictor/flows.3/Shape_41_output_0, %/duration_predictor/flows.3/Mul_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Where_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_14"](%/duration_predictor/flows.3/Equal_14_output_0, %/duration_predictor/flows.3/ConstantOfShape_24_output_0, %/duration_predictor/flows.3/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Expand_20_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_20"](%onnx::Add_5903, %/duration_predictor/flows.3/Where_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Constant_116_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_116"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Unsqueeze_17_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_17"](%/duration_predictor/flows.3/Expand_20_output_0, %/duration_predictor/flows.3/Constant_116_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Shape_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_43"](%/duration_predictor/flows.3/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/ConstantOfShape_25_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_25"](%/duration_predictor/flows.3/Shape_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Constant_117_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_117"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Mul_21_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_21"](%/duration_predictor/flows.3/ConstantOfShape_25_output_0, %/duration_predictor/flows.3/Constant_117_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Equal_15_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_15"](%/duration_predictor/flows.3/Shape_41_output_0, %/duration_predictor/flows.3/Mul_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Where_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_15"](%/duration_predictor/flows.3/Equal_15_output_0, %/duration_predictor/flows.3/ConstantOfShape_25_output_0, %/duration_predictor/flows.3/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Expand_21_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_21"](%onnx::Expand_5901, %/duration_predictor/flows.3/Where_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Constant_118_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_118"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Unsqueeze_18_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_18"](%/duration_predictor/flows.3/Expand_21_output_0, %/duration_predictor/flows.3/Constant_118_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Concat_14_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.3/Concat_14"](%/duration_predictor/flows.3/Unsqueeze_17_output_0, %/duration_predictor/flows.3/Unsqueeze_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Shape_44_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_44"](%/duration_predictor/flows.3/ScatterND_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Constant_119_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_119"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Constant_120_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_120"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Constant_121_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_121"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Slice_13_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_13"](%/duration_predictor/flows.3/Shape_44_output_0, %/duration_predictor/flows.3/Constant_120_output_0, %/duration_predictor/flows.3/Constant_121_output_0, %/duration_predictor/flows.3/Constant_119_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Concat_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_15"](%/duration_predictor/flows.3/Shape_41_output_0, %/duration_predictor/flows.3/Slice_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Reshape_12_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_12"](%/duration_predictor/flows.3/Expand_19_output_0, %/duration_predictor/flows.3/Concat_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/ScatterND_5_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND_5"](%/duration_predictor/flows.3/ScatterND_4_output_0, %/duration_predictor/flows.3/Concat_14_output_0, %/duration_predictor/flows.3/Reshape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.3/Constant_122_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_122"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Constant_123_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_123"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Constant_124_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_124"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Constant_125_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_125"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Slice_14_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_14"](%/duration_predictor/flows.3/ScatterND_5_output_0, %/duration_predictor/flows.3/Constant_123_output_0, %/duration_predictor/flows.3/Constant_124_output_0, %/duration_predictor/flows.3/Constant_122_output_0, %/duration_predictor/flows.3/Constant_125_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Constant_126_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_126"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Constant_127_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_127"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Constant_128_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_128"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Constant_129_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_129"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Slice_15_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_15"](%/duration_predictor/flows.3/ScatterND_5_output_0, %/duration_predictor/flows.3/Constant_127_output_0, %/duration_predictor/flows.3/Constant_128_output_0, %/duration_predictor/flows.3/Constant_126_output_0, %/duration_predictor/flows.3/Constant_129_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Sub_2_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub_2"](%/duration_predictor/flows.3/Slice_14_output_0, %/duration_predictor/flows.3/Slice_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.3/Gather_10_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_10"](%/duration_predictor/flows.3/ScatterND_5_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_130_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/duration_predictor/flows.3/Constant_130"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Add_15_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_15"](%/duration_predictor/flows.3/Gather_10_output_0, %/duration_predictor/flows.3/Constant_130_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_45"](%/duration_predictor/flows.3/Gather_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Expand_22_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_22"](%/duration_predictor/flows.3/Add_15_output_0, %/duration_predictor/flows.3/Shape_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %onnx::Gather_5958 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/ScatterND_5_output_0)
  %onnx::Gather_5959 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_5960 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_5958, %onnx::Gather_5959)
  %onnx::Range_5961 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_5960)
  %onnx::Range_5962 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_5963 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_5964 : Long(*, device=cpu) = onnx::Range(%onnx::Range_5962, %onnx::Range_5961, %onnx::Range_5963)
  %onnx::Expand_5965 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_5966 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_5967 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_5964, %onnx::Reshape_5966)
  %/duration_predictor/flows.3/Constant_131_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_131"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Add_16_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_16"](%onnx::Add_5967, %/duration_predictor/flows.3/Constant_131_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_46_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_46"](%/duration_predictor/flows.3/Add_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_47_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_47"](%/duration_predictor/flows.3/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/ConstantOfShape_26_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_26"](%/duration_predictor/flows.3/Shape_47_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_132_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_132"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Mul_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_22"](%/duration_predictor/flows.3/ConstantOfShape_26_output_0, %/duration_predictor/flows.3/Constant_132_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Equal_16_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_16"](%/duration_predictor/flows.3/Shape_46_output_0, %/duration_predictor/flows.3/Mul_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Where_16_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_16"](%/duration_predictor/flows.3/Equal_16_output_0, %/duration_predictor/flows.3/ConstantOfShape_26_output_0, %/duration_predictor/flows.3/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Expand_23_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_23"](%onnx::Add_5967, %/duration_predictor/flows.3/Where_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_133_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_133"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Unsqueeze_19_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_19"](%/duration_predictor/flows.3/Expand_23_output_0, %/duration_predictor/flows.3/Constant_133_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_48_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_48"](%/duration_predictor/flows.3/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/ConstantOfShape_27_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_27"](%/duration_predictor/flows.3/Shape_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_134_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_134"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Mul_23_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_23"](%/duration_predictor/flows.3/ConstantOfShape_27_output_0, %/duration_predictor/flows.3/Constant_134_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Equal_17_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_17"](%/duration_predictor/flows.3/Shape_46_output_0, %/duration_predictor/flows.3/Mul_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Where_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_17"](%/duration_predictor/flows.3/Equal_17_output_0, %/duration_predictor/flows.3/ConstantOfShape_27_output_0, %/duration_predictor/flows.3/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Expand_24_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_24"](%onnx::Expand_5965, %/duration_predictor/flows.3/Where_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_135_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_135"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Unsqueeze_20_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_20"](%/duration_predictor/flows.3/Expand_24_output_0, %/duration_predictor/flows.3/Constant_135_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Concat_16_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.3/Concat_16"](%/duration_predictor/flows.3/Unsqueeze_19_output_0, %/duration_predictor/flows.3/Unsqueeze_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_49_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_49"](%/duration_predictor/flows.3/ScatterND_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_136_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_136"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_137_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_137"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_138_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_138"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Slice_16_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_16"](%/duration_predictor/flows.3/Shape_49_output_0, %/duration_predictor/flows.3/Constant_137_output_0, %/duration_predictor/flows.3/Constant_138_output_0, %/duration_predictor/flows.3/Constant_136_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Concat_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_17"](%/duration_predictor/flows.3/Shape_46_output_0, %/duration_predictor/flows.3/Slice_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Reshape_13_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_13"](%/duration_predictor/flows.3/Expand_22_output_0, %/duration_predictor/flows.3/Concat_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/ScatterND_6_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND_6"](%/duration_predictor/flows.3/ScatterND_5_output_0, %/duration_predictor/flows.3/Concat_16_output_0, %/duration_predictor/flows.3/Reshape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Gather_11_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_11"](%/duration_predictor/flows.3/ScatterND_6_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_50"](%/duration_predictor/flows.3/Gather_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Expand_25_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_25"](%/duration_predictor/flows.3/Add_15_output_0, %/duration_predictor/flows.3/Shape_50_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %onnx::Gather_6001 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.3/ScatterND_6_output_0)
  %onnx::Gather_6002 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_6003 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6001, %onnx::Gather_6002)
  %onnx::Range_6004 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6003)
  %onnx::Range_6005 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6006 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6007 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6005, %onnx::Range_6004, %onnx::Range_6006)
  %onnx::Expand_6008 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_6009 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_6010 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6007, %onnx::Reshape_6009)
  %/duration_predictor/flows.3/Constant_139_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_139"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Add_17_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_17"](%onnx::Add_6010, %/duration_predictor/flows.3/Constant_139_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_51_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_51"](%/duration_predictor/flows.3/Add_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_52"](%/duration_predictor/flows.3/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/ConstantOfShape_28_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_28"](%/duration_predictor/flows.3/Shape_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_140_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_140"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Mul_24_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_24"](%/duration_predictor/flows.3/ConstantOfShape_28_output_0, %/duration_predictor/flows.3/Constant_140_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Equal_18_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_18"](%/duration_predictor/flows.3/Shape_51_output_0, %/duration_predictor/flows.3/Mul_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Where_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_18"](%/duration_predictor/flows.3/Equal_18_output_0, %/duration_predictor/flows.3/ConstantOfShape_28_output_0, %/duration_predictor/flows.3/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Expand_26_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_26"](%onnx::Add_6010, %/duration_predictor/flows.3/Where_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_141"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Unsqueeze_21_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_21"](%/duration_predictor/flows.3/Expand_26_output_0, %/duration_predictor/flows.3/Constant_141_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_53"](%/duration_predictor/flows.3/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/ConstantOfShape_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.3/ConstantOfShape_29"](%/duration_predictor/flows.3/Shape_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_142_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_142"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Mul_25_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_25"](%/duration_predictor/flows.3/ConstantOfShape_29_output_0, %/duration_predictor/flows.3/Constant_142_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Equal_19_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.3/Equal_19"](%/duration_predictor/flows.3/Shape_51_output_0, %/duration_predictor/flows.3/Mul_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Where_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.3/Where_19"](%/duration_predictor/flows.3/Equal_19_output_0, %/duration_predictor/flows.3/ConstantOfShape_29_output_0, %/duration_predictor/flows.3/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Expand_27_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_27"](%onnx::Expand_6008, %/duration_predictor/flows.3/Where_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_143"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Unsqueeze_22_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_22"](%/duration_predictor/flows.3/Expand_27_output_0, %/duration_predictor/flows.3/Constant_143_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Concat_18_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.3/Concat_18"](%/duration_predictor/flows.3/Unsqueeze_21_output_0, %/duration_predictor/flows.3/Unsqueeze_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Shape_54_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_54"](%/duration_predictor/flows.3/ScatterND_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_144_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_144"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_145_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_145"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_146_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_146"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Slice_17_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_17"](%/duration_predictor/flows.3/Shape_54_output_0, %/duration_predictor/flows.3/Constant_145_output_0, %/duration_predictor/flows.3/Constant_146_output_0, %/duration_predictor/flows.3/Constant_144_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Concat_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.3/Concat_19"](%/duration_predictor/flows.3/Shape_51_output_0, %/duration_predictor/flows.3/Slice_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Reshape_14_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_14"](%/duration_predictor/flows.3/Expand_25_output_0, %/duration_predictor/flows.3/Concat_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/ScatterND_7_output_0 : Float(*, *, requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND_7"](%/duration_predictor/flows.3/ScatterND_6_output_0, %/duration_predictor/flows.3/Concat_18_output_0, %/duration_predictor/flows.3/Reshape_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.3/Constant_147_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_147"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.3/Unsqueeze_23_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_23"](%/duration_predictor/flows.3/GatherND_1_output_0, %/duration_predictor/flows.3/Constant_147_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.3/GreaterOrEqual_1_output_0 : Bool(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::GreaterOrEqual[onnx_name="/duration_predictor/flows.3/GreaterOrEqual_1"](%/duration_predictor/flows.3/Unsqueeze_23_output_0, %/duration_predictor/flows.3/ScatterND_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.3/Cast_4_output_0 : Long(*, *, device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.3/Cast_4"](%/duration_predictor/flows.3/GreaterOrEqual_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.3/ReduceSum_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::ReduceSum[keepdims=0, onnx_name="/duration_predictor/flows.3/ReduceSum"](%/duration_predictor/flows.3/Cast_4_output_0, %onnx::ReduceSum_5156), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.3/Constant_148_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_148"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.3/Sub_3_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub_3"](%/duration_predictor/flows.3/ReduceSum_output_0, %/duration_predictor/flows.3/Constant_148_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.3/Constant_149_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_149"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:142:0
  %/duration_predictor/flows.3/Unsqueeze_24_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_24"](%/duration_predictor/flows.3/Sub_3_output_0, %/duration_predictor/flows.3/Constant_149_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:142:0
  %/duration_predictor/flows.3/GatherElements_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.3/GatherElements"](%/duration_predictor/flows.3/ScatterND_3_output_0, %/duration_predictor/flows.3/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:146:0
  %/duration_predictor/flows.3/Gather_12_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_12"](%/duration_predictor/flows.3/GatherElements_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:146:0
  %/duration_predictor/flows.3/GatherElements_1_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.3/GatherElements_1"](%/duration_predictor/flows.3/Sub_1_output_0, %/duration_predictor/flows.3/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:147:0
  %/duration_predictor/flows.3/Gather_13_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_13"](%/duration_predictor/flows.3/GatherElements_1_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:147:0
  %/duration_predictor/flows.3/GatherElements_2_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.3/GatherElements_2"](%/duration_predictor/flows.3/ScatterND_7_output_0, %/duration_predictor/flows.3/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:149:0
  %/duration_predictor/flows.3/Gather_14_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_14"](%/duration_predictor/flows.3/GatherElements_2_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:149:0
  %/duration_predictor/flows.3/Div_2_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/Div_2"](%/duration_predictor/flows.3/Sub_2_output_0, %/duration_predictor/flows.3/Sub_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:150:0
  %/duration_predictor/flows.3/GatherElements_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.3/GatherElements_3"](%/duration_predictor/flows.3/Div_2_output_0, %/duration_predictor/flows.3/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:151:0
  %/duration_predictor/flows.3/Gather_15_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_15"](%/duration_predictor/flows.3/GatherElements_3_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:151:0
  %/duration_predictor/flows.3/GatherElements_4_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.3/GatherElements_4"](%/duration_predictor/flows.3/Add_10_output_0, %/duration_predictor/flows.3/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:153:0
  %/duration_predictor/flows.3/Gather_16_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_16"](%/duration_predictor/flows.3/GatherElements_4_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:153:0
  %/duration_predictor/flows.3/Constant_150_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_150"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.3/Constant_151_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_151"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.3/Constant_152_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.3/Constant_152"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.3/Constant_153_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.3/Constant_153"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.3/Slice_18_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_18"](%/duration_predictor/flows.3/Add_10_output_0, %/duration_predictor/flows.3/Constant_151_output_0, %/duration_predictor/flows.3/Constant_152_output_0, %/duration_predictor/flows.3/Constant_150_output_0, %/duration_predictor/flows.3/Constant_153_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.3/GatherElements_5_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.3/GatherElements_5"](%/duration_predictor/flows.3/Slice_18_output_0, %/duration_predictor/flows.3/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.3/Gather_17_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_17"](%/duration_predictor/flows.3/GatherElements_5_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.3/GatherElements_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.3/GatherElements_6"](%/duration_predictor/flows.3/Sub_2_output_0, %/duration_predictor/flows.3/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:156:0
  %/duration_predictor/flows.3/Gather_18_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.3/Gather_18"](%/duration_predictor/flows.3/GatherElements_6_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:156:0
  %/duration_predictor/flows.3/Sub_4_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub_4"](%/duration_predictor/flows.3/GatherND_1_output_0, %/duration_predictor/flows.3/Gather_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:159:0
  %/duration_predictor/flows.3/Add_18_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_18"](%/duration_predictor/flows.3/Gather_16_output_0, %/duration_predictor/flows.3/Gather_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.3/Constant_154_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_154"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.3/Mul_26_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_26"](%/duration_predictor/flows.3/Gather_15_output_0, %/duration_predictor/flows.3/Constant_154_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.3/Sub_5_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub_5"](%/duration_predictor/flows.3/Add_18_output_0, %/duration_predictor/flows.3/Mul_26_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.3/Mul_27_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_27"](%/duration_predictor/flows.3/Sub_4_output_0, %/duration_predictor/flows.3/Sub_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:159:0
  %/duration_predictor/flows.3/Sub_6_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub_6"](%/duration_predictor/flows.3/Gather_15_output_0, %/duration_predictor/flows.3/Gather_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:161:0
  %/duration_predictor/flows.3/Mul_28_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_28"](%/duration_predictor/flows.3/Gather_18_output_0, %/duration_predictor/flows.3/Sub_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:161:0
  %/duration_predictor/flows.3/Add_19_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_19"](%/duration_predictor/flows.3/Mul_27_output_0, %/duration_predictor/flows.3/Mul_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:159:0
  %/duration_predictor/flows.3/Mul_29_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_29"](%/duration_predictor/flows.3/Gather_18_output_0, %/duration_predictor/flows.3/Gather_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:162:0
  %/duration_predictor/flows.3/Sub_7_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub_7"](%/duration_predictor/flows.3/Mul_29_output_0, %/duration_predictor/flows.3/Mul_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:162:0
  %/duration_predictor/flows.3/Neg_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/duration_predictor/flows.3/Neg"](%/duration_predictor/flows.3/Gather_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:165:0
  %/duration_predictor/flows.3/Mul_30_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_30"](%/duration_predictor/flows.3/Neg_output_0, %/duration_predictor/flows.3/Sub_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:165:0
  %/duration_predictor/flows.3/Constant_155_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_155"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.3/Pow_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.3/Pow"](%/duration_predictor/flows.3/Sub_7_output_0, %/duration_predictor/flows.3/Constant_155_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.3/Constant_156_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/duration_predictor/flows.3/Constant_156"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.3/Mul_31_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_31"](%/duration_predictor/flows.3/Add_19_output_0, %/duration_predictor/flows.3/Constant_156_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.3/Mul_32_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_32"](%/duration_predictor/flows.3/Mul_31_output_0, %/duration_predictor/flows.3/Mul_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.3/Sub_8_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub_8"](%/duration_predictor/flows.3/Pow_output_0, %/duration_predictor/flows.3/Mul_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.3/Constant_157_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.3/Constant_157"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.3/Mul_33_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_33"](%/duration_predictor/flows.3/Mul_30_output_0, %/duration_predictor/flows.3/Constant_157_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.3/Neg_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/duration_predictor/flows.3/Neg_1"](%/duration_predictor/flows.3/Sub_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.3/Sqrt_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.3/Sqrt"](%/duration_predictor/flows.3/Sub_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.3/Sub_9_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.3/Sub_9"](%/duration_predictor/flows.3/Neg_1_output_0, %/duration_predictor/flows.3/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.3/Div_3_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.3/Div_3"](%/duration_predictor/flows.3/Mul_33_output_0, %/duration_predictor/flows.3/Sub_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.3/Mul_34_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_34"](%/duration_predictor/flows.3/Div_3_output_0, %/duration_predictor/flows.3/Gather_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:171:0
  %/duration_predictor/flows.3/Add_20_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.3/Add_20"](%/duration_predictor/flows.3/Mul_34_output_0, %/duration_predictor/flows.3/Gather_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:171:0
  %/duration_predictor/flows.3/Shape_55_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_55"](%/duration_predictor/flows.3/ConstantOfShape_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Expand_28_output_0 : Bool(*, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_28"](%/duration_predictor/flows.3/Not_output_0, %/duration_predictor/flows.3/Shape_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/NonZero_5_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.3/NonZero_5"](%/duration_predictor/flows.3/Expand_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Transpose_9_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_9"](%/duration_predictor/flows.3/NonZero_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Constant_158_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_158"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Reshape_15_output_0 : Float(*, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_15"](%/duration_predictor/flows.3/GatherND_output_0, %/duration_predictor/flows.3/Constant_158_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Shape_56_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_56"](%/duration_predictor/flows.3/Transpose_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Constant_159_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_159"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Gather_19_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.3/Gather_19"](%/duration_predictor/flows.3/Shape_56_output_0, %/duration_predictor/flows.3/Constant_159_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Constant_160_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_160"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Constant_161_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_161"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Constant_162_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_162"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_25"](%/duration_predictor/flows.3/Gather_19_output_0, %/duration_predictor/flows.3/Constant_162_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Slice_19_output_0 : Float(*, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_19"](%/duration_predictor/flows.3/Reshape_15_output_0, %/duration_predictor/flows.3/Constant_161_output_0, %/duration_predictor/flows.3/Unsqueeze_25_output_0, %/duration_predictor/flows.3/Constant_160_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/ScatterND_8_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND_8"](%/duration_predictor/flows.3/ConstantOfShape_11_output_0, %/duration_predictor/flows.3/Transpose_9_output_0, %/duration_predictor/flows.3/Slice_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.3/Shape_57_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_57"](%/duration_predictor/flows.3/ScatterND_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Expand_29_output_0 : Bool(*, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.3/Expand_29"](%/duration_predictor/flows.3/And_output_0, %/duration_predictor/flows.3/Shape_57_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/NonZero_6_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.3/NonZero_6"](%/duration_predictor/flows.3/Expand_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Transpose_10_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.3/Transpose_10"](%/duration_predictor/flows.3/NonZero_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Constant_163_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.3/Constant_163"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Reshape_16_output_0 : Float(*, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.3/Reshape_16"](%/duration_predictor/flows.3/Add_20_output_0, %/duration_predictor/flows.3/Constant_163_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Shape_58_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.3/Shape_58"](%/duration_predictor/flows.3/Transpose_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Constant_164_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_164"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Gather_20_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.3/Gather_20"](%/duration_predictor/flows.3/Shape_58_output_0, %/duration_predictor/flows.3/Constant_164_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Constant_165_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_165"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Constant_166_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_166"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Constant_167_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.3/Constant_167"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.3/Unsqueeze_26"](%/duration_predictor/flows.3/Gather_20_output_0, %/duration_predictor/flows.3/Constant_167_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Slice_20_output_0 : Float(*, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.3/Slice_20"](%/duration_predictor/flows.3/Reshape_16_output_0, %/duration_predictor/flows.3/Constant_166_output_0, %/duration_predictor/flows.3/Unsqueeze_26_output_0, %/duration_predictor/flows.3/Constant_165_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/ScatterND_9_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.3/ScatterND_9"](%/duration_predictor/flows.3/ScatterND_8_output_0, %/duration_predictor/flows.3/Transpose_10_output_0, %/duration_predictor/flows.3/Slice_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.3/Concat_20_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name="/duration_predictor/flows.3/Concat_20"](%/duration_predictor/flows.3/Split_output_0, %/duration_predictor/flows.3/ScatterND_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:143:0
  %/duration_predictor/flows.3/Mul_35_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.3/Mul_35"](%/duration_predictor/flows.3/Concat_20_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:143:0
  %/duration_predictor/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Slice_2_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/Slice_2"](%/duration_predictor/flows.3/Mul_35_output_0, %/duration_predictor/Constant_13_output_0, %/duration_predictor/Constant_14_output_0, %/duration_predictor/Constant_12_output_0, %/duration_predictor/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/flows.2/Split_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu), %/duration_predictor/flows.2/Split_output_1 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Split[axis=1, onnx_name="/duration_predictor/flows.2/Split"](%/duration_predictor/Slice_2_output_0, %onnx::Split_4359), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:917:0
  %/duration_predictor/flows.2/pre/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.2/pre/Conv"](%/duration_predictor/flows.2/Split_output_0, %duration_predictor.flows.2.pre.weight, %duration_predictor.flows.2.pre.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/torch.nn.modules.conv.Conv1d::pre # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.2/convs/Add_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add"](%/duration_predictor/flows.2/pre/Conv_output_0, %/duration_predictor/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:53:0
  %/duration_predictor/flows.2/convs/Mul_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul"](%/duration_predictor/flows.2/convs/Add_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/flows.2/convs/convs_sep.0/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=192, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/duration_predictor/flows.2/convs/convs_sep.0/Conv"](%/duration_predictor/flows.2/convs/Mul_output_0, %duration_predictor.flows.2.convs.convs_sep.0.weight, %duration_predictor.flows.2.convs.convs_sep.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.2/convs/norms_1.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Transpose"](%/duration_predictor/flows.2/convs/convs_sep.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.2/convs/norms_1.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_1.0/ReduceMean"](%/duration_predictor/flows.2/convs/norms_1.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Sub"](%/duration_predictor/flows.2/convs/norms_1.0/Transpose_output_0, %/duration_predictor/flows.2/convs/norms_1.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Pow"](%/duration_predictor/flows.2/convs/norms_1.0/Sub_output_0, %/duration_predictor/flows.2/convs/norms_1.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_1.0/ReduceMean_1"](%/duration_predictor/flows.2/convs/norms_1.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Add"](%/duration_predictor/flows.2/convs/norms_1.0/ReduceMean_1_output_0, %/duration_predictor/flows.2/convs/norms_1.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Sqrt"](%/duration_predictor/flows.2/convs/norms_1.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Div"](%/duration_predictor/flows.2/convs/norms_1.0/Sub_output_0, %/duration_predictor/flows.2/convs/norms_1.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Mul"](%/duration_predictor/flows.2/convs/norms_1.0/Div_output_0, %duration_predictor.flows.2.convs.norms_1.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Add_1"](%/duration_predictor/flows.2/convs/norms_1.0/Mul_output_0, %duration_predictor.flows.2.convs.norms_1.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_1.0/Transpose_1"](%/duration_predictor/flows.2/convs/norms_1.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.2/convs/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.2/convs/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Div_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/Div"](%/duration_predictor/flows.2/convs/norms_1.0/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Erf_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.2/convs/Erf"](%/duration_predictor/flows.2/convs/Div_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/convs/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Add_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add_1"](%/duration_predictor/flows.2/convs/Erf_output_0, %/duration_predictor/flows.2/convs/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Mul_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_1"](%/duration_predictor/flows.2/convs/norms_1.0/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.2/convs/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Mul_2_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_2"](%/duration_predictor/flows.2/convs/Mul_1_output_0, %/duration_predictor/flows.2/convs/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/convs_1x1.0/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.2/convs/convs_1x1.0/Conv"](%/duration_predictor/flows.2/convs/Mul_2_output_0, %duration_predictor.flows.2.convs.convs_1x1.0.weight, %duration_predictor.flows.2.convs.convs_1x1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.2/convs/norms_2.0/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Transpose"](%/duration_predictor/flows.2/convs/convs_1x1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.2/convs/norms_2.0/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_2.0/ReduceMean"](%/duration_predictor/flows.2/convs/norms_2.0/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Sub"](%/duration_predictor/flows.2/convs/norms_2.0/Transpose_output_0, %/duration_predictor/flows.2/convs/norms_2.0/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Pow"](%/duration_predictor/flows.2/convs/norms_2.0/Sub_output_0, %/duration_predictor/flows.2/convs/norms_2.0/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_2.0/ReduceMean_1"](%/duration_predictor/flows.2/convs/norms_2.0/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Add"](%/duration_predictor/flows.2/convs/norms_2.0/ReduceMean_1_output_0, %/duration_predictor/flows.2/convs/norms_2.0/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Sqrt"](%/duration_predictor/flows.2/convs/norms_2.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Div"](%/duration_predictor/flows.2/convs/norms_2.0/Sub_output_0, %/duration_predictor/flows.2/convs/norms_2.0/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Mul"](%/duration_predictor/flows.2/convs/norms_2.0/Div_output_0, %duration_predictor.flows.2.convs.norms_2.0.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Add_1"](%/duration_predictor/flows.2/convs/norms_2.0/Mul_output_0, %duration_predictor.flows.2.convs.norms_2.0.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.0/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_2.0/Transpose_1"](%/duration_predictor/flows.2/convs/norms_2.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.2/convs/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.2/convs/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Div_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/Div_1"](%/duration_predictor/flows.2/convs/norms_2.0/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Erf_1_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.2/convs/Erf_1"](%/duration_predictor/flows.2/convs/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Constant_4_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/convs/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Add_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add_2"](%/duration_predictor/flows.2/convs/Erf_1_output_0, %/duration_predictor/flows.2/convs/Constant_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Mul_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_3"](%/duration_predictor/flows.2/convs/norms_2.0/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Constant_5_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.2/convs/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Mul_4_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_4"](%/duration_predictor/flows.2/convs/Mul_3_output_0, %/duration_predictor/flows.2/convs/Constant_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Add_3_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add_3"](%/duration_predictor/flows.2/convs/Add_output_0, %/duration_predictor/flows.2/convs/Mul_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/flows.2/convs/Mul_5_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_5"](%/duration_predictor/flows.2/convs/Add_3_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/flows.2/convs/convs_sep.1/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=192, kernel_shape=[3], pads=[3, 3], strides=[1], onnx_name="/duration_predictor/flows.2/convs/convs_sep.1/Conv"](%/duration_predictor/flows.2/convs/Mul_5_output_0, %duration_predictor.flows.2.convs.convs_sep.1.weight, %duration_predictor.flows.2.convs.convs_sep.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.2/convs/norms_1.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Transpose"](%/duration_predictor/flows.2/convs/convs_sep.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.2/convs/norms_1.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_1.1/ReduceMean"](%/duration_predictor/flows.2/convs/norms_1.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Sub"](%/duration_predictor/flows.2/convs/norms_1.1/Transpose_output_0, %/duration_predictor/flows.2/convs/norms_1.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Pow"](%/duration_predictor/flows.2/convs/norms_1.1/Sub_output_0, %/duration_predictor/flows.2/convs/norms_1.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_1.1/ReduceMean_1"](%/duration_predictor/flows.2/convs/norms_1.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Add"](%/duration_predictor/flows.2/convs/norms_1.1/ReduceMean_1_output_0, %/duration_predictor/flows.2/convs/norms_1.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Sqrt"](%/duration_predictor/flows.2/convs/norms_1.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Div"](%/duration_predictor/flows.2/convs/norms_1.1/Sub_output_0, %/duration_predictor/flows.2/convs/norms_1.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Mul"](%/duration_predictor/flows.2/convs/norms_1.1/Div_output_0, %duration_predictor.flows.2.convs.norms_1.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Add_1"](%/duration_predictor/flows.2/convs/norms_1.1/Mul_output_0, %duration_predictor.flows.2.convs.norms_1.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_1.1/Transpose_1"](%/duration_predictor/flows.2/convs/norms_1.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.2/convs/Constant_6_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.2/convs/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Div_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/Div_2"](%/duration_predictor/flows.2/convs/norms_1.1/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Constant_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Erf_2_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.2/convs/Erf_2"](%/duration_predictor/flows.2/convs/Div_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Constant_7_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/convs/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Add_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add_4"](%/duration_predictor/flows.2/convs/Erf_2_output_0, %/duration_predictor/flows.2/convs/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Mul_6_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_6"](%/duration_predictor/flows.2/convs/norms_1.1/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Add_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.2/convs/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Mul_7_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_7"](%/duration_predictor/flows.2/convs/Mul_6_output_0, %/duration_predictor/flows.2/convs/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/convs_1x1.1/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.2/convs/convs_1x1.1/Conv"](%/duration_predictor/flows.2/convs/Mul_7_output_0, %duration_predictor.flows.2.convs.convs_1x1.1.weight, %duration_predictor.flows.2.convs.convs_1x1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.2/convs/norms_2.1/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Transpose"](%/duration_predictor/flows.2/convs/convs_1x1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.2/convs/norms_2.1/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_2.1/ReduceMean"](%/duration_predictor/flows.2/convs/norms_2.1/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Sub"](%/duration_predictor/flows.2/convs/norms_2.1/Transpose_output_0, %/duration_predictor/flows.2/convs/norms_2.1/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Pow"](%/duration_predictor/flows.2/convs/norms_2.1/Sub_output_0, %/duration_predictor/flows.2/convs/norms_2.1/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_2.1/ReduceMean_1"](%/duration_predictor/flows.2/convs/norms_2.1/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Add"](%/duration_predictor/flows.2/convs/norms_2.1/ReduceMean_1_output_0, %/duration_predictor/flows.2/convs/norms_2.1/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Sqrt"](%/duration_predictor/flows.2/convs/norms_2.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Div"](%/duration_predictor/flows.2/convs/norms_2.1/Sub_output_0, %/duration_predictor/flows.2/convs/norms_2.1/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Mul"](%/duration_predictor/flows.2/convs/norms_2.1/Div_output_0, %duration_predictor.flows.2.convs.norms_2.1.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Add_1"](%/duration_predictor/flows.2/convs/norms_2.1/Mul_output_0, %duration_predictor.flows.2.convs.norms_2.1.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.1/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_2.1/Transpose_1"](%/duration_predictor/flows.2/convs/norms_2.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.2/convs/Constant_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.2/convs/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Div_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/Div_3"](%/duration_predictor/flows.2/convs/norms_2.1/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Constant_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Erf_3_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.2/convs/Erf_3"](%/duration_predictor/flows.2/convs/Div_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Constant_10_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/convs/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Add_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add_5"](%/duration_predictor/flows.2/convs/Erf_3_output_0, %/duration_predictor/flows.2/convs/Constant_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Mul_8_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_8"](%/duration_predictor/flows.2/convs/norms_2.1/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Add_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Constant_11_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.2/convs/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Mul_9_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_9"](%/duration_predictor/flows.2/convs/Mul_8_output_0, %/duration_predictor/flows.2/convs/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Add_6_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add_6"](%/duration_predictor/flows.2/convs/Add_3_output_0, %/duration_predictor/flows.2/convs/Mul_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/flows.2/convs/Mul_10_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_10"](%/duration_predictor/flows.2/convs/Add_6_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:55:0
  %/duration_predictor/flows.2/convs/convs_sep.2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[9], group=192, kernel_shape=[3], pads=[9, 9], strides=[1], onnx_name="/duration_predictor/flows.2/convs/convs_sep.2/Conv"](%/duration_predictor/flows.2/convs/Mul_10_output_0, %duration_predictor.flows.2.convs.convs_sep.2.weight, %duration_predictor.flows.2.convs.convs_sep.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_sep.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.2/convs/norms_1.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Transpose"](%/duration_predictor/flows.2/convs/convs_sep.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.2/convs/norms_1.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_1.2/ReduceMean"](%/duration_predictor/flows.2/convs/norms_1.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Sub"](%/duration_predictor/flows.2/convs/norms_1.2/Transpose_output_0, %/duration_predictor/flows.2/convs/norms_1.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Pow"](%/duration_predictor/flows.2/convs/norms_1.2/Sub_output_0, %/duration_predictor/flows.2/convs/norms_1.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_1.2/ReduceMean_1"](%/duration_predictor/flows.2/convs/norms_1.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Add"](%/duration_predictor/flows.2/convs/norms_1.2/ReduceMean_1_output_0, %/duration_predictor/flows.2/convs/norms_1.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Sqrt"](%/duration_predictor/flows.2/convs/norms_1.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Div"](%/duration_predictor/flows.2/convs/norms_1.2/Sub_output_0, %/duration_predictor/flows.2/convs/norms_1.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Mul"](%/duration_predictor/flows.2/convs/norms_1.2/Div_output_0, %duration_predictor.flows.2.convs.norms_1.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Add_1"](%/duration_predictor/flows.2/convs/norms_1.2/Mul_output_0, %duration_predictor.flows.2.convs.norms_1.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_1.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_1.2/Transpose_1"](%/duration_predictor/flows.2/convs/norms_1.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_1.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.2/convs/Constant_12_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.2/convs/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Div_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/Div_4"](%/duration_predictor/flows.2/convs/norms_1.2/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Erf_4_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.2/convs/Erf_4"](%/duration_predictor/flows.2/convs/Div_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/convs/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Add_7_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add_7"](%/duration_predictor/flows.2/convs/Erf_4_output_0, %/duration_predictor/flows.2/convs/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Mul_11_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_11"](%/duration_predictor/flows.2/convs/norms_1.2/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Add_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Constant_14_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.2/convs/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/Mul_12_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_12"](%/duration_predictor/flows.2/convs/Mul_11_output_0, %/duration_predictor/flows.2/convs/Constant_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:57:0
  %/duration_predictor/flows.2/convs/convs_1x1.2/Conv_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.2/convs/convs_1x1.2/Conv"](%/duration_predictor/flows.2/convs/Mul_12_output_0, %duration_predictor.flows.2.convs.convs_1x1.2.weight, %duration_predictor.flows.2.convs.convs_1x1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/torch.nn.modules.conv.Conv1d::convs_1x1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.2/convs/norms_2.2/Transpose_output_0 : Float(*, *, 192, strides=[19200, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Transpose"](%/duration_predictor/flows.2/convs/convs_1x1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:51:0
  %/duration_predictor/flows.2/convs/norms_2.2/ReduceMean_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_2.2/ReduceMean"](%/duration_predictor/flows.2/convs/norms_2.2/Transpose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Sub_output_0 : Float(*, *, 192, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Sub"](%/duration_predictor/flows.2/convs/norms_2.2/Transpose_output_0, %/duration_predictor/flows.2/convs/norms_2.2/ReduceMean_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Pow_output_0 : Float(*, *, 192, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Pow"](%/duration_predictor/flows.2/convs/norms_2.2/Sub_output_0, %/duration_predictor/flows.2/convs/norms_2.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/ReduceMean_1_output_0 : Float(*, *, 1, device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name="/duration_predictor/flows.2/convs/norms_2.2/ReduceMean_1"](%/duration_predictor/flows.2/convs/norms_2.2/Pow_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Add_output_0 : Float(*, *, 1, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Add"](%/duration_predictor/flows.2/convs/norms_2.2/ReduceMean_1_output_0, %/duration_predictor/flows.2/convs/norms_2.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Sqrt_output_0 : Float(*, *, 1, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Sqrt"](%/duration_predictor/flows.2/convs/norms_2.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Div_output_0 : Float(*, *, 192, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Div"](%/duration_predictor/flows.2/convs/norms_2.2/Sub_output_0, %/duration_predictor/flows.2/convs/norms_2.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Mul_output_0 : Float(*, *, 192, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Mul"](%/duration_predictor/flows.2/convs/norms_2.2/Div_output_0, %duration_predictor.flows.2.convs.norms_2.2.gamma), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Add_1_output_0 : Float(*, *, 192, strides=[19200, 192, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Add_1"](%/duration_predictor/flows.2/convs/norms_2.2/Mul_output_0, %duration_predictor.flows.2.convs.norms_2.2.beta), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:2576:0
  %/duration_predictor/flows.2/convs/norms_2.2/Transpose_1_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/duration_predictor/flows.2/convs/norms_2.2/Transpose_1"](%/duration_predictor/flows.2/convs/norms_2.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs/TTS.tts.layers.generic.normalization.LayerNorm2::norms_2.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/normalization.py:53:0
  %/duration_predictor/flows.2/convs/Constant_15_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name="/duration_predictor/flows.2/convs/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Div_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/convs/Div_5"](%/duration_predictor/flows.2/convs/norms_2.2/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Erf_5_output_0 : Float(*, 192, *, device=cpu) = onnx::Erf[onnx_name="/duration_predictor/flows.2/convs/Erf_5"](%/duration_predictor/flows.2/convs/Div_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Constant_16_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/convs/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Add_8_output_0 : Float(*, 192, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add_8"](%/duration_predictor/flows.2/convs/Erf_5_output_0, %/duration_predictor/flows.2/convs/Constant_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Mul_13_output_0 : Float(*, 192, *, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_13"](%/duration_predictor/flows.2/convs/norms_2.2/Transpose_1_output_0, %/duration_predictor/flows.2/convs/Add_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Constant_17_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name="/duration_predictor/flows.2/convs/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Mul_14_output_0 : Float(*, 192, *, strides=[19200, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_14"](%/duration_predictor/flows.2/convs/Mul_13_output_0, %/duration_predictor/flows.2/convs/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:60:0
  %/duration_predictor/flows.2/convs/Add_9_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/convs/Add_9"](%/duration_predictor/flows.2/convs/Add_6_output_0, %/duration_predictor/flows.2/convs/Mul_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:62:0
  %/duration_predictor/flows.2/convs/Mul_15_output_0 : Float(*, 192, *, strides=[19200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/convs/Mul_15"](%/duration_predictor/flows.2/convs/Add_9_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/TTS.tts.layers.vits.stochastic_duration_predictor.DilatedDepthSeparableConv::convs # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:63:0
  %/duration_predictor/flows.2/proj/Conv_output_0 : Float(*, 29, *, strides=[2900, 100, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/duration_predictor/flows.2/proj/Conv"](%/duration_predictor/flows.2/convs/Mul_15_output_0, %duration_predictor.flows.2.proj.weight, %duration_predictor.flows.2.proj.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2/torch.nn.modules.conv.Conv1d::proj # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/duration_predictor/flows.2/Mul_output_0 : Float(*, 29, *, strides=[2900, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul"](%/duration_predictor/flows.2/proj/Conv_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:124:0
  %/duration_predictor/flows.2/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape"](%/duration_predictor/flows.2/Split_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.2/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.2/Gather_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.2/Gather"](%/duration_predictor/flows.2/Shape_output_0, %/duration_predictor/flows.2/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.2/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_1"](%/duration_predictor/flows.2/Split_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.2/Constant_1_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.2/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.2/Gather_1"](%/duration_predictor/flows.2/Shape_1_output_0, %/duration_predictor/flows.2/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.2/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_2"](%/duration_predictor/flows.2/Split_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.2/Constant_2_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %/duration_predictor/flows.2/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.2/Gather_2"](%/duration_predictor/flows.2/Shape_2_output_0, %/duration_predictor/flows.2/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:126:0
  %onnx::Unsqueeze_6292 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/flows.2/Unsqueeze_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze"](%/duration_predictor/flows.2/Gather_output_0, %onnx::Unsqueeze_6292), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2
  %onnx::Unsqueeze_6294 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/flows.2/Unsqueeze_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_1"](%/duration_predictor/flows.2/Gather_1_output_0, %onnx::Unsqueeze_6294), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2
  %/duration_predictor/flows.2/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2
  %onnx::Unsqueeze_6298 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/duration_predictor/flows.2/Unsqueeze_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_2"](%/duration_predictor/flows.2/Gather_2_output_0, %onnx::Unsqueeze_6298), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2
  %/duration_predictor/flows.2/Concat_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat"](%/duration_predictor/flows.2/Unsqueeze_output_0, %/duration_predictor/flows.2/Unsqueeze_1_output_0, %/duration_predictor/flows.2/Constant_3_output_0, %/duration_predictor/flows.2/Unsqueeze_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:127:0
  %/duration_predictor/flows.2/Reshape_output_0 : Float(*, *, *, *, strides=[2900, 2900, 100, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape"](%/duration_predictor/flows.2/Mul_output_0, %/duration_predictor/flows.2/Concat_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:127:0
  %/duration_predictor/flows.2/Transpose_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 1, 3, 2], onnx_name="/duration_predictor/flows.2/Transpose"](%/duration_predictor/flows.2/Reshape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:127:0
  %/duration_predictor/flows.2/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/duration_predictor/flows.2/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.2/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.2/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.2/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.2/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.2/Slice_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice"](%/duration_predictor/flows.2/Transpose_output_0, %/duration_predictor/flows.2/Constant_5_output_0, %/duration_predictor/flows.2/Constant_6_output_0, %/duration_predictor/flows.2/Constant_4_output_0, %/duration_predictor/flows.2/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.2/Constant_8_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={13.8564}, onnx_name="/duration_predictor/flows.2/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.2/Div_output_0 : Float(*, *, *, *, strides=[1000, 1000, 1, 100], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/Div"](%/duration_predictor/flows.2/Slice_output_0, %/duration_predictor/flows.2/Constant_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:129:0
  %/duration_predictor/flows.2/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/duration_predictor/flows.2/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.2/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.2/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.2/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={20}, onnx_name="/duration_predictor/flows.2/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.2/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.2/Slice_1_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_1"](%/duration_predictor/flows.2/Transpose_output_0, %/duration_predictor/flows.2/Constant_10_output_0, %/duration_predictor/flows.2/Constant_11_output_0, %/duration_predictor/flows.2/Constant_9_output_0, %/duration_predictor/flows.2/Constant_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.2/Constant_13_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={13.8564}, onnx_name="/duration_predictor/flows.2/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.2/Div_1_output_0 : Float(*, *, *, *, strides=[1000, 1000, 1, 100], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/Div_1"](%/duration_predictor/flows.2/Slice_1_output_0, %/duration_predictor/flows.2/Constant_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:130:0
  %/duration_predictor/flows.2/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/duration_predictor/flows.2/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.2/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={20}, onnx_name="/duration_predictor/flows.2/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.2/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.2/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.2/Slice_2_output_0 : Float(*, *, *, *, strides=[2900, 2900, 1, 100], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_2"](%/duration_predictor/flows.2/Transpose_output_0, %/duration_predictor/flows.2/Constant_15_output_0, %/duration_predictor/flows.2/Constant_16_output_0, %/duration_predictor/flows.2/Constant_14_output_0, %/duration_predictor/flows.2/Constant_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:131:0
  %/duration_predictor/flows.2/Constant_18_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-5}, onnx_name="/duration_predictor/flows.2/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.2/GreaterOrEqual_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::GreaterOrEqual[onnx_name="/duration_predictor/flows.2/GreaterOrEqual"](%/duration_predictor/flows.2/Split_output_1, %/duration_predictor/flows.2/Constant_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.2/Constant_19_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={5}, onnx_name="/duration_predictor/flows.2/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.2/LessOrEqual_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::LessOrEqual[onnx_name="/duration_predictor/flows.2/LessOrEqual"](%/duration_predictor/flows.2/Split_output_1, %/duration_predictor/flows.2/Constant_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.2/And_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::And[onnx_name="/duration_predictor/flows.2/And"](%/duration_predictor/flows.2/GreaterOrEqual_output_0, %/duration_predictor/flows.2/LessOrEqual_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:62:0
  %/duration_predictor/flows.2/Not_output_0 : Bool(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::Not[onnx_name="/duration_predictor/flows.2/Not"](%/duration_predictor/flows.2/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:63:0
  %/duration_predictor/flows.2/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={6}, onnx_name="/duration_predictor/flows.2/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_21_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  1 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.2/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/ConstantOfShape_output_0 : Long(6, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.2/ConstantOfShape"](%/duration_predictor/flows.2/Constant_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Concat_1_output_0 : Long(8, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_1"](%/duration_predictor/flows.2/Constant_21_output_0, %/duration_predictor/flows.2/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.2/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Reshape_1_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_1"](%/duration_predictor/flows.2/Concat_1_output_0, %/duration_predictor/flows.2/Constant_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Slice_3_output_0 : Long(4, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_3"](%/duration_predictor/flows.2/Reshape_1_output_0, %/duration_predictor/flows.2/Constant_24_output_0, %/duration_predictor/flows.2/Constant_25_output_0, %/duration_predictor/flows.2/Constant_23_output_0, %/duration_predictor/flows.2/Constant_26_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Transpose_1_output_0 : Long(2, 4, strides=[4, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_1"](%/duration_predictor/flows.2/Slice_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Reshape_2_output_0 : Long(8, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_2"](%/duration_predictor/flows.2/Transpose_1_output_0, %/duration_predictor/flows.2/Constant_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Cast_output_0 : Long(8, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.2/Cast"](%/duration_predictor/flows.2/Reshape_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Pad_output_0 : Float(*, *, *, *, strides=[1100, 1100, 11, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/duration_predictor/flows.2/Pad"](%/duration_predictor/flows.2/Slice_2_output_0, %/duration_predictor/flows.2/Cast_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Gather_3_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Gather[axis=3, onnx_name="/duration_predictor/flows.2/Gather_3"](%/duration_predictor/flows.2/Pad_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Shape_3_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_3"](%/duration_predictor/flows.2/Gather_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/ConstantOfShape_1_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0.539742}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_1"](%/duration_predictor/flows.2/Shape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Shape_4_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_4"](%/duration_predictor/flows.2/Gather_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Expand_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand"](%/duration_predictor/flows.2/ConstantOfShape_1_output_0, %/duration_predictor/flows.2/Shape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %onnx::Gather_6367 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/Pad_output_0)
  %onnx::Gather_6368 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_6369 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6367, %onnx::Gather_6368)
  %onnx::Range_6370 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6369)
  %onnx::Range_6371 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6372 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6373 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6371, %onnx::Range_6370, %onnx::Range_6372)
  %onnx::Gather_6374 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/Pad_output_0)
  %onnx::Gather_6375 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Cast_6376 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6374, %onnx::Gather_6375)
  %onnx::Range_6377 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6376)
  %onnx::Range_6378 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6379 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6380 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6378, %onnx::Range_6377, %onnx::Range_6379)
  %onnx::Gather_6381 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/Pad_output_0)
  %onnx::Gather_6382 : Long(device=cpu) = onnx::Constant[value={2}]()
  %onnx::Cast_6383 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6381, %onnx::Gather_6382)
  %onnx::Range_6384 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6383)
  %onnx::Range_6385 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6386 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6387 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6385, %onnx::Range_6384, %onnx::Range_6386)
  %onnx::Expand_6388 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()
  %onnx::Reshape_6389 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1  1 [ CPULongType{4} ]]()
  %onnx::Add_6390 : Long(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6373, %onnx::Reshape_6389)
  %onnx::Reshape_6391 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1 [ CPULongType{3} ]]()
  %onnx::Add_6392 : Long(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6380, %onnx::Reshape_6391)
  %onnx::Reshape_6393 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_6394 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6387, %onnx::Reshape_6393)
  %/duration_predictor/flows.2/Add_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add"](%onnx::Add_6390, %onnx::Add_6392), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Add_1_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_1"](%/duration_predictor/flows.2/Add_output_0, %onnx::Add_6394), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Add_2_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_2"](%/duration_predictor/flows.2/Add_1_output_0, %/duration_predictor/flows.2/Constant_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Shape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_5"](%/duration_predictor/flows.2/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Shape_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_6"](%/duration_predictor/flows.2/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/ConstantOfShape_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_2"](%/duration_predictor/flows.2/Shape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_29_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Mul_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_1"](%/duration_predictor/flows.2/ConstantOfShape_2_output_0, %/duration_predictor/flows.2/Constant_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Equal_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal"](%/duration_predictor/flows.2/Shape_5_output_0, %/duration_predictor/flows.2/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Where_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where"](%/duration_predictor/flows.2/Equal_output_0, %/duration_predictor/flows.2/ConstantOfShape_2_output_0, %/duration_predictor/flows.2/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Expand_1_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_1"](%onnx::Add_6390, %/duration_predictor/flows.2/Where_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Unsqueeze_3_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_3"](%/duration_predictor/flows.2/Expand_1_output_0, %/duration_predictor/flows.2/Constant_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Shape_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_7"](%/duration_predictor/flows.2/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/ConstantOfShape_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_3"](%/duration_predictor/flows.2/Shape_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_31_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Mul_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_2"](%/duration_predictor/flows.2/ConstantOfShape_3_output_0, %/duration_predictor/flows.2/Constant_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Equal_1_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_1"](%/duration_predictor/flows.2/Shape_5_output_0, %/duration_predictor/flows.2/Mul_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Where_1_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_1"](%/duration_predictor/flows.2/Equal_1_output_0, %/duration_predictor/flows.2/ConstantOfShape_3_output_0, %/duration_predictor/flows.2/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Expand_2_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_2"](%onnx::Add_6392, %/duration_predictor/flows.2/Where_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_32_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Unsqueeze_4_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_4"](%/duration_predictor/flows.2/Expand_2_output_0, %/duration_predictor/flows.2/Constant_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Shape_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_8"](%/duration_predictor/flows.2/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/ConstantOfShape_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_4"](%/duration_predictor/flows.2/Shape_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_33_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Mul_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_3"](%/duration_predictor/flows.2/ConstantOfShape_4_output_0, %/duration_predictor/flows.2/Constant_33_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Equal_2_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_2"](%/duration_predictor/flows.2/Shape_5_output_0, %/duration_predictor/flows.2/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Where_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_2"](%/duration_predictor/flows.2/Equal_2_output_0, %/duration_predictor/flows.2/ConstantOfShape_4_output_0, %/duration_predictor/flows.2/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Expand_3_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_3"](%onnx::Add_6394, %/duration_predictor/flows.2/Where_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Unsqueeze_5_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_5"](%/duration_predictor/flows.2/Expand_3_output_0, %/duration_predictor/flows.2/Constant_34_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Shape_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_9"](%/duration_predictor/flows.2/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/ConstantOfShape_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_5"](%/duration_predictor/flows.2/Shape_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_35_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Mul_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_4"](%/duration_predictor/flows.2/ConstantOfShape_5_output_0, %/duration_predictor/flows.2/Constant_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Equal_3_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_3"](%/duration_predictor/flows.2/Shape_5_output_0, %/duration_predictor/flows.2/Mul_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Where_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_3"](%/duration_predictor/flows.2/Equal_3_output_0, %/duration_predictor/flows.2/ConstantOfShape_5_output_0, %/duration_predictor/flows.2/Shape_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Expand_4_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_4"](%onnx::Expand_6388, %/duration_predictor/flows.2/Where_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Unsqueeze_6_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_6"](%/duration_predictor/flows.2/Expand_4_output_0, %/duration_predictor/flows.2/Constant_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Concat_2_output_0 : Long(*, *, *, *, 4, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.2/Concat_2"](%/duration_predictor/flows.2/Unsqueeze_3_output_0, %/duration_predictor/flows.2/Unsqueeze_4_output_0, %/duration_predictor/flows.2/Unsqueeze_5_output_0, %/duration_predictor/flows.2/Unsqueeze_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Shape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_10"](%/duration_predictor/flows.2/Pad_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_38_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/duration_predictor/flows.2/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Constant_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Slice_4_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_4"](%/duration_predictor/flows.2/Shape_10_output_0, %/duration_predictor/flows.2/Constant_38_output_0, %/duration_predictor/flows.2/Constant_39_output_0, %/duration_predictor/flows.2/Constant_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Concat_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_3"](%/duration_predictor/flows.2/Shape_5_output_0, %/duration_predictor/flows.2/Slice_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Reshape_3_output_0 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_3"](%/duration_predictor/flows.2/Expand_output_0, %/duration_predictor/flows.2/Concat_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/ScatterND_output_0 : Float(*, *, *, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND"](%/duration_predictor/flows.2/Pad_output_0, %/duration_predictor/flows.2/Concat_2_output_0, %/duration_predictor/flows.2/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:71:0
  %/duration_predictor/flows.2/Gather_4_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Gather[axis=3, onnx_name="/duration_predictor/flows.2/Gather_4"](%/duration_predictor/flows.2/ScatterND_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Shape_11_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_11"](%/duration_predictor/flows.2/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/ConstantOfShape_6_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0.539742}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_6"](%/duration_predictor/flows.2/Shape_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Shape_12_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_12"](%/duration_predictor/flows.2/Gather_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Expand_5_output_0 : Float(*, *, *, strides=[1100, 1100, 11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_5"](%/duration_predictor/flows.2/ConstantOfShape_6_output_0, %/duration_predictor/flows.2/Shape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %onnx::Gather_6450 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/ScatterND_output_0)
  %onnx::Gather_6451 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_6452 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6450, %onnx::Gather_6451)
  %onnx::Range_6453 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6452)
  %onnx::Range_6454 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6455 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6456 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6454, %onnx::Range_6453, %onnx::Range_6455)
  %onnx::Gather_6457 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/ScatterND_output_0)
  %onnx::Gather_6458 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Cast_6459 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6457, %onnx::Gather_6458)
  %onnx::Range_6460 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6459)
  %onnx::Range_6461 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6462 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6463 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6461, %onnx::Range_6460, %onnx::Range_6462)
  %onnx::Gather_6464 : Long(4, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/ScatterND_output_0)
  %onnx::Gather_6465 : Long(device=cpu) = onnx::Constant[value={2}]()
  %onnx::Cast_6466 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6464, %onnx::Gather_6465)
  %onnx::Range_6467 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6466)
  %onnx::Range_6468 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6469 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6470 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6468, %onnx::Range_6467, %onnx::Range_6469)
  %onnx::Expand_6471 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_6472 : Long(4, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1  1 [ CPULongType{4} ]]()
  %onnx::Add_6473 : Long(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6456, %onnx::Reshape_6472)
  %onnx::Reshape_6474 : Long(3, strides=[1], device=cpu) = onnx::Constant[value=-1  1  1 [ CPULongType{3} ]]()
  %onnx::Add_6475 : Long(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6463, %onnx::Reshape_6474)
  %onnx::Reshape_6476 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_6477 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6470, %onnx::Reshape_6476)
  %/duration_predictor/flows.2/Add_3_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_3"](%onnx::Add_6473, %onnx::Add_6475), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Add_4_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_4"](%/duration_predictor/flows.2/Add_3_output_0, %onnx::Add_6477), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_40_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_40"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Add_5_output_0 : Long(*, *, *, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_5"](%/duration_predictor/flows.2/Add_4_output_0, %/duration_predictor/flows.2/Constant_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Shape_13_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_13"](%/duration_predictor/flows.2/Add_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Shape_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_14"](%/duration_predictor/flows.2/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/ConstantOfShape_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_7"](%/duration_predictor/flows.2/Shape_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_41_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_41"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Mul_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_5"](%/duration_predictor/flows.2/ConstantOfShape_7_output_0, %/duration_predictor/flows.2/Constant_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Equal_4_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_4"](%/duration_predictor/flows.2/Shape_13_output_0, %/duration_predictor/flows.2/Mul_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Where_4_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_4"](%/duration_predictor/flows.2/Equal_4_output_0, %/duration_predictor/flows.2/ConstantOfShape_7_output_0, %/duration_predictor/flows.2/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Expand_6_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_6"](%onnx::Add_6473, %/duration_predictor/flows.2/Where_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_42"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Unsqueeze_7_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_7"](%/duration_predictor/flows.2/Expand_6_output_0, %/duration_predictor/flows.2/Constant_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Shape_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_15"](%/duration_predictor/flows.2/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/ConstantOfShape_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_8"](%/duration_predictor/flows.2/Shape_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_43_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_43"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Mul_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_6"](%/duration_predictor/flows.2/ConstantOfShape_8_output_0, %/duration_predictor/flows.2/Constant_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Equal_5_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_5"](%/duration_predictor/flows.2/Shape_13_output_0, %/duration_predictor/flows.2/Mul_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Where_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_5"](%/duration_predictor/flows.2/Equal_5_output_0, %/duration_predictor/flows.2/ConstantOfShape_8_output_0, %/duration_predictor/flows.2/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Expand_7_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_7"](%onnx::Add_6475, %/duration_predictor/flows.2/Where_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_44_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_44"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Unsqueeze_8_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_8"](%/duration_predictor/flows.2/Expand_7_output_0, %/duration_predictor/flows.2/Constant_44_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Shape_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_16"](%/duration_predictor/flows.2/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/ConstantOfShape_9_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_9"](%/duration_predictor/flows.2/Shape_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_45_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_45"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Mul_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_7"](%/duration_predictor/flows.2/ConstantOfShape_9_output_0, %/duration_predictor/flows.2/Constant_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Equal_6_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_6"](%/duration_predictor/flows.2/Shape_13_output_0, %/duration_predictor/flows.2/Mul_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Where_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_6"](%/duration_predictor/flows.2/Equal_6_output_0, %/duration_predictor/flows.2/ConstantOfShape_9_output_0, %/duration_predictor/flows.2/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Expand_8_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_8"](%onnx::Add_6477, %/duration_predictor/flows.2/Where_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_46_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_46"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Unsqueeze_9_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_9"](%/duration_predictor/flows.2/Expand_8_output_0, %/duration_predictor/flows.2/Constant_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Shape_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_17"](%/duration_predictor/flows.2/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/ConstantOfShape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_10"](%/duration_predictor/flows.2/Shape_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_47_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_47"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Mul_8_output_0 : Long(4, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_8"](%/duration_predictor/flows.2/ConstantOfShape_10_output_0, %/duration_predictor/flows.2/Constant_47_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Equal_7_output_0 : Bool(4, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_7"](%/duration_predictor/flows.2/Shape_13_output_0, %/duration_predictor/flows.2/Mul_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Where_7_output_0 : Long(4, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_7"](%/duration_predictor/flows.2/Equal_7_output_0, %/duration_predictor/flows.2/ConstantOfShape_10_output_0, %/duration_predictor/flows.2/Shape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Expand_9_output_0 : Long(*, *, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_9"](%onnx::Expand_6471, %/duration_predictor/flows.2/Where_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_48_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_48"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Unsqueeze_10_output_0 : Long(*, *, *, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_10"](%/duration_predictor/flows.2/Expand_9_output_0, %/duration_predictor/flows.2/Constant_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Concat_4_output_0 : Long(*, *, *, *, 4, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.2/Concat_4"](%/duration_predictor/flows.2/Unsqueeze_7_output_0, %/duration_predictor/flows.2/Unsqueeze_8_output_0, %/duration_predictor/flows.2/Unsqueeze_9_output_0, %/duration_predictor/flows.2/Unsqueeze_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Shape_18_output_0 : Long(4, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_18"](%/duration_predictor/flows.2/ScatterND_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_49_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_49"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}, onnx_name="/duration_predictor/flows.2/Constant_50"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Constant_51_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_51"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Slice_5_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_5"](%/duration_predictor/flows.2/Shape_18_output_0, %/duration_predictor/flows.2/Constant_50_output_0, %/duration_predictor/flows.2/Constant_51_output_0, %/duration_predictor/flows.2/Constant_49_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Concat_5_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_5"](%/duration_predictor/flows.2/Shape_13_output_0, %/duration_predictor/flows.2/Slice_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/Reshape_4_output_0 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_4"](%/duration_predictor/flows.2/Expand_5_output_0, %/duration_predictor/flows.2/Concat_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/ScatterND_1_output_0 : Float(*, *, *, *, strides=[1100, 1100, 11, 1], requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND_1"](%/duration_predictor/flows.2/ScatterND_output_0, %/duration_predictor/flows.2/Concat_4_output_0, %/duration_predictor/flows.2/Reshape_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:72:0
  %/duration_predictor/flows.2/NonZero_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.2/NonZero"](%/duration_predictor/flows.2/Not_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Transpose_2_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_2"](%/duration_predictor/flows.2/NonZero_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/GatherND_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.2/GatherND"](%/duration_predictor/flows.2/Split_output_1, %/duration_predictor/flows.2/Transpose_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Shape_19_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_19"](%/duration_predictor/flows.2/Split_output_1), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:65:0
  %/duration_predictor/flows.2/ConstantOfShape_11_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_11"](%/duration_predictor/flows.2/Shape_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:65:0
  %/duration_predictor/flows.2/NonZero_1_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.2/NonZero_1"](%/duration_predictor/flows.2/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:80:0
  %/duration_predictor/flows.2/Transpose_3_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_3"](%/duration_predictor/flows.2/NonZero_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:80:0
  %/duration_predictor/flows.2/GatherND_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.2/GatherND_1"](%/duration_predictor/flows.2/Split_output_1, %/duration_predictor/flows.2/Transpose_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:80:0
  %/duration_predictor/flows.2/NonZero_2_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.2/NonZero_2"](%/duration_predictor/flows.2/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:81:0
  %/duration_predictor/flows.2/Transpose_4_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_4"](%/duration_predictor/flows.2/NonZero_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:81:0
  %/duration_predictor/flows.2/GatherND_2_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.2/GatherND_2"](%/duration_predictor/flows.2/Div_output_0, %/duration_predictor/flows.2/Transpose_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:81:0
  %/duration_predictor/flows.2/NonZero_3_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.2/NonZero_3"](%/duration_predictor/flows.2/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:82:0
  %/duration_predictor/flows.2/Transpose_5_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_5"](%/duration_predictor/flows.2/NonZero_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:82:0
  %/duration_predictor/flows.2/GatherND_3_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.2/GatherND_3"](%/duration_predictor/flows.2/Div_1_output_0, %/duration_predictor/flows.2/Transpose_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:82:0
  %/duration_predictor/flows.2/NonZero_4_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.2/NonZero_4"](%/duration_predictor/flows.2/And_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:83:0
  %/duration_predictor/flows.2/Transpose_6_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_6"](%/duration_predictor/flows.2/NonZero_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:83:0
  %/duration_predictor/flows.2/GatherND_4_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::GatherND[onnx_name="/duration_predictor/flows.2/GatherND_4"](%/duration_predictor/flows.2/ScatterND_1_output_0, %/duration_predictor/flows.2/Transpose_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:83:0
  %/duration_predictor/flows.2/Shape_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_20"](%/duration_predictor/flows.2/GatherND_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:114:0
  %/duration_predictor/flows.2/Constant_52_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_52"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:114:0
  %/duration_predictor/flows.2/Gather_5_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.2/Gather_5"](%/duration_predictor/flows.2/Shape_20_output_0, %/duration_predictor/flows.2/Constant_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:114:0
  %/duration_predictor/flows.2/Softmax_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/duration_predictor/flows.2/Softmax"](%/duration_predictor/flows.2/GatherND_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/duration_predictor/flows.2/Cast_1_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/duration_predictor/flows.2/Cast_1"](%/duration_predictor/flows.2/Gather_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.2/Constant_53_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.2/Constant_53"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.2/Mul_9_output_0 : Float(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_9"](%/duration_predictor/flows.2/Cast_1_output_0, %/duration_predictor/flows.2/Constant_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.2/Constant_54_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_54"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:962:0
  %/duration_predictor/flows.2/Sub_output_0 : Float(requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub"](%/duration_predictor/flows.2/Constant_54_output_0, %/duration_predictor/flows.2/Mul_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:962:0
  %/duration_predictor/flows.2/Mul_10_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_10"](%/duration_predictor/flows.2/Sub_output_0, %/duration_predictor/flows.2/Softmax_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.2/Constant_55_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.2/Constant_55"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.2/Add_6_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_6"](%/duration_predictor/flows.2/Mul_10_output_0, %/duration_predictor/flows.2/Constant_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:122:0
  %/duration_predictor/flows.2/Constant_56_output_0 : Int(device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_56"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:123:0
  %/duration_predictor/flows.2/CumSum_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::CumSum[onnx_name="/duration_predictor/flows.2/CumSum"](%/duration_predictor/flows.2/Add_6_output_0, %/duration_predictor/flows.2/Constant_56_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:123:0
  %/duration_predictor/flows.2/Constant_57_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_57"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_58_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  0 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.2/Constant_58"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/ConstantOfShape_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_12"](%/duration_predictor/flows.2/Constant_57_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Concat_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_6"](%/duration_predictor/flows.2/Constant_58_output_0, %/duration_predictor/flows.2/ConstantOfShape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_59_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.2/Constant_59"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Reshape_5_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_5"](%/duration_predictor/flows.2/Concat_6_output_0, %/duration_predictor/flows.2/Constant_59_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_60_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_60"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_61_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_61"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_62_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_62"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_63_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_63"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Slice_6_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_6"](%/duration_predictor/flows.2/Reshape_5_output_0, %/duration_predictor/flows.2/Constant_61_output_0, %/duration_predictor/flows.2/Constant_62_output_0, %/duration_predictor/flows.2/Constant_60_output_0, %/duration_predictor/flows.2/Constant_63_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Transpose_7_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_7"](%/duration_predictor/flows.2/Slice_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_64_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_64"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Reshape_6_output_0 : Long(4, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_6"](%/duration_predictor/flows.2/Transpose_7_output_0, %/duration_predictor/flows.2/Constant_64_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Cast_2_output_0 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.2/Cast_2"](%/duration_predictor/flows.2/Reshape_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_65_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_65"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Pad_1_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/duration_predictor/flows.2/Pad_1"](%/duration_predictor/flows.2/CumSum_output_0, %/duration_predictor/flows.2/Cast_2_output_0, %/duration_predictor/flows.2/Constant_65_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_66_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.2/Constant_66"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.2/Mul_11_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_11"](%/duration_predictor/flows.2/Pad_1_output_0, %/duration_predictor/flows.2/Constant_66_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.2/Constant_67_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-5}, onnx_name="/duration_predictor/flows.2/Constant_67"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.2/Add_7_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_7"](%/duration_predictor/flows.2/Mul_11_output_0, %/duration_predictor/flows.2/Constant_67_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:125:0
  %/duration_predictor/flows.2/Gather_6_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_6"](%/duration_predictor/flows.2/Add_7_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Shape_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_21"](%/duration_predictor/flows.2/Gather_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/ConstantOfShape_13_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={-5}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_13"](%/duration_predictor/flows.2/Shape_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Shape_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_22"](%/duration_predictor/flows.2/Gather_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Expand_10_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_10"](%/duration_predictor/flows.2/ConstantOfShape_13_output_0, %/duration_predictor/flows.2/Shape_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %onnx::Gather_6591 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/Add_7_output_0)
  %onnx::Gather_6592 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_6593 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6591, %onnx::Gather_6592)
  %onnx::Range_6594 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6593)
  %onnx::Range_6595 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6596 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6597 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6595, %onnx::Range_6594, %onnx::Range_6596)
  %onnx::Expand_6598 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()
  %onnx::Reshape_6599 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_6600 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6597, %onnx::Reshape_6599)
  %/duration_predictor/flows.2/Constant_68_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_68"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Add_8_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_8"](%onnx::Add_6600, %/duration_predictor/flows.2/Constant_68_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Shape_23_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_23"](%/duration_predictor/flows.2/Add_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Shape_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_24"](%/duration_predictor/flows.2/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/ConstantOfShape_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_14"](%/duration_predictor/flows.2/Shape_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Constant_69_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_69"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Mul_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_12"](%/duration_predictor/flows.2/ConstantOfShape_14_output_0, %/duration_predictor/flows.2/Constant_69_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Equal_8_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_8"](%/duration_predictor/flows.2/Shape_23_output_0, %/duration_predictor/flows.2/Mul_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Where_8_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_8"](%/duration_predictor/flows.2/Equal_8_output_0, %/duration_predictor/flows.2/ConstantOfShape_14_output_0, %/duration_predictor/flows.2/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Expand_11_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_11"](%onnx::Add_6600, %/duration_predictor/flows.2/Where_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Constant_70_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_70"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Unsqueeze_11_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_11"](%/duration_predictor/flows.2/Expand_11_output_0, %/duration_predictor/flows.2/Constant_70_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Shape_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_25"](%/duration_predictor/flows.2/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/ConstantOfShape_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_15"](%/duration_predictor/flows.2/Shape_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Constant_71_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_71"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Mul_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_13"](%/duration_predictor/flows.2/ConstantOfShape_15_output_0, %/duration_predictor/flows.2/Constant_71_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Equal_9_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_9"](%/duration_predictor/flows.2/Shape_23_output_0, %/duration_predictor/flows.2/Mul_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Where_9_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_9"](%/duration_predictor/flows.2/Equal_9_output_0, %/duration_predictor/flows.2/ConstantOfShape_15_output_0, %/duration_predictor/flows.2/Shape_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Expand_12_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_12"](%onnx::Expand_6598, %/duration_predictor/flows.2/Where_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Constant_72_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_72"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Unsqueeze_12_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_12"](%/duration_predictor/flows.2/Expand_12_output_0, %/duration_predictor/flows.2/Constant_72_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Concat_7_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.2/Concat_7"](%/duration_predictor/flows.2/Unsqueeze_11_output_0, %/duration_predictor/flows.2/Unsqueeze_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Shape_26_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_26"](%/duration_predictor/flows.2/Add_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Constant_73_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_73"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Constant_74_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_74"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Constant_75_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_75"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Slice_7_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_7"](%/duration_predictor/flows.2/Shape_26_output_0, %/duration_predictor/flows.2/Constant_74_output_0, %/duration_predictor/flows.2/Constant_75_output_0, %/duration_predictor/flows.2/Constant_73_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Concat_8_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_8"](%/duration_predictor/flows.2/Shape_23_output_0, %/duration_predictor/flows.2/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Reshape_7_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_7"](%/duration_predictor/flows.2/Expand_10_output_0, %/duration_predictor/flows.2/Concat_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/ScatterND_2_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND_2"](%/duration_predictor/flows.2/Add_7_output_0, %/duration_predictor/flows.2/Concat_7_output_0, %/duration_predictor/flows.2/Reshape_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:126:0
  %/duration_predictor/flows.2/Gather_7_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_7"](%/duration_predictor/flows.2/ScatterND_2_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Shape_27_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_27"](%/duration_predictor/flows.2/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/ConstantOfShape_16_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={5}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_16"](%/duration_predictor/flows.2/Shape_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Shape_28_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_28"](%/duration_predictor/flows.2/Gather_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Expand_13_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_13"](%/duration_predictor/flows.2/ConstantOfShape_16_output_0, %/duration_predictor/flows.2/Shape_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %onnx::Gather_6636 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/ScatterND_2_output_0)
  %onnx::Gather_6637 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_6638 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6636, %onnx::Gather_6637)
  %onnx::Range_6639 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6638)
  %onnx::Range_6640 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6641 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6642 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6640, %onnx::Range_6639, %onnx::Range_6641)
  %onnx::Expand_6643 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_6644 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_6645 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6642, %onnx::Reshape_6644)
  %/duration_predictor/flows.2/Constant_76_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_76"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Add_9_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_9"](%onnx::Add_6645, %/duration_predictor/flows.2/Constant_76_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Shape_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_29"](%/duration_predictor/flows.2/Add_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Shape_30_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_30"](%/duration_predictor/flows.2/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/ConstantOfShape_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_17"](%/duration_predictor/flows.2/Shape_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Constant_77_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_77"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Mul_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_14"](%/duration_predictor/flows.2/ConstantOfShape_17_output_0, %/duration_predictor/flows.2/Constant_77_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Equal_10_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_10"](%/duration_predictor/flows.2/Shape_29_output_0, %/duration_predictor/flows.2/Mul_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Where_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_10"](%/duration_predictor/flows.2/Equal_10_output_0, %/duration_predictor/flows.2/ConstantOfShape_17_output_0, %/duration_predictor/flows.2/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Expand_14_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_14"](%onnx::Add_6645, %/duration_predictor/flows.2/Where_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Constant_78_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_78"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Unsqueeze_13_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_13"](%/duration_predictor/flows.2/Expand_14_output_0, %/duration_predictor/flows.2/Constant_78_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Shape_31_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_31"](%/duration_predictor/flows.2/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/ConstantOfShape_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_18"](%/duration_predictor/flows.2/Shape_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Constant_79_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_79"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Mul_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_15"](%/duration_predictor/flows.2/ConstantOfShape_18_output_0, %/duration_predictor/flows.2/Constant_79_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Equal_11_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_11"](%/duration_predictor/flows.2/Shape_29_output_0, %/duration_predictor/flows.2/Mul_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Where_11_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_11"](%/duration_predictor/flows.2/Equal_11_output_0, %/duration_predictor/flows.2/ConstantOfShape_18_output_0, %/duration_predictor/flows.2/Shape_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Expand_15_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_15"](%onnx::Expand_6643, %/duration_predictor/flows.2/Where_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Constant_80_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_80"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Unsqueeze_14_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_14"](%/duration_predictor/flows.2/Expand_15_output_0, %/duration_predictor/flows.2/Constant_80_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Concat_9_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.2/Concat_9"](%/duration_predictor/flows.2/Unsqueeze_13_output_0, %/duration_predictor/flows.2/Unsqueeze_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Shape_32_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_32"](%/duration_predictor/flows.2/ScatterND_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Constant_81_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_81"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Constant_82_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_82"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Constant_83_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_83"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Slice_8_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_8"](%/duration_predictor/flows.2/Shape_32_output_0, %/duration_predictor/flows.2/Constant_82_output_0, %/duration_predictor/flows.2/Constant_83_output_0, %/duration_predictor/flows.2/Constant_81_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Concat_10_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_10"](%/duration_predictor/flows.2/Shape_29_output_0, %/duration_predictor/flows.2/Slice_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Reshape_8_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_8"](%/duration_predictor/flows.2/Expand_13_output_0, %/duration_predictor/flows.2/Concat_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/ScatterND_3_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND_3"](%/duration_predictor/flows.2/ScatterND_2_output_0, %/duration_predictor/flows.2/Concat_9_output_0, %/duration_predictor/flows.2/Reshape_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:127:0
  %/duration_predictor/flows.2/Constant_84_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_84"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Constant_85_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_85"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Constant_86_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_86"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Constant_87_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_87"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Slice_9_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_9"](%/duration_predictor/flows.2/ScatterND_3_output_0, %/duration_predictor/flows.2/Constant_85_output_0, %/duration_predictor/flows.2/Constant_86_output_0, %/duration_predictor/flows.2/Constant_84_output_0, %/duration_predictor/flows.2/Constant_87_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Constant_88_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_88"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Constant_89_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_89"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Constant_90_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_90"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Constant_91_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_91"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Slice_10_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_10"](%/duration_predictor/flows.2/ScatterND_3_output_0, %/duration_predictor/flows.2/Constant_89_output_0, %/duration_predictor/flows.2/Constant_90_output_0, %/duration_predictor/flows.2/Constant_88_output_0, %/duration_predictor/flows.2/Constant_91_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Sub_1_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub_1"](%/duration_predictor/flows.2/Slice_9_output_0, %/duration_predictor/flows.2/Slice_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:128:0
  %/duration_predictor/flows.2/Softplus_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Softplus[onnx_name="/duration_predictor/flows.2/Softplus"](%/duration_predictor/flows.2/GatherND_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:130:0
  %/duration_predictor/flows.2/Constant_92_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.2/Constant_92"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:130:0
  %/duration_predictor/flows.2/Add_10_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_10"](%/duration_predictor/flows.2/Softplus_output_0, %/duration_predictor/flows.2/Constant_92_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:130:0
  %/duration_predictor/flows.2/Softmax_1_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Softmax[axis=-1, onnx_name="/duration_predictor/flows.2/Softmax_1"](%/duration_predictor/flows.2/GatherND_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1888:0
  %/duration_predictor/flows.2/Mul_16_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_16"](%/duration_predictor/flows.2/Sub_output_0, %/duration_predictor/flows.2/Softmax_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:133:0
  %/duration_predictor/flows.2/Constant_93_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.001}, onnx_name="/duration_predictor/flows.2/Constant_93"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:133:0
  %/duration_predictor/flows.2/Add_11_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_11"](%/duration_predictor/flows.2/Mul_16_output_0, %/duration_predictor/flows.2/Constant_93_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:133:0
  %/duration_predictor/flows.2/Constant_94_output_0 : Int(device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_94"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:134:0
  %/duration_predictor/flows.2/CumSum_1_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::CumSum[onnx_name="/duration_predictor/flows.2/CumSum_1"](%/duration_predictor/flows.2/Add_11_output_0, %/duration_predictor/flows.2/Constant_94_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:134:0
  %/duration_predictor/flows.2/Constant_95_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_95"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_96_output_0 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 1  0 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.2/Constant_96"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/ConstantOfShape_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_19"](%/duration_predictor/flows.2/Constant_95_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Concat_11_output_0 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_11"](%/duration_predictor/flows.2/Constant_96_output_0, %/duration_predictor/flows.2/ConstantOfShape_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_97_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/duration_predictor/flows.2/Constant_97"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Reshape_9_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_9"](%/duration_predictor/flows.2/Concat_11_output_0, %/duration_predictor/flows.2/Constant_97_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_98_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_98"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_99_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_99"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_100_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_100"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_101_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_101"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Slice_11_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_11"](%/duration_predictor/flows.2/Reshape_9_output_0, %/duration_predictor/flows.2/Constant_99_output_0, %/duration_predictor/flows.2/Constant_100_output_0, %/duration_predictor/flows.2/Constant_98_output_0, %/duration_predictor/flows.2/Constant_101_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Transpose_8_output_0 : Long(2, 2, strides=[2, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_8"](%/duration_predictor/flows.2/Slice_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_102_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_102"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Reshape_10_output_0 : Long(4, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_10"](%/duration_predictor/flows.2/Transpose_8_output_0, %/duration_predictor/flows.2/Constant_102_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Cast_3_output_0 : Long(4, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.2/Cast_3"](%/duration_predictor/flows.2/Reshape_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_103_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_103"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Pad_2_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/duration_predictor/flows.2/Pad_2"](%/duration_predictor/flows.2/CumSum_1_output_0, %/duration_predictor/flows.2/Cast_3_output_0, %/duration_predictor/flows.2/Constant_103_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/duration_predictor/flows.2/Constant_104_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={10}, onnx_name="/duration_predictor/flows.2/Constant_104"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.2/Mul_17_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_17"](%/duration_predictor/flows.2/Pad_2_output_0, %/duration_predictor/flows.2/Constant_104_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.2/Constant_105_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-5}, onnx_name="/duration_predictor/flows.2/Constant_105"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.2/Add_12_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_12"](%/duration_predictor/flows.2/Mul_17_output_0, %/duration_predictor/flows.2/Constant_105_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:136:0
  %/duration_predictor/flows.2/Gather_8_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_8"](%/duration_predictor/flows.2/Add_12_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Shape_33_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_33"](%/duration_predictor/flows.2/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/ConstantOfShape_20_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={-5}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_20"](%/duration_predictor/flows.2/Shape_33_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Shape_34_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_34"](%/duration_predictor/flows.2/Gather_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Expand_16_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_16"](%/duration_predictor/flows.2/ConstantOfShape_20_output_0, %/duration_predictor/flows.2/Shape_34_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %onnx::Gather_6736 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/Add_12_output_0)
  %onnx::Gather_6737 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_6738 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6736, %onnx::Gather_6737)
  %onnx::Range_6739 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6738)
  %onnx::Range_6740 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6741 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6742 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6740, %onnx::Range_6739, %onnx::Range_6741)
  %onnx::Expand_6743 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()
  %onnx::Reshape_6744 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_6745 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6742, %onnx::Reshape_6744)
  %/duration_predictor/flows.2/Constant_106_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_106"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Add_13_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_13"](%onnx::Add_6745, %/duration_predictor/flows.2/Constant_106_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Shape_35_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_35"](%/duration_predictor/flows.2/Add_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Shape_36_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_36"](%/duration_predictor/flows.2/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/ConstantOfShape_21_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_21"](%/duration_predictor/flows.2/Shape_36_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Constant_107_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_107"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Mul_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_18"](%/duration_predictor/flows.2/ConstantOfShape_21_output_0, %/duration_predictor/flows.2/Constant_107_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Equal_12_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_12"](%/duration_predictor/flows.2/Shape_35_output_0, %/duration_predictor/flows.2/Mul_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Where_12_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_12"](%/duration_predictor/flows.2/Equal_12_output_0, %/duration_predictor/flows.2/ConstantOfShape_21_output_0, %/duration_predictor/flows.2/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Expand_17_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_17"](%onnx::Add_6745, %/duration_predictor/flows.2/Where_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Constant_108_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_108"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Unsqueeze_15_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_15"](%/duration_predictor/flows.2/Expand_17_output_0, %/duration_predictor/flows.2/Constant_108_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Shape_37_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_37"](%/duration_predictor/flows.2/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/ConstantOfShape_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_22"](%/duration_predictor/flows.2/Shape_37_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Constant_109_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_109"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Mul_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_19"](%/duration_predictor/flows.2/ConstantOfShape_22_output_0, %/duration_predictor/flows.2/Constant_109_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Equal_13_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_13"](%/duration_predictor/flows.2/Shape_35_output_0, %/duration_predictor/flows.2/Mul_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Where_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_13"](%/duration_predictor/flows.2/Equal_13_output_0, %/duration_predictor/flows.2/ConstantOfShape_22_output_0, %/duration_predictor/flows.2/Shape_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Expand_18_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_18"](%onnx::Expand_6743, %/duration_predictor/flows.2/Where_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Constant_110_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_110"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Unsqueeze_16_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_16"](%/duration_predictor/flows.2/Expand_18_output_0, %/duration_predictor/flows.2/Constant_110_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Concat_12_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.2/Concat_12"](%/duration_predictor/flows.2/Unsqueeze_15_output_0, %/duration_predictor/flows.2/Unsqueeze_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Shape_38_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_38"](%/duration_predictor/flows.2/Add_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Constant_111_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_111"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Constant_112_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_112"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Constant_113_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_113"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Slice_12_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_12"](%/duration_predictor/flows.2/Shape_38_output_0, %/duration_predictor/flows.2/Constant_112_output_0, %/duration_predictor/flows.2/Constant_113_output_0, %/duration_predictor/flows.2/Constant_111_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Concat_13_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_13"](%/duration_predictor/flows.2/Shape_35_output_0, %/duration_predictor/flows.2/Slice_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Reshape_11_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_11"](%/duration_predictor/flows.2/Expand_16_output_0, %/duration_predictor/flows.2/Concat_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/ScatterND_4_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND_4"](%/duration_predictor/flows.2/Add_12_output_0, %/duration_predictor/flows.2/Concat_12_output_0, %/duration_predictor/flows.2/Reshape_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:137:0
  %/duration_predictor/flows.2/Gather_9_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_9"](%/duration_predictor/flows.2/ScatterND_4_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Shape_39_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_39"](%/duration_predictor/flows.2/Gather_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/ConstantOfShape_23_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={5}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_23"](%/duration_predictor/flows.2/Shape_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Shape_40_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_40"](%/duration_predictor/flows.2/Gather_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Expand_19_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_19"](%/duration_predictor/flows.2/ConstantOfShape_23_output_0, %/duration_predictor/flows.2/Shape_40_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %onnx::Gather_6781 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/ScatterND_4_output_0)
  %onnx::Gather_6782 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_6783 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6781, %onnx::Gather_6782)
  %onnx::Range_6784 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6783)
  %onnx::Range_6785 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6786 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6787 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6785, %onnx::Range_6784, %onnx::Range_6786)
  %onnx::Expand_6788 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_6789 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_6790 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6787, %onnx::Reshape_6789)
  %/duration_predictor/flows.2/Constant_114_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_114"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Add_14_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_14"](%onnx::Add_6790, %/duration_predictor/flows.2/Constant_114_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Shape_41_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_41"](%/duration_predictor/flows.2/Add_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Shape_42_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_42"](%/duration_predictor/flows.2/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/ConstantOfShape_24_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_24"](%/duration_predictor/flows.2/Shape_42_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Constant_115_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_115"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Mul_20_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_20"](%/duration_predictor/flows.2/ConstantOfShape_24_output_0, %/duration_predictor/flows.2/Constant_115_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Equal_14_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_14"](%/duration_predictor/flows.2/Shape_41_output_0, %/duration_predictor/flows.2/Mul_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Where_14_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_14"](%/duration_predictor/flows.2/Equal_14_output_0, %/duration_predictor/flows.2/ConstantOfShape_24_output_0, %/duration_predictor/flows.2/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Expand_20_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_20"](%onnx::Add_6790, %/duration_predictor/flows.2/Where_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Constant_116_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_116"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Unsqueeze_17_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_17"](%/duration_predictor/flows.2/Expand_20_output_0, %/duration_predictor/flows.2/Constant_116_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Shape_43_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_43"](%/duration_predictor/flows.2/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/ConstantOfShape_25_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_25"](%/duration_predictor/flows.2/Shape_43_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Constant_117_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_117"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Mul_21_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_21"](%/duration_predictor/flows.2/ConstantOfShape_25_output_0, %/duration_predictor/flows.2/Constant_117_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Equal_15_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_15"](%/duration_predictor/flows.2/Shape_41_output_0, %/duration_predictor/flows.2/Mul_21_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Where_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_15"](%/duration_predictor/flows.2/Equal_15_output_0, %/duration_predictor/flows.2/ConstantOfShape_25_output_0, %/duration_predictor/flows.2/Shape_41_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Expand_21_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_21"](%onnx::Expand_6788, %/duration_predictor/flows.2/Where_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Constant_118_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_118"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Unsqueeze_18_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_18"](%/duration_predictor/flows.2/Expand_21_output_0, %/duration_predictor/flows.2/Constant_118_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Concat_14_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.2/Concat_14"](%/duration_predictor/flows.2/Unsqueeze_17_output_0, %/duration_predictor/flows.2/Unsqueeze_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Shape_44_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_44"](%/duration_predictor/flows.2/ScatterND_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Constant_119_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_119"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Constant_120_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_120"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Constant_121_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_121"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Slice_13_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_13"](%/duration_predictor/flows.2/Shape_44_output_0, %/duration_predictor/flows.2/Constant_120_output_0, %/duration_predictor/flows.2/Constant_121_output_0, %/duration_predictor/flows.2/Constant_119_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Concat_15_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_15"](%/duration_predictor/flows.2/Shape_41_output_0, %/duration_predictor/flows.2/Slice_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Reshape_12_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_12"](%/duration_predictor/flows.2/Expand_19_output_0, %/duration_predictor/flows.2/Concat_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/ScatterND_5_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND_5"](%/duration_predictor/flows.2/ScatterND_4_output_0, %/duration_predictor/flows.2/Concat_14_output_0, %/duration_predictor/flows.2/Reshape_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:138:0
  %/duration_predictor/flows.2/Constant_122_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_122"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Constant_123_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_123"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Constant_124_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_124"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Constant_125_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_125"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Slice_14_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_14"](%/duration_predictor/flows.2/ScatterND_5_output_0, %/duration_predictor/flows.2/Constant_123_output_0, %/duration_predictor/flows.2/Constant_124_output_0, %/duration_predictor/flows.2/Constant_122_output_0, %/duration_predictor/flows.2/Constant_125_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Constant_126_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_126"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Constant_127_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_127"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Constant_128_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_128"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Constant_129_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_129"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Slice_15_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_15"](%/duration_predictor/flows.2/ScatterND_5_output_0, %/duration_predictor/flows.2/Constant_127_output_0, %/duration_predictor/flows.2/Constant_128_output_0, %/duration_predictor/flows.2/Constant_126_output_0, %/duration_predictor/flows.2/Constant_129_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Sub_2_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub_2"](%/duration_predictor/flows.2/Slice_14_output_0, %/duration_predictor/flows.2/Slice_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:139:0
  %/duration_predictor/flows.2/Gather_10_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_10"](%/duration_predictor/flows.2/ScatterND_5_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_130_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-06}, onnx_name="/duration_predictor/flows.2/Constant_130"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Add_15_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_15"](%/duration_predictor/flows.2/Gather_10_output_0, %/duration_predictor/flows.2/Constant_130_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_45_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_45"](%/duration_predictor/flows.2/Gather_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Expand_22_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_22"](%/duration_predictor/flows.2/Add_15_output_0, %/duration_predictor/flows.2/Shape_45_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %onnx::Gather_6845 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/ScatterND_5_output_0)
  %onnx::Gather_6846 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_6847 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6845, %onnx::Gather_6846)
  %onnx::Range_6848 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6847)
  %onnx::Range_6849 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6850 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6851 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6849, %onnx::Range_6848, %onnx::Range_6850)
  %onnx::Expand_6852 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_6853 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_6854 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6851, %onnx::Reshape_6853)
  %/duration_predictor/flows.2/Constant_131_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_131"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Add_16_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_16"](%onnx::Add_6854, %/duration_predictor/flows.2/Constant_131_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_46_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_46"](%/duration_predictor/flows.2/Add_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_47_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_47"](%/duration_predictor/flows.2/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/ConstantOfShape_26_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_26"](%/duration_predictor/flows.2/Shape_47_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_132_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_132"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Mul_22_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_22"](%/duration_predictor/flows.2/ConstantOfShape_26_output_0, %/duration_predictor/flows.2/Constant_132_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Equal_16_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_16"](%/duration_predictor/flows.2/Shape_46_output_0, %/duration_predictor/flows.2/Mul_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Where_16_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_16"](%/duration_predictor/flows.2/Equal_16_output_0, %/duration_predictor/flows.2/ConstantOfShape_26_output_0, %/duration_predictor/flows.2/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Expand_23_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_23"](%onnx::Add_6854, %/duration_predictor/flows.2/Where_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_133_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_133"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Unsqueeze_19_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_19"](%/duration_predictor/flows.2/Expand_23_output_0, %/duration_predictor/flows.2/Constant_133_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_48_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_48"](%/duration_predictor/flows.2/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/ConstantOfShape_27_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_27"](%/duration_predictor/flows.2/Shape_48_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_134_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_134"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Mul_23_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_23"](%/duration_predictor/flows.2/ConstantOfShape_27_output_0, %/duration_predictor/flows.2/Constant_134_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Equal_17_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_17"](%/duration_predictor/flows.2/Shape_46_output_0, %/duration_predictor/flows.2/Mul_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Where_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_17"](%/duration_predictor/flows.2/Equal_17_output_0, %/duration_predictor/flows.2/ConstantOfShape_27_output_0, %/duration_predictor/flows.2/Shape_46_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Expand_24_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_24"](%onnx::Expand_6852, %/duration_predictor/flows.2/Where_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_135_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_135"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Unsqueeze_20_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_20"](%/duration_predictor/flows.2/Expand_24_output_0, %/duration_predictor/flows.2/Constant_135_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Concat_16_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.2/Concat_16"](%/duration_predictor/flows.2/Unsqueeze_19_output_0, %/duration_predictor/flows.2/Unsqueeze_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_49_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_49"](%/duration_predictor/flows.2/ScatterND_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_136_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_136"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_137_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_137"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_138_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_138"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Slice_16_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_16"](%/duration_predictor/flows.2/Shape_49_output_0, %/duration_predictor/flows.2/Constant_137_output_0, %/duration_predictor/flows.2/Constant_138_output_0, %/duration_predictor/flows.2/Constant_136_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Concat_17_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_17"](%/duration_predictor/flows.2/Shape_46_output_0, %/duration_predictor/flows.2/Slice_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Reshape_13_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_13"](%/duration_predictor/flows.2/Expand_22_output_0, %/duration_predictor/flows.2/Concat_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/ScatterND_6_output_0 : Float(*, *, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND_6"](%/duration_predictor/flows.2/ScatterND_5_output_0, %/duration_predictor/flows.2/Concat_16_output_0, %/duration_predictor/flows.2/Reshape_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Gather_11_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_11"](%/duration_predictor/flows.2/ScatterND_6_output_0, %/emb_g/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_50_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_50"](%/duration_predictor/flows.2/Gather_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Expand_25_output_0 : Float(*, strides=[11], requires_grad=0, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_25"](%/duration_predictor/flows.2/Add_15_output_0, %/duration_predictor/flows.2/Shape_50_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %onnx::Gather_6888 : Long(2, strides=[1], device=cpu) = onnx::Shape(%/duration_predictor/flows.2/ScatterND_6_output_0)
  %onnx::Gather_6889 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Cast_6890 : Long(device=cpu) = onnx::Gather[axis=0](%onnx::Gather_6888, %onnx::Gather_6889)
  %onnx::Range_6891 : Long(device=cpu) = onnx::Cast[to=7](%onnx::Cast_6890)
  %onnx::Range_6892 : Long(device=cpu) = onnx::Constant[value={0}]()
  %onnx::Range_6893 : Long(device=cpu) = onnx::Constant[value={1}]()
  %onnx::Reshape_6894 : Long(*, device=cpu) = onnx::Range(%onnx::Range_6892, %onnx::Range_6891, %onnx::Range_6893)
  %onnx::Expand_6895 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()
  %onnx::Reshape_6896 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()
  %onnx::Add_6897 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%onnx::Reshape_6894, %onnx::Reshape_6896)
  %/duration_predictor/flows.2/Constant_139_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_139"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Add_17_output_0 : Long(*, *, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_17"](%onnx::Add_6897, %/duration_predictor/flows.2/Constant_139_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_51_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_51"](%/duration_predictor/flows.2/Add_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_52_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_52"](%/duration_predictor/flows.2/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/ConstantOfShape_28_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_28"](%/duration_predictor/flows.2/Shape_52_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_140_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_140"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Mul_24_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_24"](%/duration_predictor/flows.2/ConstantOfShape_28_output_0, %/duration_predictor/flows.2/Constant_140_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Equal_18_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_18"](%/duration_predictor/flows.2/Shape_51_output_0, %/duration_predictor/flows.2/Mul_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Where_18_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_18"](%/duration_predictor/flows.2/Equal_18_output_0, %/duration_predictor/flows.2/ConstantOfShape_28_output_0, %/duration_predictor/flows.2/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Expand_26_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_26"](%onnx::Add_6897, %/duration_predictor/flows.2/Where_18_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_141_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_141"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Unsqueeze_21_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_21"](%/duration_predictor/flows.2/Expand_26_output_0, %/duration_predictor/flows.2/Constant_141_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_53_output_0 : Long(1, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_53"](%/duration_predictor/flows.2/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/ConstantOfShape_29_output_0 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}, onnx_name="/duration_predictor/flows.2/ConstantOfShape_29"](%/duration_predictor/flows.2/Shape_53_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_142_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_142"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Mul_25_output_0 : Long(2, strides=[1], device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_25"](%/duration_predictor/flows.2/ConstantOfShape_29_output_0, %/duration_predictor/flows.2/Constant_142_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Equal_19_output_0 : Bool(2, strides=[1], device=cpu) = onnx::Equal[onnx_name="/duration_predictor/flows.2/Equal_19"](%/duration_predictor/flows.2/Shape_51_output_0, %/duration_predictor/flows.2/Mul_25_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Where_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Where[onnx_name="/duration_predictor/flows.2/Where_19"](%/duration_predictor/flows.2/Equal_19_output_0, %/duration_predictor/flows.2/ConstantOfShape_29_output_0, %/duration_predictor/flows.2/Shape_51_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Expand_27_output_0 : Long(*, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_27"](%onnx::Expand_6895, %/duration_predictor/flows.2/Where_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_143_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_143"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Unsqueeze_22_output_0 : Long(*, *, 1, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_22"](%/duration_predictor/flows.2/Expand_27_output_0, %/duration_predictor/flows.2/Constant_143_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Concat_18_output_0 : Long(*, *, 2, device=cpu) = onnx::Concat[axis=-1, onnx_name="/duration_predictor/flows.2/Concat_18"](%/duration_predictor/flows.2/Unsqueeze_21_output_0, %/duration_predictor/flows.2/Unsqueeze_22_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Shape_54_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_54"](%/duration_predictor/flows.2/ScatterND_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_144_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_144"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_145_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_145"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_146_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_146"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Slice_17_output_0 : Long(0, strides=[1], device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_17"](%/duration_predictor/flows.2/Shape_54_output_0, %/duration_predictor/flows.2/Constant_145_output_0, %/duration_predictor/flows.2/Constant_146_output_0, %/duration_predictor/flows.2/Constant_144_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Concat_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/duration_predictor/flows.2/Concat_19"](%/duration_predictor/flows.2/Shape_51_output_0, %/duration_predictor/flows.2/Slice_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Reshape_14_output_0 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_14"](%/duration_predictor/flows.2/Expand_25_output_0, %/duration_predictor/flows.2/Concat_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/ScatterND_7_output_0 : Float(*, *, requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND_7"](%/duration_predictor/flows.2/ScatterND_6_output_0, %/duration_predictor/flows.2/Concat_18_output_0, %/duration_predictor/flows.2/Reshape_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:46:0
  %/duration_predictor/flows.2/Constant_147_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_147"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.2/Unsqueeze_23_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_23"](%/duration_predictor/flows.2/GatherND_1_output_0, %/duration_predictor/flows.2/Constant_147_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.2/GreaterOrEqual_1_output_0 : Bool(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::GreaterOrEqual[onnx_name="/duration_predictor/flows.2/GreaterOrEqual_1"](%/duration_predictor/flows.2/Unsqueeze_23_output_0, %/duration_predictor/flows.2/ScatterND_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.2/Cast_4_output_0 : Long(*, *, device=cpu) = onnx::Cast[to=7, onnx_name="/duration_predictor/flows.2/Cast_4"](%/duration_predictor/flows.2/GreaterOrEqual_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.2/ReduceSum_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::ReduceSum[keepdims=0, onnx_name="/duration_predictor/flows.2/ReduceSum"](%/duration_predictor/flows.2/Cast_4_output_0, %onnx::ReduceSum_5156), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.2/Constant_148_output_0 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_148"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.2/Sub_3_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub_3"](%/duration_predictor/flows.2/ReduceSum_output_0, %/duration_predictor/flows.2/Constant_148_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:47:0
  %/duration_predictor/flows.2/Constant_149_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_149"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:142:0
  %/duration_predictor/flows.2/Unsqueeze_24_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_24"](%/duration_predictor/flows.2/Sub_3_output_0, %/duration_predictor/flows.2/Constant_149_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:142:0
  %/duration_predictor/flows.2/GatherElements_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.2/GatherElements"](%/duration_predictor/flows.2/ScatterND_3_output_0, %/duration_predictor/flows.2/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:146:0
  %/duration_predictor/flows.2/Gather_12_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_12"](%/duration_predictor/flows.2/GatherElements_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:146:0
  %/duration_predictor/flows.2/GatherElements_1_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.2/GatherElements_1"](%/duration_predictor/flows.2/Sub_1_output_0, %/duration_predictor/flows.2/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:147:0
  %/duration_predictor/flows.2/Gather_13_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_13"](%/duration_predictor/flows.2/GatherElements_1_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:147:0
  %/duration_predictor/flows.2/GatherElements_2_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.2/GatherElements_2"](%/duration_predictor/flows.2/ScatterND_7_output_0, %/duration_predictor/flows.2/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:149:0
  %/duration_predictor/flows.2/Gather_14_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_14"](%/duration_predictor/flows.2/GatherElements_2_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:149:0
  %/duration_predictor/flows.2/Div_2_output_0 : Float(*, *, strides=[10, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/Div_2"](%/duration_predictor/flows.2/Sub_2_output_0, %/duration_predictor/flows.2/Sub_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:150:0
  %/duration_predictor/flows.2/GatherElements_3_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.2/GatherElements_3"](%/duration_predictor/flows.2/Div_2_output_0, %/duration_predictor/flows.2/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:151:0
  %/duration_predictor/flows.2/Gather_15_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_15"](%/duration_predictor/flows.2/GatherElements_3_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:151:0
  %/duration_predictor/flows.2/GatherElements_4_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.2/GatherElements_4"](%/duration_predictor/flows.2/Add_10_output_0, %/duration_predictor/flows.2/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:153:0
  %/duration_predictor/flows.2/Gather_16_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_16"](%/duration_predictor/flows.2/GatherElements_4_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:153:0
  %/duration_predictor/flows.2/Constant_150_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_150"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.2/Constant_151_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_151"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.2/Constant_152_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/duration_predictor/flows.2/Constant_152"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.2/Constant_153_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/flows.2/Constant_153"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.2/Slice_18_output_0 : Float(*, *, strides=[11, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_18"](%/duration_predictor/flows.2/Add_10_output_0, %/duration_predictor/flows.2/Constant_151_output_0, %/duration_predictor/flows.2/Constant_152_output_0, %/duration_predictor/flows.2/Constant_150_output_0, %/duration_predictor/flows.2/Constant_153_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.2/GatherElements_5_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.2/GatherElements_5"](%/duration_predictor/flows.2/Slice_18_output_0, %/duration_predictor/flows.2/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.2/Gather_17_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_17"](%/duration_predictor/flows.2/GatherElements_5_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:154:0
  %/duration_predictor/flows.2/GatherElements_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::GatherElements[axis=-1, onnx_name="/duration_predictor/flows.2/GatherElements_6"](%/duration_predictor/flows.2/Sub_2_output_0, %/duration_predictor/flows.2/Unsqueeze_24_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:156:0
  %/duration_predictor/flows.2/Gather_18_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Gather[axis=1, onnx_name="/duration_predictor/flows.2/Gather_18"](%/duration_predictor/flows.2/GatherElements_6_output_0, %/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:156:0
  %/duration_predictor/flows.2/Sub_4_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub_4"](%/duration_predictor/flows.2/GatherND_1_output_0, %/duration_predictor/flows.2/Gather_14_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:159:0
  %/duration_predictor/flows.2/Add_18_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_18"](%/duration_predictor/flows.2/Gather_16_output_0, %/duration_predictor/flows.2/Gather_17_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.2/Constant_154_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_154"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.2/Mul_26_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_26"](%/duration_predictor/flows.2/Gather_15_output_0, %/duration_predictor/flows.2/Constant_154_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.2/Sub_5_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub_5"](%/duration_predictor/flows.2/Add_18_output_0, %/duration_predictor/flows.2/Mul_26_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:160:0
  %/duration_predictor/flows.2/Mul_27_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_27"](%/duration_predictor/flows.2/Sub_4_output_0, %/duration_predictor/flows.2/Sub_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:159:0
  %/duration_predictor/flows.2/Sub_6_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub_6"](%/duration_predictor/flows.2/Gather_15_output_0, %/duration_predictor/flows.2/Gather_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:161:0
  %/duration_predictor/flows.2/Mul_28_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_28"](%/duration_predictor/flows.2/Gather_18_output_0, %/duration_predictor/flows.2/Sub_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:161:0
  %/duration_predictor/flows.2/Add_19_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_19"](%/duration_predictor/flows.2/Mul_27_output_0, %/duration_predictor/flows.2/Mul_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:159:0
  %/duration_predictor/flows.2/Mul_29_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_29"](%/duration_predictor/flows.2/Gather_18_output_0, %/duration_predictor/flows.2/Gather_16_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:162:0
  %/duration_predictor/flows.2/Sub_7_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub_7"](%/duration_predictor/flows.2/Mul_29_output_0, %/duration_predictor/flows.2/Mul_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:162:0
  %/duration_predictor/flows.2/Neg_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/duration_predictor/flows.2/Neg"](%/duration_predictor/flows.2/Gather_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:165:0
  %/duration_predictor/flows.2/Mul_30_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_30"](%/duration_predictor/flows.2/Neg_output_0, %/duration_predictor/flows.2/Sub_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:165:0
  %/duration_predictor/flows.2/Constant_155_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_155"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.2/Pow_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Pow[onnx_name="/duration_predictor/flows.2/Pow"](%/duration_predictor/flows.2/Sub_7_output_0, %/duration_predictor/flows.2/Constant_155_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.2/Constant_156_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={4}, onnx_name="/duration_predictor/flows.2/Constant_156"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.2/Mul_31_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_31"](%/duration_predictor/flows.2/Add_19_output_0, %/duration_predictor/flows.2/Constant_156_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.2/Mul_32_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_32"](%/duration_predictor/flows.2/Mul_31_output_0, %/duration_predictor/flows.2/Mul_30_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.2/Sub_8_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub_8"](%/duration_predictor/flows.2/Pow_output_0, %/duration_predictor/flows.2/Mul_32_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:167:0
  %/duration_predictor/flows.2/Constant_157_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name="/duration_predictor/flows.2/Constant_157"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.2/Mul_33_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_33"](%/duration_predictor/flows.2/Mul_30_output_0, %/duration_predictor/flows.2/Constant_157_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.2/Neg_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/duration_predictor/flows.2/Neg_1"](%/duration_predictor/flows.2/Sub_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.2/Sqrt_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sqrt[onnx_name="/duration_predictor/flows.2/Sqrt"](%/duration_predictor/flows.2/Sub_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.2/Sub_9_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.2/Sub_9"](%/duration_predictor/flows.2/Neg_1_output_0, %/duration_predictor/flows.2/Sqrt_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.2/Div_3_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/duration_predictor/flows.2/Div_3"](%/duration_predictor/flows.2/Mul_33_output_0, %/duration_predictor/flows.2/Sub_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:170:0
  %/duration_predictor/flows.2/Mul_34_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_34"](%/duration_predictor/flows.2/Div_3_output_0, %/duration_predictor/flows.2/Gather_13_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:171:0
  %/duration_predictor/flows.2/Add_20_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/duration_predictor/flows.2/Add_20"](%/duration_predictor/flows.2/Mul_34_output_0, %/duration_predictor/flows.2/Gather_12_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:171:0
  %/duration_predictor/flows.2/Shape_55_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_55"](%/duration_predictor/flows.2/ConstantOfShape_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Expand_28_output_0 : Bool(*, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_28"](%/duration_predictor/flows.2/Not_output_0, %/duration_predictor/flows.2/Shape_55_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/NonZero_5_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.2/NonZero_5"](%/duration_predictor/flows.2/Expand_28_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Transpose_9_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_9"](%/duration_predictor/flows.2/NonZero_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Constant_158_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_158"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Reshape_15_output_0 : Float(*, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_15"](%/duration_predictor/flows.2/GatherND_output_0, %/duration_predictor/flows.2/Constant_158_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Shape_56_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_56"](%/duration_predictor/flows.2/Transpose_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Constant_159_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_159"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Gather_19_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.2/Gather_19"](%/duration_predictor/flows.2/Shape_56_output_0, %/duration_predictor/flows.2/Constant_159_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Constant_160_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_160"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Constant_161_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_161"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Constant_162_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_162"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Unsqueeze_25_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_25"](%/duration_predictor/flows.2/Gather_19_output_0, %/duration_predictor/flows.2/Constant_162_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Slice_19_output_0 : Float(*, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_19"](%/duration_predictor/flows.2/Reshape_15_output_0, %/duration_predictor/flows.2/Constant_161_output_0, %/duration_predictor/flows.2/Unsqueeze_25_output_0, %/duration_predictor/flows.2/Constant_160_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/ScatterND_8_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND_8"](%/duration_predictor/flows.2/ConstantOfShape_11_output_0, %/duration_predictor/flows.2/Transpose_9_output_0, %/duration_predictor/flows.2/Slice_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:74:0
  %/duration_predictor/flows.2/Shape_57_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_57"](%/duration_predictor/flows.2/ScatterND_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Expand_29_output_0 : Bool(*, *, *, device=cpu) = onnx::Expand[onnx_name="/duration_predictor/flows.2/Expand_29"](%/duration_predictor/flows.2/And_output_0, %/duration_predictor/flows.2/Shape_57_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/NonZero_6_output_0 : Long(3, *, device=cpu) = onnx::NonZero[onnx_name="/duration_predictor/flows.2/NonZero_6"](%/duration_predictor/flows.2/Expand_29_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Transpose_10_output_0 : Long(*, 3, device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/duration_predictor/flows.2/Transpose_10"](%/duration_predictor/flows.2/NonZero_6_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Constant_163_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/flows.2/Constant_163"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Reshape_16_output_0 : Float(*, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/duration_predictor/flows.2/Reshape_16"](%/duration_predictor/flows.2/Add_20_output_0, %/duration_predictor/flows.2/Constant_163_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Shape_58_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name="/duration_predictor/flows.2/Shape_58"](%/duration_predictor/flows.2/Transpose_10_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Constant_164_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_164"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Gather_20_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/duration_predictor/flows.2/Gather_20"](%/duration_predictor/flows.2/Shape_58_output_0, %/duration_predictor/flows.2/Constant_164_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Constant_165_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_165"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Constant_166_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_166"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Constant_167_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/duration_predictor/flows.2/Constant_167"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Unsqueeze_26_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/duration_predictor/flows.2/Unsqueeze_26"](%/duration_predictor/flows.2/Gather_20_output_0, %/duration_predictor/flows.2/Constant_167_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Slice_20_output_0 : Float(*, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/flows.2/Slice_20"](%/duration_predictor/flows.2/Reshape_16_output_0, %/duration_predictor/flows.2/Constant_166_output_0, %/duration_predictor/flows.2/Unsqueeze_26_output_0, %/duration_predictor/flows.2/Constant_165_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/ScatterND_9_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::ScatterND[onnx_name="/duration_predictor/flows.2/ScatterND_9"](%/duration_predictor/flows.2/ScatterND_8_output_0, %/duration_predictor/flows.2/Transpose_10_output_0, %/duration_predictor/flows.2/Slice_20_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/transforms.py:79:0
  %/duration_predictor/flows.2/Concat_20_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name="/duration_predictor/flows.2/Concat_20"](%/duration_predictor/flows.2/Split_output_0, %/duration_predictor/flows.2/ScatterND_9_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:143:0
  %/duration_predictor/flows.2/Mul_35_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.2/Mul_35"](%/duration_predictor/flows.2/Concat_20_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ConvFlow::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:143:0
  %/duration_predictor/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/duration_predictor/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_17_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_18_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/duration_predictor/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Constant_19_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/duration_predictor/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/Slice_3_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/duration_predictor/Slice_3"](%/duration_predictor/flows.2/Mul_35_output_0, %/duration_predictor/Constant_17_output_0, %/duration_predictor/Constant_18_output_0, %/duration_predictor/Constant_16_output_0, %/duration_predictor/Constant_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:289:0
  %/duration_predictor/flows.0/Sub_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/duration_predictor/flows.0/Sub"](%/duration_predictor/Slice_3_output_0, %duration_predictor.flows.0.translation), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ElementwiseAffine::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:83:0
  %/duration_predictor/flows.0/Exp_output_0 : Float(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Exp[onnx_name="/duration_predictor/flows.0/Exp"](%onnx::Exp_9560), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ElementwiseAffine::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:83:0
  %/duration_predictor/flows.0/Mul_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.0/Mul"](%/duration_predictor/flows.0/Sub_output_0, %/duration_predictor/flows.0/Exp_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ElementwiseAffine::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:83:0
  %/duration_predictor/flows.0/Mul_1_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/duration_predictor/flows.0/Mul_1"](%/duration_predictor/flows.0/Mul_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor/TTS.tts.layers.vits.stochastic_duration_predictor.ElementwiseAffine::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/stochastic_duration_predictor.py:83:0
  %/duration_predictor/Split_output_0 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu), %/duration_predictor/Split_output_1 : Float(*, *, *, strides=[200, 100, 1], requires_grad=0, device=cpu) = onnx::Split[axis=1, onnx_name="/duration_predictor/Split"](%/duration_predictor/flows.0/Mul_1_output_0, %onnx::Split_4359), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.stochastic_duration_predictor.StochasticDurationPredictor::duration_predictor # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:917:0
  %/Exp_output_0 : Float(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::Exp[onnx_name="/Exp"](%/duration_predictor/Split_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1140:0
  %/Mul_output_0 : Float(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/Mul"](%/Exp_output_0, %/text_encoder/Cast_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1140:0
  %/Mul_1_output_0 : Float(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/Mul_1"](%/Mul_output_0, %/Gather_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1140:0
  %/Ceil_output_0 : Float(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::Ceil[onnx_name="/Ceil"](%/Mul_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1145:0
  %onnx::ReduceSum_7036 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 1  2 [ CPULongType{2} ]]()
  %/ReduceSum_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::ReduceSum[keepdims=0, onnx_name="/ReduceSum"](%/Ceil_output_0, %onnx::ReduceSum_7036), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1146:0
  %/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_3"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1146:0
  %onnx::Clip_7039 : Tensor? = prim::Constant(), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1146:0
  %/Clip_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Clip[onnx_name="/Clip"](%/ReduceSum_output_0, %/Constant_3_output_0, %onnx::Clip_7039), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1146:0
  %/Cast_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Cast[to=7, onnx_name="/Cast"](%/Clip_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1146:0
  %/ReduceMax_output_0 : Long(requires_grad=0, device=cpu) = onnx::ReduceMax[keepdims=0, onnx_name="/ReduceMax"](%/Cast_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:54:0
  %/Cast_1_output_0 : Long(device=cpu) = onnx::Cast[to=7, onnx_name="/Cast_1"](%/ReduceMax_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/Constant_4_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_4"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/Constant_5_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_5"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/Range_output_0 : Long(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name="/Range"](%/Constant_4_output_0, %/Cast_1_output_0, %/Constant_5_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_6"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Unsqueeze_1_output_0 : Long(1, *, strides=[180, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze_1"](%/Range_output_0, %/Constant_6_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_7"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Unsqueeze_2_output_0 : Long(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze_2"](%/Cast_output_0, %/Constant_7_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Less_output_0 : Bool(*, *, strides=[180, 1], requires_grad=0, device=cpu) = onnx::Less[onnx_name="/Less"](%/Unsqueeze_1_output_0, %/Unsqueeze_2_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Cast_2_output_0 : Float(*, *, strides=[180, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name="/Cast_2"](%/Less_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1147:0
  %/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_8"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1147:0
  %/Unsqueeze_3_output_0 : Float(*, 1, *, strides=[180, 180, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze_3"](%/Cast_2_output_0, %/Constant_8_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1147:0
  %/Transpose_output_0 : Float(*, *, 1, strides=[180, 1, 180], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/Transpose"](%/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1149:0
  %/Mul_2_output_0 : Float(*, *, *, strides=[18000, 100, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/Mul_2"](%/text_encoder/Cast_1_output_0, %/Transpose_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1149:0
  %/Transpose_1_output_0 : Float(*, *, *, strides=[18000, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/Transpose_1"](%/Mul_2_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1150:0
  %/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/Shape"](%/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:161:0
  %/Constant_9_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_9"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:161:0
  %/Gather_1_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/Gather_1"](%/Shape_output_0, %/Constant_9_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:161:0
  %/Shape_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/Shape_1"](%/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:161:0
  %/Constant_10_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_10"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:161:0
  %/Gather_2_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/Gather_2"](%/Shape_1_output_0, %/Constant_10_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:161:0
  %/Shape_2_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/Shape_2"](%/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:161:0
  %/Constant_11_output_0 : Long(device=cpu) = onnx::Constant[value={2}, onnx_name="/Constant_11"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:161:0
  %/Gather_3_output_0 : Long(device=cpu) = onnx::Gather[axis=0, onnx_name="/Gather_3"](%/Shape_2_output_0, %/Constant_11_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:161:0
  %/Constant_12_output_0 : Int(device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_12"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:162:0
  %/CumSum_output_0 : Float(*, *, *, strides=[100, 100, 1], requires_grad=0, device=cpu) = onnx::CumSum[onnx_name="/CumSum"](%/Ceil_output_0, %/Constant_12_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:162:0
  %/Mul_3_output_0 : Long(requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/Mul_3"](%/Gather_1_output_0, %/Gather_2_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:164:0
  %onnx::Unsqueeze_7070 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/Unsqueeze_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze_4"](%/Mul_3_output_0, %onnx::Unsqueeze_7070), scope: TTS.tts.models.vits.Vits::
  %/Concat_output_0 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/Concat"](%/Unsqueeze_4_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:164:0
  %/Reshape_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/Reshape"](%/CumSum_output_0, %/Concat_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:164:0
  %/Cast_3_output_0 : Float(device=cpu) = onnx::Cast[to=1, onnx_name="/Cast_3"](%/Gather_3_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/Constant_13_output_0 : Float(device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_13"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/Constant_14_output_0 : Float(device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_14"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/Range_1_output_0 : Float(*, strides=[1], requires_grad=0, device=cpu) = onnx::Range[onnx_name="/Range_1"](%/Constant_13_output_0, %/Cast_3_output_0, %/Constant_14_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:55:0
  %/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_15"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Unsqueeze_5_output_0 : Float(1, *, strides=[180, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze_5"](%/Range_1_output_0, %/Constant_15_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Constant_16_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_16"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Unsqueeze_6_output_0 : Float(*, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze_6"](%/Reshape_output_0, %/Constant_16_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Less_1_output_0 : Bool(*, *, strides=[180, 1], requires_grad=0, device=cpu) = onnx::Less[onnx_name="/Less_1"](%/Unsqueeze_5_output_0, %/Unsqueeze_6_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:57:0
  %/Cast_4_output_0 : Float(*, *, strides=[180, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1, onnx_name="/Cast_4"](%/Less_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:165:0
  %onnx::Unsqueeze_7084 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/Unsqueeze_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze_7"](%/Gather_1_output_0, %onnx::Unsqueeze_7084), scope: TTS.tts.models.vits.Vits::
  %onnx::Unsqueeze_7086 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/Unsqueeze_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze_8"](%/Gather_2_output_0, %onnx::Unsqueeze_7086), scope: TTS.tts.models.vits.Vits::
  %onnx::Unsqueeze_7088 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()
  %/Unsqueeze_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[onnx_name="/Unsqueeze_9"](%/Gather_3_output_0, %onnx::Unsqueeze_7088), scope: TTS.tts.models.vits.Vits::
  %/Concat_1_output_0 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/Concat_1"](%/Unsqueeze_7_output_0, %/Unsqueeze_8_output_0, %/Unsqueeze_9_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:166:0
  %/Reshape_1_output_0 : Float(*, *, *, strides=[18000, 180, 1], requires_grad=0, device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/Reshape_1"](%/Cast_4_output_0, %/Concat_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:166:0
  %/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_17"](), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Constant_18_output_0 : Long(6, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  0  1  0  0  0 [ CPULongType{6} ], onnx_name="/Constant_18"](), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/ConstantOfShape_output_0 : Long(0, strides=[1], device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/ConstantOfShape"](%/Constant_17_output_0), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Concat_2_output_0 : Long(6, strides=[1], device=cpu) = onnx::Concat[axis=0, onnx_name="/Concat_2"](%/Constant_18_output_0, %/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Constant_19_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  2 [ CPULongType{2} ], onnx_name="/Constant_19"](), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Reshape_2_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/Reshape_2"](%/Concat_2_output_0, %/Constant_19_output_0), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Constant_20_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_20"](), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Constant_21_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/Constant_21"](), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Constant_22_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/Constant_22"](), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Constant_23_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/Constant_23"](), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Slice_output_0 : Long(3, 2, strides=[2, 1], device=cpu) = onnx::Slice[onnx_name="/Slice"](%/Reshape_2_output_0, %/Constant_21_output_0, %/Constant_22_output_0, %/Constant_20_output_0, %/Constant_23_output_0), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Transpose_2_output_0 : Long(2, 3, strides=[3, 1], device=cpu) = onnx::Transpose[perm=[1, 0], onnx_name="/Transpose_2"](%/Slice_output_0), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Constant_24_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/Constant_24"](), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Reshape_3_output_0 : Long(6, strides=[1], device=cpu) = onnx::Reshape[allowzero=0, onnx_name="/Reshape_3"](%/Transpose_2_output_0, %/Constant_24_output_0), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Cast_5_output_0 : Long(6, strides=[1], device=cpu) = onnx::Cast[to=7, onnx_name="/Cast_5"](%/Reshape_3_output_0), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Pad_output_0 : Float(*, *, *, strides=[18180, 180, 1], requires_grad=0, device=cpu) = onnx::Pad[mode="constant", onnx_name="/Pad"](%/Reshape_1_output_0, %/Cast_5_output_0, %onnx::Pad_877), scope: TTS.tts.models.vits.Vits:: # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:4552:0
  %/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_25"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:167:0
  %/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/Constant_26"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:167:0
  %/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={-1}, onnx_name="/Constant_27"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:167:0
  %/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/Constant_28"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:167:0
  %/Slice_1_output_0 : Float(*, *, *, strides=[18180, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/Slice_1"](%/Pad_output_0, %/Constant_26_output_0, %/Constant_27_output_0, %/Constant_25_output_0, %/Constant_28_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:167:0
  %/Sub_output_0 : Float(*, *, *, strides=[18000, 180, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/Sub"](%/Reshape_1_output_0, %/Slice_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:167:0
  %/Mul_4_output_0 : Float(*, *, *, strides=[18000, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/Mul_4"](%/Sub_output_0, %/Transpose_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/utils/helpers.py:168:0
  %/Transpose_3_output_0 : Float(*, *, *, strides=[18000, 1, 180], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/Transpose_3"](%/Mul_4_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1152:0
  %/Transpose_4_output_0 : Float(*, *, 192, strides=[38400, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/Transpose_4"](%/text_encoder/Split_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1152:0
  %/MatMul_output_0 : Float(*, *, 192, strides=[34560, 192, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/MatMul"](%/Transpose_3_output_0, %/Transpose_4_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1152:0
  %/Transpose_5_output_0 : Float(*, 192, *, strides=[34560, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/Transpose_5"](%/MatMul_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1152:0
  %/Transpose_6_output_0 : Float(*, *, 192, strides=[38400, 1, 100], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/Transpose_6"](%/text_encoder/Split_output_1), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1153:0
  %/MatMul_1_output_0 : Float(*, *, 192, strides=[34560, 192, 1], requires_grad=0, device=cpu) = onnx::MatMul[onnx_name="/MatMul_1"](%/Transpose_3_output_0, %/Transpose_6_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1153:0
  %/Transpose_7_output_0 : Float(*, 192, *, strides=[34560, 1, 192], requires_grad=0, device=cpu) = onnx::Transpose[perm=[0, 2, 1], onnx_name="/Transpose_7"](%/MatMul_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1153:0
  %/RandomNormalLike_output_0 : Float(*, 192, *, strides=[34560, 1, 192], requires_grad=0, device=cpu) = onnx::RandomNormalLike[dtype=1, onnx_name="/RandomNormalLike"](%/Transpose_5_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1155:0
  %/Exp_1_output_0 : Float(*, 192, *, strides=[34560, 1, 192], requires_grad=0, device=cpu) = onnx::Exp[onnx_name="/Exp_1"](%/Transpose_7_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1155:0
  %/Mul_5_output_0 : Float(*, 192, *, strides=[34560, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/Mul_5"](%/RandomNormalLike_output_0, %/Exp_1_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1155:0
  %/Constant_29_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.667}, onnx_name="/Constant_29"](), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1155:0
  %/Mul_6_output_0 : Float(*, 192, *, strides=[34560, 1, 192], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/Mul_6"](%/Mul_5_output_0, %/Constant_29_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1155:0
  %/Add_output_0 : Float(*, 192, *, strides=[34560, 1, 192], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/Add"](%/Transpose_5_output_0, %/Mul_6_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1155:0
  %/flow/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/flow/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/flow/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/flow/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Slice_output_0 : Float(*, 192, *, strides=[34560, 1, 192], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/Slice"](%/Add_output_0, %/flow/Constant_1_output_0, %/flow/Constant_2_output_0, %/flow/Constant_output_0, %/flow/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %onnx::Split_7144 : Long(2, strides=[1], device=cpu) = onnx::Constant[value= 96  96 [ CPULongType{2} ]]()
  %/flow/flows.3/Split_output_0 : Float(*, 96, *, strides=[34560, 1, 192], requires_grad=0, device=cpu), %/flow/flows.3/Split_output_1 : Float(*, 96, *, strides=[34560, 1, 192], requires_grad=0, device=cpu) = onnx::Split[axis=1, onnx_name="/flow/flows.3/Split"](%/flow/Slice_output_0, %onnx::Split_7144), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:917:0
  %/flow/flows.3/pre/Conv_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.3/pre/Conv"](%/flow/flows.3/Split_output_0, %flow.flows.3.pre.weight, %flow.flows.3.pre.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/torch.nn.modules.conv.Conv1d::pre # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/Mul_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.3/Mul"](%/flow/flows.3/pre/Conv_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:149:0
  %/flow/flows.3/enc/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/flow/flows.3/enc/Shape"](%/flow/flows.3/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:95:0
  %/flow/flows.3/enc/ConstantOfShape_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/flow/flows.3/enc/ConstantOfShape"](%/flow/flows.3/enc/Shape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:95:0
  %/flow/flows.3/enc/cond_layer/Conv_output_0 : Float(1, 1536, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.3/enc/cond_layer/Conv"](%/Unsqueeze_output_0, %onnx::Conv_9573, %flow.flows.3.enc.cond_layer.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::cond_layer # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/enc/in_layers.0/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.3/enc/in_layers.0/Conv"](%/flow/flows.3/Mul_output_0, %onnx::Conv_9576, %flow.flows.3.enc.in_layers.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/enc/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.3/enc/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={384}, onnx_name="/flow/flows.3/enc/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Slice_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice"](%/flow/flows.3/enc/cond_layer/Conv_output_0, %/flow/flows.3/enc/Constant_1_output_0, %/flow/flows.3/enc/Constant_2_output_0, %/flow/flows.3/enc/Constant_output_0, %/flow/flows.3/enc/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.3/enc/in_layers.0/Conv_output_0, %/flow/flows.3/enc/Slice_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9581 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7172 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7173 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9582 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7176 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act, %onnx::Slice_7172, %onnx::Slice_7173, %onnx::Slice_9581, %onnx::Slice_9582) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9583 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7179 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9584 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9585 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7184 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7176, %onnx::Slice_7179, %onnx::Slice_9584, %onnx::Slice_9583, %onnx::Slice_9585) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9586 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7188 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9587 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7191 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7184, %onnx::Slice_7187, %onnx::Slice_7188, %onnx::Slice_9586, %onnx::Slice_9587) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7191) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9588 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9589 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7197 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9590 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7200 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7176, %onnx::Slice_9589, %onnx::Slice_7197, %onnx::Slice_9588, %onnx::Slice_9590) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9591 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7203 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7204 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9592 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7207 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7200, %onnx::Slice_7203, %onnx::Slice_7204, %onnx::Slice_9591, %onnx::Slice_9592) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7207) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.384 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act, %s_act) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.3/enc/res_skip_layers.0/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.3/enc/res_skip_layers.0/Conv"](%input.384, %onnx::Conv_9595, %flow.flows.3.enc.res_skip_layers.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/enc/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.3/enc/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.3/enc/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Slice_1_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice_1"](%/flow/flows.3/enc/res_skip_layers.0/Conv_output_0, %/flow/flows.3/enc/Constant_5_output_0, %/flow/flows.3/enc/Constant_6_output_0, %/flow/flows.3/enc/Constant_4_output_0, %/flow/flows.3/enc/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Add_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.3/enc/Add"](%/flow/flows.3/Mul_output_0, %/flow/flows.3/enc/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Mul_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.3/enc/Mul"](%/flow/flows.3/enc/Add_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.3/enc/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.3/enc/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Slice_2_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice_2"](%/flow/flows.3/enc/res_skip_layers.0/Conv_output_0, %/flow/flows.3/enc/Constant_9_output_0, %/flow/flows.3/enc/Constant_10_output_0, %/flow/flows.3/enc/Constant_8_output_0, %/flow/flows.3/enc/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Add_1_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.3/enc/Add_1"](%/flow/flows.3/enc/ConstantOfShape_output_0, %/flow/flows.3/enc/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/in_layers.1/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.3/enc/in_layers.1/Conv"](%/flow/flows.3/enc/Mul_output_0, %onnx::Conv_9606, %flow.flows.3.enc.in_layers.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/enc/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={384}, onnx_name="/flow/flows.3/enc/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={768}, onnx_name="/flow/flows.3/enc/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Slice_3_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice_3"](%/flow/flows.3/enc/cond_layer/Conv_output_0, %/flow/flows.3/enc/Constant_13_output_0, %/flow/flows.3/enc/Constant_14_output_0, %/flow/flows.3/enc/Constant_12_output_0, %/flow/flows.3/enc/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.3 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.3/enc/in_layers.1/Conv_output_0, %/flow/flows.3/enc/Slice_3_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9611 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7252 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7253 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9612 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7256 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.3, %onnx::Slice_7252, %onnx::Slice_7253, %onnx::Slice_9611, %onnx::Slice_9612) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9613 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7259 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9614 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9615 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7264 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7256, %onnx::Slice_7259, %onnx::Slice_9614, %onnx::Slice_9613, %onnx::Slice_9615) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9616 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7267 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7268 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9617 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7271 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7264, %onnx::Slice_7267, %onnx::Slice_7268, %onnx::Slice_9616, %onnx::Slice_9617) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.3 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7271) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9618 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9619 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7277 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9620 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7280 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7256, %onnx::Slice_9619, %onnx::Slice_7277, %onnx::Slice_9618, %onnx::Slice_9620) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9621 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7283 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7284 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9622 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7287 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7280, %onnx::Slice_7283, %onnx::Slice_7284, %onnx::Slice_9621, %onnx::Slice_9622) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.3 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7287) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.396 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.3, %s_act.3) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.3/enc/res_skip_layers.1/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.3/enc/res_skip_layers.1/Conv"](%input.396, %onnx::Conv_9625, %flow.flows.3.enc.res_skip_layers.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/enc/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.3/enc/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.3/enc/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Slice_4_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice_4"](%/flow/flows.3/enc/res_skip_layers.1/Conv_output_0, %/flow/flows.3/enc/Constant_17_output_0, %/flow/flows.3/enc/Constant_18_output_0, %/flow/flows.3/enc/Constant_16_output_0, %/flow/flows.3/enc/Constant_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Add_2_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.3/enc/Add_2"](%/flow/flows.3/enc/Mul_output_0, %/flow/flows.3/enc/Slice_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Mul_1_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.3/enc/Mul_1"](%/flow/flows.3/enc/Add_2_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.3/enc/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.3/enc/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Slice_5_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice_5"](%/flow/flows.3/enc/res_skip_layers.1/Conv_output_0, %/flow/flows.3/enc/Constant_21_output_0, %/flow/flows.3/enc/Constant_22_output_0, %/flow/flows.3/enc/Constant_20_output_0, %/flow/flows.3/enc/Constant_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Add_3_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.3/enc/Add_3"](%/flow/flows.3/enc/Add_1_output_0, %/flow/flows.3/enc/Slice_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/in_layers.2/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.3/enc/in_layers.2/Conv"](%/flow/flows.3/enc/Mul_1_output_0, %onnx::Conv_9636, %flow.flows.3.enc.in_layers.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/enc/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={768}, onnx_name="/flow/flows.3/enc/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1152}, onnx_name="/flow/flows.3/enc/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Slice_6_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice_6"](%/flow/flows.3/enc/cond_layer/Conv_output_0, %/flow/flows.3/enc/Constant_25_output_0, %/flow/flows.3/enc/Constant_26_output_0, %/flow/flows.3/enc/Constant_24_output_0, %/flow/flows.3/enc/Constant_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.7 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.3/enc/in_layers.2/Conv_output_0, %/flow/flows.3/enc/Slice_6_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9641 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7332 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7333 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9642 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7336 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.7, %onnx::Slice_7332, %onnx::Slice_7333, %onnx::Slice_9641, %onnx::Slice_9642) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9643 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7339 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9644 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9645 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7344 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7336, %onnx::Slice_7339, %onnx::Slice_9644, %onnx::Slice_9643, %onnx::Slice_9645) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9646 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7347 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7348 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9647 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7351 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7344, %onnx::Slice_7347, %onnx::Slice_7348, %onnx::Slice_9646, %onnx::Slice_9647) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.7 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7351) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9648 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9649 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7357 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9650 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7360 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7336, %onnx::Slice_9649, %onnx::Slice_7357, %onnx::Slice_9648, %onnx::Slice_9650) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9651 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7363 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7364 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9652 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7367 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7360, %onnx::Slice_7363, %onnx::Slice_7364, %onnx::Slice_9651, %onnx::Slice_9652) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.7 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7367) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.408 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.7, %s_act.7) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.3/enc/res_skip_layers.2/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.3/enc/res_skip_layers.2/Conv"](%input.408, %onnx::Conv_9655, %flow.flows.3.enc.res_skip_layers.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/enc/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.3/enc/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.3/enc/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Slice_7_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice_7"](%/flow/flows.3/enc/res_skip_layers.2/Conv_output_0, %/flow/flows.3/enc/Constant_29_output_0, %/flow/flows.3/enc/Constant_30_output_0, %/flow/flows.3/enc/Constant_28_output_0, %/flow/flows.3/enc/Constant_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Add_4_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.3/enc/Add_4"](%/flow/flows.3/enc/Mul_1_output_0, %/flow/flows.3/enc/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Mul_2_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.3/enc/Mul_2"](%/flow/flows.3/enc/Add_4_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.3/enc/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.3/enc/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.3/enc/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Slice_8_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice_8"](%/flow/flows.3/enc/res_skip_layers.2/Conv_output_0, %/flow/flows.3/enc/Constant_33_output_0, %/flow/flows.3/enc/Constant_34_output_0, %/flow/flows.3/enc/Constant_32_output_0, %/flow/flows.3/enc/Constant_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/Add_5_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.3/enc/Add_5"](%/flow/flows.3/enc/Add_3_output_0, %/flow/flows.3/enc/Slice_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.3/enc/in_layers.3/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.3/enc/in_layers.3/Conv"](%/flow/flows.3/enc/Mul_2_output_0, %onnx::Conv_9666, %flow.flows.3.enc.in_layers.3.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/enc/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1152}, onnx_name="/flow/flows.3/enc/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1536}, onnx_name="/flow/flows.3/enc/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.3/enc/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.3/enc/Slice_9_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.3/enc/Slice_9"](%/flow/flows.3/enc/cond_layer/Conv_output_0, %/flow/flows.3/enc/Constant_37_output_0, %/flow/flows.3/enc/Constant_38_output_0, %/flow/flows.3/enc/Constant_36_output_0, %/flow/flows.3/enc/Constant_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.11 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.3/enc/in_layers.3/Conv_output_0, %/flow/flows.3/enc/Slice_9_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9671 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7412 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7413 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9672 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7416 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.11, %onnx::Slice_7412, %onnx::Slice_7413, %onnx::Slice_9671, %onnx::Slice_9672) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9673 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7419 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9674 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9675 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7424 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7416, %onnx::Slice_7419, %onnx::Slice_9674, %onnx::Slice_9673, %onnx::Slice_9675) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9676 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7427 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7428 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9677 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7431 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7424, %onnx::Slice_7427, %onnx::Slice_7428, %onnx::Slice_9676, %onnx::Slice_9677) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.11 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7431) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9678 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9679 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7437 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9680 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7440 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7416, %onnx::Slice_9679, %onnx::Slice_7437, %onnx::Slice_9678, %onnx::Slice_9680) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9681 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7443 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7444 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9682 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7447 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7440, %onnx::Slice_7443, %onnx::Slice_7444, %onnx::Slice_9681, %onnx::Slice_9682) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.11 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7447) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.420 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.11, %s_act.11) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.3/enc/res_skip_layers.3/Conv_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.3/enc/res_skip_layers.3/Conv"](%input.420, %onnx::Conv_9685, %flow.flows.3.enc.res_skip_layers.3.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/enc/Add_6_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.3/enc/Add_6"](%/flow/flows.3/enc/Add_5_output_0, %/flow/flows.3/enc/res_skip_layers.3/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:114:0
  %/flow/flows.3/enc/Mul_3_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.3/enc/Mul_3"](%/flow/flows.3/enc/Add_6_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:115:0
  %/flow/flows.3/post/Conv_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.3/post/Conv"](%/flow/flows.3/enc/Mul_3_output_0, %flow.flows.3.post.weight, %flow.flows.3.post.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3/torch.nn.modules.conv.Conv1d::post # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.3/Mul_1_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.3/Mul_1"](%/flow/flows.3/post/Conv_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:151:0
  %/flow/flows.3/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/flow/flows.3/Shape"](%/flow/flows.3/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:156:0
  %/flow/flows.3/ConstantOfShape_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/flow/flows.3/ConstantOfShape"](%/flow/flows.3/Shape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:156:0
  %/flow/flows.3/Sub_output_0 : Float(*, 96, *, strides=[17280, 1, 96], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/flow/flows.3/Sub"](%/flow/flows.3/Split_output_1, %/flow/flows.3/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.3/Neg_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/flow/flows.3/Neg"](%/flow/flows.3/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.3/Exp_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Exp[onnx_name="/flow/flows.3/Exp"](%/flow/flows.3/Neg_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.3/Mul_2_output_0 : Float(*, 96, *, strides=[17280, 1, 96], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.3/Mul_2"](%/flow/flows.3/Sub_output_0, %/flow/flows.3/Exp_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.3/Mul_3_output_0 : Float(*, 96, *, strides=[17280, 1, 96], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.3/Mul_3"](%/flow/flows.3/Mul_2_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.3/Concat_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name="/flow/flows.3/Concat"](%/flow/flows.3/Split_output_0, %/flow/flows.3/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.3 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:165:0
  %/flow/Constant_4_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_5_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/flow/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_6_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/flow/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_7_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/flow/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Slice_1_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/Slice_1"](%/flow/flows.3/Concat_output_0, %/flow/Constant_5_output_0, %/flow/Constant_6_output_0, %/flow/Constant_4_output_0, %/flow/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/flows.2/Split_output_0 : Float(*, 96, *, strides=[34560, 180, 1], requires_grad=0, device=cpu), %/flow/flows.2/Split_output_1 : Float(*, 96, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Split[axis=1, onnx_name="/flow/flows.2/Split"](%/flow/Slice_1_output_0, %onnx::Split_7144), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:917:0
  %/flow/flows.2/pre/Conv_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.2/pre/Conv"](%/flow/flows.2/Split_output_0, %flow.flows.2.pre.weight, %flow.flows.2.pre.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/torch.nn.modules.conv.Conv1d::pre # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/Mul_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.2/Mul"](%/flow/flows.2/pre/Conv_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:149:0
  %/flow/flows.2/enc/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/flow/flows.2/enc/Shape"](%/flow/flows.2/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:95:0
  %/flow/flows.2/enc/ConstantOfShape_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/flow/flows.2/enc/ConstantOfShape"](%/flow/flows.2/enc/Shape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:95:0
  %/flow/flows.2/enc/cond_layer/Conv_output_0 : Float(1, 1536, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.2/enc/cond_layer/Conv"](%/Unsqueeze_output_0, %onnx::Conv_9688, %flow.flows.2.enc.cond_layer.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::cond_layer # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/enc/in_layers.0/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.2/enc/in_layers.0/Conv"](%/flow/flows.2/Mul_output_0, %onnx::Conv_9691, %flow.flows.2.enc.in_layers.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/enc/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.2/enc/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={384}, onnx_name="/flow/flows.2/enc/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Slice_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice"](%/flow/flows.2/enc/cond_layer/Conv_output_0, %/flow/flows.2/enc/Constant_1_output_0, %/flow/flows.2/enc/Constant_2_output_0, %/flow/flows.2/enc/Constant_output_0, %/flow/flows.2/enc/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.15 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.2/enc/in_layers.0/Conv_output_0, %/flow/flows.2/enc/Slice_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9696 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7497 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7498 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9697 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7501 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.15, %onnx::Slice_7497, %onnx::Slice_7498, %onnx::Slice_9696, %onnx::Slice_9697) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9698 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7504 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9699 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9700 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7509 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7501, %onnx::Slice_7504, %onnx::Slice_9699, %onnx::Slice_9698, %onnx::Slice_9700) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9701 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7512 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7513 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9702 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7516 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7509, %onnx::Slice_7512, %onnx::Slice_7513, %onnx::Slice_9701, %onnx::Slice_9702) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.15 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7516) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9703 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9704 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7522 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9705 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7525 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7501, %onnx::Slice_9704, %onnx::Slice_7522, %onnx::Slice_9703, %onnx::Slice_9705) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9706 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7528 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7529 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9707 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7532 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7525, %onnx::Slice_7528, %onnx::Slice_7529, %onnx::Slice_9706, %onnx::Slice_9707) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.15 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7532) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.440 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.15, %s_act.15) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.2/enc/res_skip_layers.0/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.2/enc/res_skip_layers.0/Conv"](%input.440, %onnx::Conv_9710, %flow.flows.2.enc.res_skip_layers.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/enc/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.2/enc/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.2/enc/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Slice_1_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice_1"](%/flow/flows.2/enc/res_skip_layers.0/Conv_output_0, %/flow/flows.2/enc/Constant_5_output_0, %/flow/flows.2/enc/Constant_6_output_0, %/flow/flows.2/enc/Constant_4_output_0, %/flow/flows.2/enc/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Add_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.2/enc/Add"](%/flow/flows.2/Mul_output_0, %/flow/flows.2/enc/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Mul_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.2/enc/Mul"](%/flow/flows.2/enc/Add_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.2/enc/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.2/enc/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Slice_2_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice_2"](%/flow/flows.2/enc/res_skip_layers.0/Conv_output_0, %/flow/flows.2/enc/Constant_9_output_0, %/flow/flows.2/enc/Constant_10_output_0, %/flow/flows.2/enc/Constant_8_output_0, %/flow/flows.2/enc/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Add_1_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.2/enc/Add_1"](%/flow/flows.2/enc/ConstantOfShape_output_0, %/flow/flows.2/enc/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/in_layers.1/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.2/enc/in_layers.1/Conv"](%/flow/flows.2/enc/Mul_output_0, %onnx::Conv_9721, %flow.flows.2.enc.in_layers.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/enc/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={384}, onnx_name="/flow/flows.2/enc/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={768}, onnx_name="/flow/flows.2/enc/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Slice_3_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice_3"](%/flow/flows.2/enc/cond_layer/Conv_output_0, %/flow/flows.2/enc/Constant_13_output_0, %/flow/flows.2/enc/Constant_14_output_0, %/flow/flows.2/enc/Constant_12_output_0, %/flow/flows.2/enc/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.19 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.2/enc/in_layers.1/Conv_output_0, %/flow/flows.2/enc/Slice_3_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9726 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7576 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7577 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9727 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7580 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.19, %onnx::Slice_7576, %onnx::Slice_7577, %onnx::Slice_9726, %onnx::Slice_9727) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9728 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7583 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9729 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9730 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7588 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7580, %onnx::Slice_7583, %onnx::Slice_9729, %onnx::Slice_9728, %onnx::Slice_9730) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9731 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7592 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9732 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7595 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7588, %onnx::Slice_7591, %onnx::Slice_7592, %onnx::Slice_9731, %onnx::Slice_9732) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.19 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7595) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9733 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9734 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7601 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9735 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7604 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7580, %onnx::Slice_9734, %onnx::Slice_7601, %onnx::Slice_9733, %onnx::Slice_9735) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9736 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7607 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7608 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9737 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7611 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7604, %onnx::Slice_7607, %onnx::Slice_7608, %onnx::Slice_9736, %onnx::Slice_9737) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.19 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7611) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.452 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.19, %s_act.19) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.2/enc/res_skip_layers.1/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.2/enc/res_skip_layers.1/Conv"](%input.452, %onnx::Conv_9740, %flow.flows.2.enc.res_skip_layers.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/enc/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.2/enc/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.2/enc/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Slice_4_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice_4"](%/flow/flows.2/enc/res_skip_layers.1/Conv_output_0, %/flow/flows.2/enc/Constant_17_output_0, %/flow/flows.2/enc/Constant_18_output_0, %/flow/flows.2/enc/Constant_16_output_0, %/flow/flows.2/enc/Constant_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Add_2_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.2/enc/Add_2"](%/flow/flows.2/enc/Mul_output_0, %/flow/flows.2/enc/Slice_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Mul_1_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.2/enc/Mul_1"](%/flow/flows.2/enc/Add_2_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.2/enc/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.2/enc/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Slice_5_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice_5"](%/flow/flows.2/enc/res_skip_layers.1/Conv_output_0, %/flow/flows.2/enc/Constant_21_output_0, %/flow/flows.2/enc/Constant_22_output_0, %/flow/flows.2/enc/Constant_20_output_0, %/flow/flows.2/enc/Constant_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Add_3_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.2/enc/Add_3"](%/flow/flows.2/enc/Add_1_output_0, %/flow/flows.2/enc/Slice_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/in_layers.2/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.2/enc/in_layers.2/Conv"](%/flow/flows.2/enc/Mul_1_output_0, %onnx::Conv_9751, %flow.flows.2.enc.in_layers.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/enc/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={768}, onnx_name="/flow/flows.2/enc/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1152}, onnx_name="/flow/flows.2/enc/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Slice_6_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice_6"](%/flow/flows.2/enc/cond_layer/Conv_output_0, %/flow/flows.2/enc/Constant_25_output_0, %/flow/flows.2/enc/Constant_26_output_0, %/flow/flows.2/enc/Constant_24_output_0, %/flow/flows.2/enc/Constant_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.23 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.2/enc/in_layers.2/Conv_output_0, %/flow/flows.2/enc/Slice_6_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9756 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7655 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7656 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9757 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7659 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.23, %onnx::Slice_7655, %onnx::Slice_7656, %onnx::Slice_9756, %onnx::Slice_9757) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9758 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7662 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9759 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9760 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7667 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7659, %onnx::Slice_7662, %onnx::Slice_9759, %onnx::Slice_9758, %onnx::Slice_9760) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9761 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7670 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7671 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9762 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7674 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7667, %onnx::Slice_7670, %onnx::Slice_7671, %onnx::Slice_9761, %onnx::Slice_9762) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.23 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7674) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9763 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9764 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7680 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9765 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7683 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7659, %onnx::Slice_9764, %onnx::Slice_7680, %onnx::Slice_9763, %onnx::Slice_9765) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9766 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7686 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7687 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9767 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7690 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7683, %onnx::Slice_7686, %onnx::Slice_7687, %onnx::Slice_9766, %onnx::Slice_9767) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.23 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7690) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.464 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.23, %s_act.23) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.2/enc/res_skip_layers.2/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.2/enc/res_skip_layers.2/Conv"](%input.464, %onnx::Conv_9770, %flow.flows.2.enc.res_skip_layers.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/enc/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.2/enc/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.2/enc/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Slice_7_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice_7"](%/flow/flows.2/enc/res_skip_layers.2/Conv_output_0, %/flow/flows.2/enc/Constant_29_output_0, %/flow/flows.2/enc/Constant_30_output_0, %/flow/flows.2/enc/Constant_28_output_0, %/flow/flows.2/enc/Constant_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Add_4_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.2/enc/Add_4"](%/flow/flows.2/enc/Mul_1_output_0, %/flow/flows.2/enc/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Mul_2_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.2/enc/Mul_2"](%/flow/flows.2/enc/Add_4_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.2/enc/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.2/enc/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.2/enc/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Slice_8_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice_8"](%/flow/flows.2/enc/res_skip_layers.2/Conv_output_0, %/flow/flows.2/enc/Constant_33_output_0, %/flow/flows.2/enc/Constant_34_output_0, %/flow/flows.2/enc/Constant_32_output_0, %/flow/flows.2/enc/Constant_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/Add_5_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.2/enc/Add_5"](%/flow/flows.2/enc/Add_3_output_0, %/flow/flows.2/enc/Slice_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.2/enc/in_layers.3/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.2/enc/in_layers.3/Conv"](%/flow/flows.2/enc/Mul_2_output_0, %onnx::Conv_9781, %flow.flows.2.enc.in_layers.3.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/enc/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1152}, onnx_name="/flow/flows.2/enc/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1536}, onnx_name="/flow/flows.2/enc/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.2/enc/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.2/enc/Slice_9_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.2/enc/Slice_9"](%/flow/flows.2/enc/cond_layer/Conv_output_0, %/flow/flows.2/enc/Constant_37_output_0, %/flow/flows.2/enc/Constant_38_output_0, %/flow/flows.2/enc/Constant_36_output_0, %/flow/flows.2/enc/Constant_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.27 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.2/enc/in_layers.3/Conv_output_0, %/flow/flows.2/enc/Slice_9_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9786 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7734 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7735 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9787 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7738 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.27, %onnx::Slice_7734, %onnx::Slice_7735, %onnx::Slice_9786, %onnx::Slice_9787) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9788 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7741 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9789 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9790 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7746 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7738, %onnx::Slice_7741, %onnx::Slice_9789, %onnx::Slice_9788, %onnx::Slice_9790) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9791 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7749 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7750 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9792 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7753 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7746, %onnx::Slice_7749, %onnx::Slice_7750, %onnx::Slice_9791, %onnx::Slice_9792) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.27 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7753) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9793 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9794 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7759 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9795 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7762 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7738, %onnx::Slice_9794, %onnx::Slice_7759, %onnx::Slice_9793, %onnx::Slice_9795) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9796 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7765 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7766 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9797 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7769 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7762, %onnx::Slice_7765, %onnx::Slice_7766, %onnx::Slice_9796, %onnx::Slice_9797) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.27 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7769) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.476 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.27, %s_act.27) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.2/enc/res_skip_layers.3/Conv_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.2/enc/res_skip_layers.3/Conv"](%input.476, %onnx::Conv_9800, %flow.flows.2.enc.res_skip_layers.3.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/enc/Add_6_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.2/enc/Add_6"](%/flow/flows.2/enc/Add_5_output_0, %/flow/flows.2/enc/res_skip_layers.3/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:114:0
  %/flow/flows.2/enc/Mul_3_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.2/enc/Mul_3"](%/flow/flows.2/enc/Add_6_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:115:0
  %/flow/flows.2/post/Conv_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.2/post/Conv"](%/flow/flows.2/enc/Mul_3_output_0, %flow.flows.2.post.weight, %flow.flows.2.post.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2/torch.nn.modules.conv.Conv1d::post # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.2/Mul_1_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.2/Mul_1"](%/flow/flows.2/post/Conv_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:151:0
  %/flow/flows.2/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/flow/flows.2/Shape"](%/flow/flows.2/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:156:0
  %/flow/flows.2/ConstantOfShape_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/flow/flows.2/ConstantOfShape"](%/flow/flows.2/Shape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:156:0
  %/flow/flows.2/Sub_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/flow/flows.2/Sub"](%/flow/flows.2/Split_output_1, %/flow/flows.2/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.2/Neg_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/flow/flows.2/Neg"](%/flow/flows.2/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.2/Exp_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Exp[onnx_name="/flow/flows.2/Exp"](%/flow/flows.2/Neg_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.2/Mul_2_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.2/Mul_2"](%/flow/flows.2/Sub_output_0, %/flow/flows.2/Exp_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.2/Mul_3_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.2/Mul_3"](%/flow/flows.2/Mul_2_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.2/Concat_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name="/flow/flows.2/Concat"](%/flow/flows.2/Split_output_0, %/flow/flows.2/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.2 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:165:0
  %/flow/Constant_8_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_9_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/flow/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_10_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/flow/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_11_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/flow/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Slice_2_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/Slice_2"](%/flow/flows.2/Concat_output_0, %/flow/Constant_9_output_0, %/flow/Constant_10_output_0, %/flow/Constant_8_output_0, %/flow/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/flows.1/Split_output_0 : Float(*, 96, *, strides=[34560, 180, 1], requires_grad=0, device=cpu), %/flow/flows.1/Split_output_1 : Float(*, 96, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Split[axis=1, onnx_name="/flow/flows.1/Split"](%/flow/Slice_2_output_0, %onnx::Split_7144), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:917:0
  %/flow/flows.1/pre/Conv_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.1/pre/Conv"](%/flow/flows.1/Split_output_0, %flow.flows.1.pre.weight, %flow.flows.1.pre.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/torch.nn.modules.conv.Conv1d::pre # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/Mul_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.1/Mul"](%/flow/flows.1/pre/Conv_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:149:0
  %/flow/flows.1/enc/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/flow/flows.1/enc/Shape"](%/flow/flows.1/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:95:0
  %/flow/flows.1/enc/ConstantOfShape_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/flow/flows.1/enc/ConstantOfShape"](%/flow/flows.1/enc/Shape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:95:0
  %/flow/flows.1/enc/cond_layer/Conv_output_0 : Float(1, 1536, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.1/enc/cond_layer/Conv"](%/Unsqueeze_output_0, %onnx::Conv_9803, %flow.flows.1.enc.cond_layer.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::cond_layer # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/enc/in_layers.0/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.1/enc/in_layers.0/Conv"](%/flow/flows.1/Mul_output_0, %onnx::Conv_9806, %flow.flows.1.enc.in_layers.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/enc/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.1/enc/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={384}, onnx_name="/flow/flows.1/enc/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Slice_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice"](%/flow/flows.1/enc/cond_layer/Conv_output_0, %/flow/flows.1/enc/Constant_1_output_0, %/flow/flows.1/enc/Constant_2_output_0, %/flow/flows.1/enc/Constant_output_0, %/flow/flows.1/enc/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.31 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.1/enc/in_layers.0/Conv_output_0, %/flow/flows.1/enc/Slice_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9811 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7819 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7820 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9812 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7823 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.31, %onnx::Slice_7819, %onnx::Slice_7820, %onnx::Slice_9811, %onnx::Slice_9812) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9813 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7826 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9814 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9815 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7831 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7823, %onnx::Slice_7826, %onnx::Slice_9814, %onnx::Slice_9813, %onnx::Slice_9815) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9816 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7834 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7835 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9817 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7838 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7831, %onnx::Slice_7834, %onnx::Slice_7835, %onnx::Slice_9816, %onnx::Slice_9817) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.31 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7838) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9818 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9819 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7844 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9820 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7847 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7823, %onnx::Slice_9819, %onnx::Slice_7844, %onnx::Slice_9818, %onnx::Slice_9820) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9821 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7850 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9822 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7854 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7847, %onnx::Slice_7850, %onnx::Slice_7851, %onnx::Slice_9821, %onnx::Slice_9822) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.31 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7854) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.496 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.31, %s_act.31) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.1/enc/res_skip_layers.0/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.1/enc/res_skip_layers.0/Conv"](%input.496, %onnx::Conv_9825, %flow.flows.1.enc.res_skip_layers.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/enc/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.1/enc/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.1/enc/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Slice_1_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice_1"](%/flow/flows.1/enc/res_skip_layers.0/Conv_output_0, %/flow/flows.1/enc/Constant_5_output_0, %/flow/flows.1/enc/Constant_6_output_0, %/flow/flows.1/enc/Constant_4_output_0, %/flow/flows.1/enc/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Add_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.1/enc/Add"](%/flow/flows.1/Mul_output_0, %/flow/flows.1/enc/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Mul_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.1/enc/Mul"](%/flow/flows.1/enc/Add_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.1/enc/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.1/enc/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Slice_2_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice_2"](%/flow/flows.1/enc/res_skip_layers.0/Conv_output_0, %/flow/flows.1/enc/Constant_9_output_0, %/flow/flows.1/enc/Constant_10_output_0, %/flow/flows.1/enc/Constant_8_output_0, %/flow/flows.1/enc/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Add_1_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.1/enc/Add_1"](%/flow/flows.1/enc/ConstantOfShape_output_0, %/flow/flows.1/enc/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/in_layers.1/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.1/enc/in_layers.1/Conv"](%/flow/flows.1/enc/Mul_output_0, %onnx::Conv_9836, %flow.flows.1.enc.in_layers.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/enc/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={384}, onnx_name="/flow/flows.1/enc/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={768}, onnx_name="/flow/flows.1/enc/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Slice_3_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice_3"](%/flow/flows.1/enc/cond_layer/Conv_output_0, %/flow/flows.1/enc/Constant_13_output_0, %/flow/flows.1/enc/Constant_14_output_0, %/flow/flows.1/enc/Constant_12_output_0, %/flow/flows.1/enc/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.35 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.1/enc/in_layers.1/Conv_output_0, %/flow/flows.1/enc/Slice_3_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9841 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7898 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9842 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7902 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.35, %onnx::Slice_7898, %onnx::Slice_7899, %onnx::Slice_9841, %onnx::Slice_9842) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9843 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7905 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9844 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9845 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7910 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7902, %onnx::Slice_7905, %onnx::Slice_9844, %onnx::Slice_9843, %onnx::Slice_9845) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9846 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7913 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7914 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9847 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7917 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7910, %onnx::Slice_7913, %onnx::Slice_7914, %onnx::Slice_9846, %onnx::Slice_9847) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.35 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7917) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9848 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9849 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7923 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9850 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7926 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7902, %onnx::Slice_9849, %onnx::Slice_7923, %onnx::Slice_9848, %onnx::Slice_9850) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9851 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_7930 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9852 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_7933 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7926, %onnx::Slice_7929, %onnx::Slice_7930, %onnx::Slice_9851, %onnx::Slice_9852) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.35 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_7933) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.508 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.35, %s_act.35) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.1/enc/res_skip_layers.1/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.1/enc/res_skip_layers.1/Conv"](%input.508, %onnx::Conv_9855, %flow.flows.1.enc.res_skip_layers.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/enc/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.1/enc/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.1/enc/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Slice_4_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice_4"](%/flow/flows.1/enc/res_skip_layers.1/Conv_output_0, %/flow/flows.1/enc/Constant_17_output_0, %/flow/flows.1/enc/Constant_18_output_0, %/flow/flows.1/enc/Constant_16_output_0, %/flow/flows.1/enc/Constant_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Add_2_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.1/enc/Add_2"](%/flow/flows.1/enc/Mul_output_0, %/flow/flows.1/enc/Slice_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Mul_1_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.1/enc/Mul_1"](%/flow/flows.1/enc/Add_2_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.1/enc/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.1/enc/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Slice_5_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice_5"](%/flow/flows.1/enc/res_skip_layers.1/Conv_output_0, %/flow/flows.1/enc/Constant_21_output_0, %/flow/flows.1/enc/Constant_22_output_0, %/flow/flows.1/enc/Constant_20_output_0, %/flow/flows.1/enc/Constant_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Add_3_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.1/enc/Add_3"](%/flow/flows.1/enc/Add_1_output_0, %/flow/flows.1/enc/Slice_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/in_layers.2/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.1/enc/in_layers.2/Conv"](%/flow/flows.1/enc/Mul_1_output_0, %onnx::Conv_9866, %flow.flows.1.enc.in_layers.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/enc/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={768}, onnx_name="/flow/flows.1/enc/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1152}, onnx_name="/flow/flows.1/enc/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Slice_6_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice_6"](%/flow/flows.1/enc/cond_layer/Conv_output_0, %/flow/flows.1/enc/Constant_25_output_0, %/flow/flows.1/enc/Constant_26_output_0, %/flow/flows.1/enc/Constant_24_output_0, %/flow/flows.1/enc/Constant_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.39 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.1/enc/in_layers.2/Conv_output_0, %/flow/flows.1/enc/Slice_6_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9871 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7977 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7978 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9872 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7981 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.39, %onnx::Slice_7977, %onnx::Slice_7978, %onnx::Slice_9871, %onnx::Slice_9872) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9873 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7984 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9874 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9875 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7989 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7981, %onnx::Slice_7984, %onnx::Slice_9874, %onnx::Slice_9873, %onnx::Slice_9875) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9876 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7992 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_7993 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9877 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_7996 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7989, %onnx::Slice_7992, %onnx::Slice_7993, %onnx::Slice_9876, %onnx::Slice_9877) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.39 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_7996) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9878 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9879 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8002 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9880 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8005 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_7981, %onnx::Slice_9879, %onnx::Slice_8002, %onnx::Slice_9878, %onnx::Slice_9880) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9881 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8008 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8009 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9882 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_8012 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8005, %onnx::Slice_8008, %onnx::Slice_8009, %onnx::Slice_9881, %onnx::Slice_9882) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.39 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_8012) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.520 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.39, %s_act.39) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.1/enc/res_skip_layers.2/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.1/enc/res_skip_layers.2/Conv"](%input.520, %onnx::Conv_9885, %flow.flows.1.enc.res_skip_layers.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/enc/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.1/enc/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.1/enc/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Slice_7_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice_7"](%/flow/flows.1/enc/res_skip_layers.2/Conv_output_0, %/flow/flows.1/enc/Constant_29_output_0, %/flow/flows.1/enc/Constant_30_output_0, %/flow/flows.1/enc/Constant_28_output_0, %/flow/flows.1/enc/Constant_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Add_4_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.1/enc/Add_4"](%/flow/flows.1/enc/Mul_1_output_0, %/flow/flows.1/enc/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Mul_2_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.1/enc/Mul_2"](%/flow/flows.1/enc/Add_4_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.1/enc/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.1/enc/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.1/enc/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Slice_8_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice_8"](%/flow/flows.1/enc/res_skip_layers.2/Conv_output_0, %/flow/flows.1/enc/Constant_33_output_0, %/flow/flows.1/enc/Constant_34_output_0, %/flow/flows.1/enc/Constant_32_output_0, %/flow/flows.1/enc/Constant_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/Add_5_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.1/enc/Add_5"](%/flow/flows.1/enc/Add_3_output_0, %/flow/flows.1/enc/Slice_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.1/enc/in_layers.3/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.1/enc/in_layers.3/Conv"](%/flow/flows.1/enc/Mul_2_output_0, %onnx::Conv_9896, %flow.flows.1.enc.in_layers.3.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/enc/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1152}, onnx_name="/flow/flows.1/enc/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1536}, onnx_name="/flow/flows.1/enc/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.1/enc/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.1/enc/Slice_9_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.1/enc/Slice_9"](%/flow/flows.1/enc/cond_layer/Conv_output_0, %/flow/flows.1/enc/Constant_37_output_0, %/flow/flows.1/enc/Constant_38_output_0, %/flow/flows.1/enc/Constant_36_output_0, %/flow/flows.1/enc/Constant_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.43 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.1/enc/in_layers.3/Conv_output_0, %/flow/flows.1/enc/Slice_9_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9901 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8056 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8057 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9902 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8060 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.43, %onnx::Slice_8056, %onnx::Slice_8057, %onnx::Slice_9901, %onnx::Slice_9902) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9903 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8063 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9904 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9905 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8068 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8060, %onnx::Slice_8063, %onnx::Slice_9904, %onnx::Slice_9903, %onnx::Slice_9905) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9906 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8071 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8072 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9907 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_8075 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8068, %onnx::Slice_8071, %onnx::Slice_8072, %onnx::Slice_9906, %onnx::Slice_9907) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.43 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_8075) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9908 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9909 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8081 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9910 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8084 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8060, %onnx::Slice_9909, %onnx::Slice_8081, %onnx::Slice_9908, %onnx::Slice_9910) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9911 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8087 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8088 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9912 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_8091 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8084, %onnx::Slice_8087, %onnx::Slice_8088, %onnx::Slice_9911, %onnx::Slice_9912) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.43 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_8091) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.532 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.43, %s_act.43) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.1/enc/res_skip_layers.3/Conv_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.1/enc/res_skip_layers.3/Conv"](%input.532, %onnx::Conv_9915, %flow.flows.1.enc.res_skip_layers.3.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/enc/Add_6_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.1/enc/Add_6"](%/flow/flows.1/enc/Add_5_output_0, %/flow/flows.1/enc/res_skip_layers.3/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:114:0
  %/flow/flows.1/enc/Mul_3_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.1/enc/Mul_3"](%/flow/flows.1/enc/Add_6_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:115:0
  %/flow/flows.1/post/Conv_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.1/post/Conv"](%/flow/flows.1/enc/Mul_3_output_0, %flow.flows.1.post.weight, %flow.flows.1.post.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1/torch.nn.modules.conv.Conv1d::post # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.1/Mul_1_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.1/Mul_1"](%/flow/flows.1/post/Conv_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:151:0
  %/flow/flows.1/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/flow/flows.1/Shape"](%/flow/flows.1/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:156:0
  %/flow/flows.1/ConstantOfShape_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/flow/flows.1/ConstantOfShape"](%/flow/flows.1/Shape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:156:0
  %/flow/flows.1/Sub_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/flow/flows.1/Sub"](%/flow/flows.1/Split_output_1, %/flow/flows.1/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.1/Neg_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/flow/flows.1/Neg"](%/flow/flows.1/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.1/Exp_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Exp[onnx_name="/flow/flows.1/Exp"](%/flow/flows.1/Neg_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.1/Mul_2_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.1/Mul_2"](%/flow/flows.1/Sub_output_0, %/flow/flows.1/Exp_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.1/Mul_3_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.1/Mul_3"](%/flow/flows.1/Mul_2_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.1/Concat_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name="/flow/flows.1/Concat"](%/flow/flows.1/Split_output_0, %/flow/flows.1/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.1 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:165:0
  %/flow/Constant_12_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_13_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/flow/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_14_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-9223372036854775807}, onnx_name="/flow/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Constant_15_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name="/flow/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/Slice_3_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/Slice_3"](%/flow/flows.1/Concat_output_0, %/flow/Constant_13_output_0, %/flow/Constant_14_output_0, %/flow/Constant_12_output_0, %/flow/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:230:0
  %/flow/flows.0/Split_output_0 : Float(*, 96, *, strides=[34560, 180, 1], requires_grad=0, device=cpu), %/flow/flows.0/Split_output_1 : Float(*, 96, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Split[axis=1, onnx_name="/flow/flows.0/Split"](%/flow/Slice_3_output_0, %onnx::Split_7144), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /usr/local/lib64/python3.11/site-packages/torch/_tensor.py:917:0
  %/flow/flows.0/pre/Conv_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.0/pre/Conv"](%/flow/flows.0/Split_output_0, %flow.flows.0.pre.weight, %flow.flows.0.pre.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/torch.nn.modules.conv.Conv1d::pre # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/Mul_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.0/Mul"](%/flow/flows.0/pre/Conv_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:149:0
  %/flow/flows.0/enc/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/flow/flows.0/enc/Shape"](%/flow/flows.0/Mul_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:95:0
  %/flow/flows.0/enc/ConstantOfShape_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/flow/flows.0/enc/ConstantOfShape"](%/flow/flows.0/enc/Shape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:95:0
  %/flow/flows.0/enc/cond_layer/Conv_output_0 : Float(1, 1536, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.0/enc/cond_layer/Conv"](%/Unsqueeze_output_0, %onnx::Conv_9918, %flow.flows.0.enc.cond_layer.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::cond_layer # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/enc/in_layers.0/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.0/enc/in_layers.0/Conv"](%/flow/flows.0/Mul_output_0, %onnx::Conv_9921, %flow.flows.0.enc.in_layers.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/enc/Constant_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_1_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.0/enc/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_2_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={384}, onnx_name="/flow/flows.0/enc/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_3_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Slice_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice"](%/flow/flows.0/enc/cond_layer/Conv_output_0, %/flow/flows.0/enc/Constant_1_output_0, %/flow/flows.0/enc/Constant_2_output_0, %/flow/flows.0/enc/Constant_output_0, %/flow/flows.0/enc/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.47 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.0/enc/in_layers.0/Conv_output_0, %/flow/flows.0/enc/Slice_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9926 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8141 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8142 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9927 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8145 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.47, %onnx::Slice_8141, %onnx::Slice_8142, %onnx::Slice_9926, %onnx::Slice_9927) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9928 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8148 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9929 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9930 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8153 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8145, %onnx::Slice_8148, %onnx::Slice_9929, %onnx::Slice_9928, %onnx::Slice_9930) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9931 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8156 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9932 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_8160 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8153, %onnx::Slice_8156, %onnx::Slice_8157, %onnx::Slice_9931, %onnx::Slice_9932) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.47 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_8160) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9933 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9934 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8166 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9935 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8169 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8145, %onnx::Slice_9934, %onnx::Slice_8166, %onnx::Slice_9933, %onnx::Slice_9935) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9936 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8172 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8173 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9937 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_8176 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8169, %onnx::Slice_8172, %onnx::Slice_8173, %onnx::Slice_9936, %onnx::Slice_9937) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.47 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_8176) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.552 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.47, %s_act.47) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.0/enc/res_skip_layers.0/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.0/enc/res_skip_layers.0/Conv"](%input.552, %onnx::Conv_9940, %flow.flows.0.enc.res_skip_layers.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/enc/Constant_4_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_4"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_5_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.0/enc/Constant_5"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_6_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.0/enc/Constant_6"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_7_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_7"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Slice_1_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice_1"](%/flow/flows.0/enc/res_skip_layers.0/Conv_output_0, %/flow/flows.0/enc/Constant_5_output_0, %/flow/flows.0/enc/Constant_6_output_0, %/flow/flows.0/enc/Constant_4_output_0, %/flow/flows.0/enc/Constant_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Add_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.0/enc/Add"](%/flow/flows.0/Mul_output_0, %/flow/flows.0/enc/Slice_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Mul_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.0/enc/Mul"](%/flow/flows.0/enc/Add_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_8_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_8"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Constant_9_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.0/enc/Constant_9"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Constant_10_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.0/enc/Constant_10"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Constant_11_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_11"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Slice_2_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice_2"](%/flow/flows.0/enc/res_skip_layers.0/Conv_output_0, %/flow/flows.0/enc/Constant_9_output_0, %/flow/flows.0/enc/Constant_10_output_0, %/flow/flows.0/enc/Constant_8_output_0, %/flow/flows.0/enc/Constant_11_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Add_1_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.0/enc/Add_1"](%/flow/flows.0/enc/ConstantOfShape_output_0, %/flow/flows.0/enc/Slice_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/in_layers.1/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.0/enc/in_layers.1/Conv"](%/flow/flows.0/enc/Mul_output_0, %onnx::Conv_9951, %flow.flows.0.enc.in_layers.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/enc/Constant_12_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_12"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_13_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={384}, onnx_name="/flow/flows.0/enc/Constant_13"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_14_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={768}, onnx_name="/flow/flows.0/enc/Constant_14"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_15_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_15"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Slice_3_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice_3"](%/flow/flows.0/enc/cond_layer/Conv_output_0, %/flow/flows.0/enc/Constant_13_output_0, %/flow/flows.0/enc/Constant_14_output_0, %/flow/flows.0/enc/Constant_12_output_0, %/flow/flows.0/enc/Constant_15_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.51 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.0/enc/in_layers.1/Conv_output_0, %/flow/flows.0/enc/Slice_3_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9956 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8220 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8221 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9957 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8224 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.51, %onnx::Slice_8220, %onnx::Slice_8221, %onnx::Slice_9956, %onnx::Slice_9957) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9958 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8227 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9959 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9960 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8232 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8224, %onnx::Slice_8227, %onnx::Slice_9959, %onnx::Slice_9958, %onnx::Slice_9960) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9961 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8235 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9962 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_8239 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8232, %onnx::Slice_8235, %onnx::Slice_8236, %onnx::Slice_9961, %onnx::Slice_9962) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.51 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_8239) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9963 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9964 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8245 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9965 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8248 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8224, %onnx::Slice_9964, %onnx::Slice_8245, %onnx::Slice_9963, %onnx::Slice_9965) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9966 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8251 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8252 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9967 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_8255 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8248, %onnx::Slice_8251, %onnx::Slice_8252, %onnx::Slice_9966, %onnx::Slice_9967) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.51 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_8255) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.564 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.51, %s_act.51) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.0/enc/res_skip_layers.1/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.0/enc/res_skip_layers.1/Conv"](%input.564, %onnx::Conv_9970, %flow.flows.0.enc.res_skip_layers.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/enc/Constant_16_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_16"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_17_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.0/enc/Constant_17"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_18_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.0/enc/Constant_18"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_19_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_19"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Slice_4_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice_4"](%/flow/flows.0/enc/res_skip_layers.1/Conv_output_0, %/flow/flows.0/enc/Constant_17_output_0, %/flow/flows.0/enc/Constant_18_output_0, %/flow/flows.0/enc/Constant_16_output_0, %/flow/flows.0/enc/Constant_19_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Add_2_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.0/enc/Add_2"](%/flow/flows.0/enc/Mul_output_0, %/flow/flows.0/enc/Slice_4_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Mul_1_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.0/enc/Mul_1"](%/flow/flows.0/enc/Add_2_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_20_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_20"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Constant_21_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.0/enc/Constant_21"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Constant_22_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.0/enc/Constant_22"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Constant_23_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_23"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Slice_5_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice_5"](%/flow/flows.0/enc/res_skip_layers.1/Conv_output_0, %/flow/flows.0/enc/Constant_21_output_0, %/flow/flows.0/enc/Constant_22_output_0, %/flow/flows.0/enc/Constant_20_output_0, %/flow/flows.0/enc/Constant_23_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Add_3_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.0/enc/Add_3"](%/flow/flows.0/enc/Add_1_output_0, %/flow/flows.0/enc/Slice_5_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/in_layers.2/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.0/enc/in_layers.2/Conv"](%/flow/flows.0/enc/Mul_1_output_0, %onnx::Conv_9981, %flow.flows.0.enc.in_layers.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/enc/Constant_24_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_24"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_25_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={768}, onnx_name="/flow/flows.0/enc/Constant_25"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_26_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1152}, onnx_name="/flow/flows.0/enc/Constant_26"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_27_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_27"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Slice_6_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice_6"](%/flow/flows.0/enc/cond_layer/Conv_output_0, %/flow/flows.0/enc/Constant_25_output_0, %/flow/flows.0/enc/Constant_26_output_0, %/flow/flows.0/enc/Constant_24_output_0, %/flow/flows.0/enc/Constant_27_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.55 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.0/enc/in_layers.2/Conv_output_0, %/flow/flows.0/enc/Slice_6_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_9986 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8299 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8300 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9987 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8303 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.55, %onnx::Slice_8299, %onnx::Slice_8300, %onnx::Slice_9986, %onnx::Slice_9987) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9988 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8306 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9989 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9990 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8311 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8303, %onnx::Slice_8306, %onnx::Slice_9989, %onnx::Slice_9988, %onnx::Slice_9990) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9991 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8314 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8315 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_9992 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_8318 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8311, %onnx::Slice_8314, %onnx::Slice_8315, %onnx::Slice_9991, %onnx::Slice_9992) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.55 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_8318) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_9993 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9994 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8324 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9995 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8327 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8303, %onnx::Slice_9994, %onnx::Slice_8324, %onnx::Slice_9993, %onnx::Slice_9995) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9996 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8330 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8331 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_9997 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_8334 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8327, %onnx::Slice_8330, %onnx::Slice_8331, %onnx::Slice_9996, %onnx::Slice_9997) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.55 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_8334) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.576 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.55, %s_act.55) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.0/enc/res_skip_layers.2/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.0/enc/res_skip_layers.2/Conv"](%input.576, %onnx::Conv_10000, %flow.flows.0.enc.res_skip_layers.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/enc/Constant_28_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_28"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_29_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name="/flow/flows.0/enc/Constant_29"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_30_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.0/enc/Constant_30"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_31_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_31"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Slice_7_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice_7"](%/flow/flows.0/enc/res_skip_layers.2/Conv_output_0, %/flow/flows.0/enc/Constant_29_output_0, %/flow/flows.0/enc/Constant_30_output_0, %/flow/flows.0/enc/Constant_28_output_0, %/flow/flows.0/enc/Constant_31_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Add_4_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.0/enc/Add_4"](%/flow/flows.0/enc/Mul_1_output_0, %/flow/flows.0/enc/Slice_7_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Mul_2_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.0/enc/Mul_2"](%/flow/flows.0/enc/Add_4_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:111:0
  %/flow/flows.0/enc/Constant_32_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_32"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Constant_33_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}, onnx_name="/flow/flows.0/enc/Constant_33"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Constant_34_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name="/flow/flows.0/enc/Constant_34"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Constant_35_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_35"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Slice_8_output_0 : Float(*, 192, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice_8"](%/flow/flows.0/enc/res_skip_layers.2/Conv_output_0, %/flow/flows.0/enc/Constant_33_output_0, %/flow/flows.0/enc/Constant_34_output_0, %/flow/flows.0/enc/Constant_32_output_0, %/flow/flows.0/enc/Constant_35_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/Add_5_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.0/enc/Add_5"](%/flow/flows.0/enc/Add_3_output_0, %/flow/flows.0/enc/Slice_8_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:112:0
  %/flow/flows.0/enc/in_layers.3/Conv_output_0 : Float(*, 384, *, strides=[69120, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[5], pads=[2, 2], strides=[1], onnx_name="/flow/flows.0/enc/in_layers.3/Conv"](%/flow/flows.0/enc/Mul_2_output_0, %onnx::Conv_10011, %flow.flows.0.enc.in_layers.3.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::in_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/enc/Constant_36_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_36"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_37_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1152}, onnx_name="/flow/flows.0/enc/Constant_37"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_38_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1536}, onnx_name="/flow/flows.0/enc/Constant_38"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Constant_39_output_0 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name="/flow/flows.0/enc/Constant_39"](), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %/flow/flows.0/enc/Slice_9_output_0 : Float(1, 384, 1, strides=[1536, 1, 1], requires_grad=0, device=cpu) = onnx::Slice[onnx_name="/flow/flows.0/enc/Slice_9"](%/flow/flows.0/enc/cond_layer/Conv_output_0, %/flow/flows.0/enc/Constant_37_output_0, %/flow/flows.0/enc/Constant_38_output_0, %/flow/flows.0/enc/Constant_36_output_0, %/flow/flows.0/enc/Constant_39_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:105:0
  %in_act.59 : Float(*, 384, *, device=cpu) = onnx::Add(%/flow/flows.0/enc/in_layers.3/Conv_output_0, %/flow/flows.0/enc/Slice_9_output_0) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:9:13
  %onnx::Slice_10016 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8378 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8379 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_10017 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8382 : Float(*, 384, *, device=cpu) = onnx::Slice(%in_act.59, %onnx::Slice_8378, %onnx::Slice_8379, %onnx::Slice_10016, %onnx::Slice_10017) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_10018 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8385 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_10019 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_10020 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8390 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8382, %onnx::Slice_8385, %onnx::Slice_10019, %onnx::Slice_10018, %onnx::Slice_10020) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_10021 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8393 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_8394 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Slice_10022 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %onnx::Tanh_8397 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8390, %onnx::Slice_8393, %onnx::Slice_8394, %onnx::Slice_10021, %onnx::Slice_10022) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:23
  %t_act.59 : Float(*, 192, *, device=cpu) = onnx::Tanh(%onnx::Tanh_8397) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:10:12
  %onnx::Slice_10023 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_10024 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={192}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8403 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_10025 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8406 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8382, %onnx::Slice_10024, %onnx::Slice_8403, %onnx::Slice_10023, %onnx::Slice_10025) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_10026 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8409 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_8410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Slice_10027 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %onnx::Sigmoid_8413 : Float(*, 192, *, device=cpu) = onnx::Slice(%onnx::Slice_8406, %onnx::Slice_8409, %onnx::Slice_8410, %onnx::Slice_10026, %onnx::Slice_10027) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:26
  %s_act.59 : Float(*, 192, *, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_8413) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:11:12
  %input.588 : Float(*, 192, *, device=cpu) = onnx::Mul(%t_act.59, %s_act.59) # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:12:11
  %/flow/flows.0/enc/res_skip_layers.3/Conv_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.0/enc/res_skip_layers.3/Conv"](%input.588, %onnx::Conv_10030, %flow.flows.0.enc.res_skip_layers.3.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc/torch.nn.utils.parametrize.ParametrizedConv1d::res_skip_layers.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/enc/Add_6_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/flow/flows.0/enc/Add_6"](%/flow/flows.0/enc/Add_5_output_0, %/flow/flows.0/enc/res_skip_layers.3/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:114:0
  %/flow/flows.0/enc/Mul_3_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.0/enc/Mul_3"](%/flow/flows.0/enc/Add_6_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/TTS.tts.layers.generic.wavenet.WN::enc # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/generic/wavenet.py:115:0
  %/flow/flows.0/post/Conv_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/flow/flows.0/post/Conv"](%/flow/flows.0/enc/Mul_3_output_0, %flow.flows.0.post.weight, %flow.flows.0.post.bias), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0/torch.nn.modules.conv.Conv1d::post # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/flow/flows.0/Mul_1_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.0/Mul_1"](%/flow/flows.0/post/Conv_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:151:0
  %/flow/flows.0/Shape_output_0 : Long(3, strides=[1], device=cpu) = onnx::Shape[onnx_name="/flow/flows.0/Shape"](%/flow/flows.0/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:156:0
  %/flow/flows.0/ConstantOfShape_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::ConstantOfShape[value={0}, onnx_name="/flow/flows.0/ConstantOfShape"](%/flow/flows.0/Shape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:156:0
  %/flow/flows.0/Sub_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Sub[onnx_name="/flow/flows.0/Sub"](%/flow/flows.0/Split_output_1, %/flow/flows.0/Mul_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.0/Neg_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Neg[onnx_name="/flow/flows.0/Neg"](%/flow/flows.0/ConstantOfShape_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.0/Exp_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Exp[onnx_name="/flow/flows.0/Exp"](%/flow/flows.0/Neg_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.0/Mul_2_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.0/Mul_2"](%/flow/flows.0/Sub_output_0, %/flow/flows.0/Exp_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.0/Mul_3_output_0 : Float(*, 96, *, strides=[17280, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/flow/flows.0/Mul_3"](%/flow/flows.0/Mul_2_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:164:0
  %/flow/flows.0/Concat_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1, onnx_name="/flow/flows.0/Concat"](%/flow/flows.0/Split_output_0, %/flow/flows.0/Mul_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.tts.layers.vits.networks.ResidualCouplingBlocks::flow/TTS.tts.layers.vits.networks.ResidualCouplingBlock::flows.0 # /root/coastcao/HelloTorch//TTS/TTS/tts/layers/vits/networks.py:165:0
  %/Mul_7_output_0 : Float(*, 192, *, strides=[34560, 180, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name="/Mul_7"](%/flow/flows.0/Concat_output_0, %/Unsqueeze_3_output_0), scope: TTS.tts.models.vits.Vits:: # /root/coastcao/HelloTorch//TTS/TTS/tts/models/vits.py:1161:0
  %/waveform_decoder/conv_pre/Conv_output_0 : Float(*, 512, *, strides=[92160, 180, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/conv_pre/Conv"](%/Mul_7_output_0, %waveform_decoder.conv_pre.weight, %waveform_decoder.conv_pre.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/torch.nn.modules.conv.Conv1d::conv_pre # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/cond_layer/Conv_output_0 : Float(1, 512, 1, strides=[512, 1, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1], onnx_name="/waveform_decoder/cond_layer/Conv"](%/Unsqueeze_output_0, %waveform_decoder.cond_layer.weight, %waveform_decoder.cond_layer.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/torch.nn.modules.conv.Conv1d::cond_layer # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/Add_output_0 : Float(*, 512, *, strides=[92160, 180, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/Add"](%/waveform_decoder/conv_pre/Conv_output_0, %/waveform_decoder/cond_layer/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:251:0
  %/waveform_decoder/LeakyRelu_output_0 : Float(*, 512, *, strides=[92160, 180, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/LeakyRelu"](%/waveform_decoder/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/ups.0/ConvTranspose_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1], group=1, kernel_shape=[16], pads=[4, 4], strides=[8], onnx_name="/waveform_decoder/ups.0/ConvTranspose"](%/waveform_decoder/LeakyRelu_output_0, %onnx::ConvTranspose_10033, %waveform_decoder.ups.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/torch.nn.utils.parametrize.ParametrizedConvTranspose1d::ups.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:793:0
  %/waveform_decoder/resblocks.0/LeakyRelu_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.0/LeakyRelu"](%/waveform_decoder/ups.0/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.0/convs1.0/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.0/convs1.0/Conv"](%/waveform_decoder/resblocks.0/LeakyRelu_output_0, %onnx::Conv_10036, %waveform_decoder.resblocks.0.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.0/LeakyRelu_1_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.0/LeakyRelu_1"](%/waveform_decoder/resblocks.0/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.0/convs2.0/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.0/convs2.0/Conv"](%/waveform_decoder/resblocks.0/LeakyRelu_1_output_0, %onnx::Conv_10039, %waveform_decoder.resblocks.0.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.0/Add_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.0/Add"](%/waveform_decoder/resblocks.0/convs2.0/Conv_output_0, %/waveform_decoder/ups.0/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.0/LeakyRelu_2_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.0/LeakyRelu_2"](%/waveform_decoder/resblocks.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.0/convs1.1/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[3], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.0/convs1.1/Conv"](%/waveform_decoder/resblocks.0/LeakyRelu_2_output_0, %onnx::Conv_10042, %waveform_decoder.resblocks.0.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.0/LeakyRelu_3_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.0/LeakyRelu_3"](%/waveform_decoder/resblocks.0/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.0/convs2.1/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.0/convs2.1/Conv"](%/waveform_decoder/resblocks.0/LeakyRelu_3_output_0, %onnx::Conv_10045, %waveform_decoder.resblocks.0.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.0/Add_1_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.0/Add_1"](%/waveform_decoder/resblocks.0/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.0/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.0/LeakyRelu_4_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.0/LeakyRelu_4"](%/waveform_decoder/resblocks.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.0/convs1.2/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[3], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.0/convs1.2/Conv"](%/waveform_decoder/resblocks.0/LeakyRelu_4_output_0, %onnx::Conv_10048, %waveform_decoder.resblocks.0.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.0/LeakyRelu_5_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.0/LeakyRelu_5"](%/waveform_decoder/resblocks.0/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.0/convs2.2/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.0/convs2.2/Conv"](%/waveform_decoder/resblocks.0/LeakyRelu_5_output_0, %onnx::Conv_10051, %waveform_decoder.resblocks.0.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.0/Add_2_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.0/Add_2"](%/waveform_decoder/resblocks.0/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.0/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.0 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.1/convs1.0/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.1/convs1.0/Conv"](%/waveform_decoder/resblocks.0/LeakyRelu_output_0, %onnx::Conv_10054, %waveform_decoder.resblocks.1.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.1/LeakyRelu_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.1/LeakyRelu"](%/waveform_decoder/resblocks.1/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.1/convs2.0/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.1/convs2.0/Conv"](%/waveform_decoder/resblocks.1/LeakyRelu_output_0, %onnx::Conv_10057, %waveform_decoder.resblocks.1.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.1/Add_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.1/Add"](%/waveform_decoder/resblocks.1/convs2.0/Conv_output_0, %/waveform_decoder/ups.0/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.1/LeakyRelu_1_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.1/LeakyRelu_1"](%/waveform_decoder/resblocks.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.1/convs1.1/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[7], pads=[9, 9], strides=[1], onnx_name="/waveform_decoder/resblocks.1/convs1.1/Conv"](%/waveform_decoder/resblocks.1/LeakyRelu_1_output_0, %onnx::Conv_10060, %waveform_decoder.resblocks.1.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.1/LeakyRelu_2_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.1/LeakyRelu_2"](%/waveform_decoder/resblocks.1/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.1/convs2.1/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.1/convs2.1/Conv"](%/waveform_decoder/resblocks.1/LeakyRelu_2_output_0, %onnx::Conv_10063, %waveform_decoder.resblocks.1.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.1/Add_1_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.1/Add_1"](%/waveform_decoder/resblocks.1/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.1/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.1/LeakyRelu_3_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.1/LeakyRelu_3"](%/waveform_decoder/resblocks.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.1/convs1.2/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[7], pads=[15, 15], strides=[1], onnx_name="/waveform_decoder/resblocks.1/convs1.2/Conv"](%/waveform_decoder/resblocks.1/LeakyRelu_3_output_0, %onnx::Conv_10066, %waveform_decoder.resblocks.1.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.1/LeakyRelu_4_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.1/LeakyRelu_4"](%/waveform_decoder/resblocks.1/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.1/convs2.2/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.1/convs2.2/Conv"](%/waveform_decoder/resblocks.1/LeakyRelu_4_output_0, %onnx::Conv_10069, %waveform_decoder.resblocks.1.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.1/Add_2_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.1/Add_2"](%/waveform_decoder/resblocks.1/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.1/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.1 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/Add_1_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/Add_1"](%/waveform_decoder/resblocks.0/Add_2_output_0, %/waveform_decoder/resblocks.1/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:260:0
  %/waveform_decoder/resblocks.2/convs1.0/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.2/convs1.0/Conv"](%/waveform_decoder/resblocks.0/LeakyRelu_output_0, %onnx::Conv_10072, %waveform_decoder.resblocks.2.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.2/LeakyRelu_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.2/LeakyRelu"](%/waveform_decoder/resblocks.2/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.2/convs2.0/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.2/convs2.0/Conv"](%/waveform_decoder/resblocks.2/LeakyRelu_output_0, %onnx::Conv_10075, %waveform_decoder.resblocks.2.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.2/Add_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.2/Add"](%/waveform_decoder/resblocks.2/convs2.0/Conv_output_0, %/waveform_decoder/ups.0/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.2/LeakyRelu_1_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.2/LeakyRelu_1"](%/waveform_decoder/resblocks.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.2/convs1.1/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[11], pads=[15, 15], strides=[1], onnx_name="/waveform_decoder/resblocks.2/convs1.1/Conv"](%/waveform_decoder/resblocks.2/LeakyRelu_1_output_0, %onnx::Conv_10078, %waveform_decoder.resblocks.2.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.2/LeakyRelu_2_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.2/LeakyRelu_2"](%/waveform_decoder/resblocks.2/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.2/convs2.1/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.2/convs2.1/Conv"](%/waveform_decoder/resblocks.2/LeakyRelu_2_output_0, %onnx::Conv_10081, %waveform_decoder.resblocks.2.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.2/Add_1_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.2/Add_1"](%/waveform_decoder/resblocks.2/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.2/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.2/LeakyRelu_3_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.2/LeakyRelu_3"](%/waveform_decoder/resblocks.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.2/convs1.2/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[11], pads=[25, 25], strides=[1], onnx_name="/waveform_decoder/resblocks.2/convs1.2/Conv"](%/waveform_decoder/resblocks.2/LeakyRelu_3_output_0, %onnx::Conv_10084, %waveform_decoder.resblocks.2.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.2/LeakyRelu_4_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.2/LeakyRelu_4"](%/waveform_decoder/resblocks.2/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.2/convs2.2/Conv_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.2/convs2.2/Conv"](%/waveform_decoder/resblocks.2/LeakyRelu_4_output_0, %onnx::Conv_10087, %waveform_decoder.resblocks.2.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.2/Add_2_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.2/Add_2"](%/waveform_decoder/resblocks.2/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.2/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.2 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/Add_2_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/Add_2"](%/waveform_decoder/Add_1_output_0, %/waveform_decoder/resblocks.2/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:260:0
  %/waveform_decoder/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/waveform_decoder/Constant"](), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:261:0
  %/waveform_decoder/Div_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/waveform_decoder/Div"](%/waveform_decoder/Add_2_output_0, %/waveform_decoder/Constant_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:261:0
  %/waveform_decoder/LeakyRelu_1_output_0 : Float(*, 256, *, strides=[368640, 1440, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/LeakyRelu_1"](%/waveform_decoder/Div_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/ups.1/ConvTranspose_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1], group=1, kernel_shape=[16], pads=[4, 4], strides=[8], onnx_name="/waveform_decoder/ups.1/ConvTranspose"](%/waveform_decoder/LeakyRelu_1_output_0, %onnx::ConvTranspose_10090, %waveform_decoder.ups.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/torch.nn.utils.parametrize.ParametrizedConvTranspose1d::ups.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:793:0
  %/waveform_decoder/resblocks.3/LeakyRelu_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.3/LeakyRelu"](%/waveform_decoder/ups.1/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.3/convs1.0/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.3/convs1.0/Conv"](%/waveform_decoder/resblocks.3/LeakyRelu_output_0, %onnx::Conv_10093, %waveform_decoder.resblocks.3.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.3/LeakyRelu_1_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.3/LeakyRelu_1"](%/waveform_decoder/resblocks.3/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.3/convs2.0/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.3/convs2.0/Conv"](%/waveform_decoder/resblocks.3/LeakyRelu_1_output_0, %onnx::Conv_10096, %waveform_decoder.resblocks.3.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.3/Add_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.3/Add"](%/waveform_decoder/resblocks.3/convs2.0/Conv_output_0, %/waveform_decoder/ups.1/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.3/LeakyRelu_2_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.3/LeakyRelu_2"](%/waveform_decoder/resblocks.3/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.3/convs1.1/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[3], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.3/convs1.1/Conv"](%/waveform_decoder/resblocks.3/LeakyRelu_2_output_0, %onnx::Conv_10099, %waveform_decoder.resblocks.3.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.3/LeakyRelu_3_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.3/LeakyRelu_3"](%/waveform_decoder/resblocks.3/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.3/convs2.1/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.3/convs2.1/Conv"](%/waveform_decoder/resblocks.3/LeakyRelu_3_output_0, %onnx::Conv_10102, %waveform_decoder.resblocks.3.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.3/Add_1_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.3/Add_1"](%/waveform_decoder/resblocks.3/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.3/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.3/LeakyRelu_4_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.3/LeakyRelu_4"](%/waveform_decoder/resblocks.3/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.3/convs1.2/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[3], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.3/convs1.2/Conv"](%/waveform_decoder/resblocks.3/LeakyRelu_4_output_0, %onnx::Conv_10105, %waveform_decoder.resblocks.3.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.3/LeakyRelu_5_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.3/LeakyRelu_5"](%/waveform_decoder/resblocks.3/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.3/convs2.2/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.3/convs2.2/Conv"](%/waveform_decoder/resblocks.3/LeakyRelu_5_output_0, %onnx::Conv_10108, %waveform_decoder.resblocks.3.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.3/Add_2_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.3/Add_2"](%/waveform_decoder/resblocks.3/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.3/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.3 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.4/convs1.0/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.4/convs1.0/Conv"](%/waveform_decoder/resblocks.3/LeakyRelu_output_0, %onnx::Conv_10111, %waveform_decoder.resblocks.4.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.4/LeakyRelu_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.4/LeakyRelu"](%/waveform_decoder/resblocks.4/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.4/convs2.0/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.4/convs2.0/Conv"](%/waveform_decoder/resblocks.4/LeakyRelu_output_0, %onnx::Conv_10114, %waveform_decoder.resblocks.4.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.4/Add_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.4/Add"](%/waveform_decoder/resblocks.4/convs2.0/Conv_output_0, %/waveform_decoder/ups.1/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.4/LeakyRelu_1_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.4/LeakyRelu_1"](%/waveform_decoder/resblocks.4/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.4/convs1.1/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[7], pads=[9, 9], strides=[1], onnx_name="/waveform_decoder/resblocks.4/convs1.1/Conv"](%/waveform_decoder/resblocks.4/LeakyRelu_1_output_0, %onnx::Conv_10117, %waveform_decoder.resblocks.4.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.4/LeakyRelu_2_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.4/LeakyRelu_2"](%/waveform_decoder/resblocks.4/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.4/convs2.1/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.4/convs2.1/Conv"](%/waveform_decoder/resblocks.4/LeakyRelu_2_output_0, %onnx::Conv_10120, %waveform_decoder.resblocks.4.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.4/Add_1_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.4/Add_1"](%/waveform_decoder/resblocks.4/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.4/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.4/LeakyRelu_3_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.4/LeakyRelu_3"](%/waveform_decoder/resblocks.4/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.4/convs1.2/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[7], pads=[15, 15], strides=[1], onnx_name="/waveform_decoder/resblocks.4/convs1.2/Conv"](%/waveform_decoder/resblocks.4/LeakyRelu_3_output_0, %onnx::Conv_10123, %waveform_decoder.resblocks.4.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.4/LeakyRelu_4_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.4/LeakyRelu_4"](%/waveform_decoder/resblocks.4/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.4/convs2.2/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.4/convs2.2/Conv"](%/waveform_decoder/resblocks.4/LeakyRelu_4_output_0, %onnx::Conv_10126, %waveform_decoder.resblocks.4.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.4/Add_2_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.4/Add_2"](%/waveform_decoder/resblocks.4/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.4/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.4 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/Add_3_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/Add_3"](%/waveform_decoder/resblocks.3/Add_2_output_0, %/waveform_decoder/resblocks.4/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:260:0
  %/waveform_decoder/resblocks.5/convs1.0/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.5/convs1.0/Conv"](%/waveform_decoder/resblocks.3/LeakyRelu_output_0, %onnx::Conv_10129, %waveform_decoder.resblocks.5.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.5/LeakyRelu_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.5/LeakyRelu"](%/waveform_decoder/resblocks.5/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.5/convs2.0/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.5/convs2.0/Conv"](%/waveform_decoder/resblocks.5/LeakyRelu_output_0, %onnx::Conv_10132, %waveform_decoder.resblocks.5.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.5/Add_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.5/Add"](%/waveform_decoder/resblocks.5/convs2.0/Conv_output_0, %/waveform_decoder/ups.1/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.5/LeakyRelu_1_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.5/LeakyRelu_1"](%/waveform_decoder/resblocks.5/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.5/convs1.1/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[11], pads=[15, 15], strides=[1], onnx_name="/waveform_decoder/resblocks.5/convs1.1/Conv"](%/waveform_decoder/resblocks.5/LeakyRelu_1_output_0, %onnx::Conv_10135, %waveform_decoder.resblocks.5.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.5/LeakyRelu_2_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.5/LeakyRelu_2"](%/waveform_decoder/resblocks.5/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.5/convs2.1/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.5/convs2.1/Conv"](%/waveform_decoder/resblocks.5/LeakyRelu_2_output_0, %onnx::Conv_10138, %waveform_decoder.resblocks.5.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.5/Add_1_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.5/Add_1"](%/waveform_decoder/resblocks.5/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.5/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.5/LeakyRelu_3_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.5/LeakyRelu_3"](%/waveform_decoder/resblocks.5/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.5/convs1.2/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[11], pads=[25, 25], strides=[1], onnx_name="/waveform_decoder/resblocks.5/convs1.2/Conv"](%/waveform_decoder/resblocks.5/LeakyRelu_3_output_0, %onnx::Conv_10141, %waveform_decoder.resblocks.5.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.5/LeakyRelu_4_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.5/LeakyRelu_4"](%/waveform_decoder/resblocks.5/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.5/convs2.2/Conv_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.5/convs2.2/Conv"](%/waveform_decoder/resblocks.5/LeakyRelu_4_output_0, %onnx::Conv_10144, %waveform_decoder.resblocks.5.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.5/Add_2_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.5/Add_2"](%/waveform_decoder/resblocks.5/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.5/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.5 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/Add_4_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/Add_4"](%/waveform_decoder/Add_3_output_0, %/waveform_decoder/resblocks.5/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:260:0
  %/waveform_decoder/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/waveform_decoder/Constant_1"](), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:261:0
  %/waveform_decoder/Div_1_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/waveform_decoder/Div_1"](%/waveform_decoder/Add_4_output_0, %/waveform_decoder/Constant_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:261:0
  %/waveform_decoder/LeakyRelu_2_output_0 : Float(*, 128, *, strides=[1474560, 11520, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/LeakyRelu_2"](%/waveform_decoder/Div_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/ups.2/ConvTranspose_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1], group=1, kernel_shape=[4], pads=[1, 1], strides=[2], onnx_name="/waveform_decoder/ups.2/ConvTranspose"](%/waveform_decoder/LeakyRelu_2_output_0, %onnx::ConvTranspose_10147, %waveform_decoder.ups.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/torch.nn.utils.parametrize.ParametrizedConvTranspose1d::ups.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:793:0
  %/waveform_decoder/resblocks.6/LeakyRelu_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.6/LeakyRelu"](%/waveform_decoder/ups.2/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.6/convs1.0/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.6/convs1.0/Conv"](%/waveform_decoder/resblocks.6/LeakyRelu_output_0, %onnx::Conv_10150, %waveform_decoder.resblocks.6.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.6/LeakyRelu_1_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.6/LeakyRelu_1"](%/waveform_decoder/resblocks.6/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.6/convs2.0/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.6/convs2.0/Conv"](%/waveform_decoder/resblocks.6/LeakyRelu_1_output_0, %onnx::Conv_10153, %waveform_decoder.resblocks.6.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.6/Add_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.6/Add"](%/waveform_decoder/resblocks.6/convs2.0/Conv_output_0, %/waveform_decoder/ups.2/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.6/LeakyRelu_2_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.6/LeakyRelu_2"](%/waveform_decoder/resblocks.6/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.6/convs1.1/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[3], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.6/convs1.1/Conv"](%/waveform_decoder/resblocks.6/LeakyRelu_2_output_0, %onnx::Conv_10156, %waveform_decoder.resblocks.6.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.6/LeakyRelu_3_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.6/LeakyRelu_3"](%/waveform_decoder/resblocks.6/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.6/convs2.1/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.6/convs2.1/Conv"](%/waveform_decoder/resblocks.6/LeakyRelu_3_output_0, %onnx::Conv_10159, %waveform_decoder.resblocks.6.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.6/Add_1_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.6/Add_1"](%/waveform_decoder/resblocks.6/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.6/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.6/LeakyRelu_4_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.6/LeakyRelu_4"](%/waveform_decoder/resblocks.6/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.6/convs1.2/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[3], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.6/convs1.2/Conv"](%/waveform_decoder/resblocks.6/LeakyRelu_4_output_0, %onnx::Conv_10162, %waveform_decoder.resblocks.6.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.6/LeakyRelu_5_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.6/LeakyRelu_5"](%/waveform_decoder/resblocks.6/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.6/convs2.2/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.6/convs2.2/Conv"](%/waveform_decoder/resblocks.6/LeakyRelu_5_output_0, %onnx::Conv_10165, %waveform_decoder.resblocks.6.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.6/Add_2_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.6/Add_2"](%/waveform_decoder/resblocks.6/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.6/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.6 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.7/convs1.0/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.7/convs1.0/Conv"](%/waveform_decoder/resblocks.6/LeakyRelu_output_0, %onnx::Conv_10168, %waveform_decoder.resblocks.7.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.7/LeakyRelu_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.7/LeakyRelu"](%/waveform_decoder/resblocks.7/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.7/convs2.0/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.7/convs2.0/Conv"](%/waveform_decoder/resblocks.7/LeakyRelu_output_0, %onnx::Conv_10171, %waveform_decoder.resblocks.7.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.7/Add_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.7/Add"](%/waveform_decoder/resblocks.7/convs2.0/Conv_output_0, %/waveform_decoder/ups.2/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.7/LeakyRelu_1_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.7/LeakyRelu_1"](%/waveform_decoder/resblocks.7/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.7/convs1.1/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[7], pads=[9, 9], strides=[1], onnx_name="/waveform_decoder/resblocks.7/convs1.1/Conv"](%/waveform_decoder/resblocks.7/LeakyRelu_1_output_0, %onnx::Conv_10174, %waveform_decoder.resblocks.7.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.7/LeakyRelu_2_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.7/LeakyRelu_2"](%/waveform_decoder/resblocks.7/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.7/convs2.1/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.7/convs2.1/Conv"](%/waveform_decoder/resblocks.7/LeakyRelu_2_output_0, %onnx::Conv_10177, %waveform_decoder.resblocks.7.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.7/Add_1_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.7/Add_1"](%/waveform_decoder/resblocks.7/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.7/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.7/LeakyRelu_3_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.7/LeakyRelu_3"](%/waveform_decoder/resblocks.7/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.7/convs1.2/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[7], pads=[15, 15], strides=[1], onnx_name="/waveform_decoder/resblocks.7/convs1.2/Conv"](%/waveform_decoder/resblocks.7/LeakyRelu_3_output_0, %onnx::Conv_10180, %waveform_decoder.resblocks.7.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.7/LeakyRelu_4_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.7/LeakyRelu_4"](%/waveform_decoder/resblocks.7/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.7/convs2.2/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.7/convs2.2/Conv"](%/waveform_decoder/resblocks.7/LeakyRelu_4_output_0, %onnx::Conv_10183, %waveform_decoder.resblocks.7.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.7/Add_2_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.7/Add_2"](%/waveform_decoder/resblocks.7/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.7/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.7 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/Add_5_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/Add_5"](%/waveform_decoder/resblocks.6/Add_2_output_0, %/waveform_decoder/resblocks.7/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:260:0
  %/waveform_decoder/resblocks.8/convs1.0/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.8/convs1.0/Conv"](%/waveform_decoder/resblocks.6/LeakyRelu_output_0, %onnx::Conv_10186, %waveform_decoder.resblocks.8.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.8/LeakyRelu_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.8/LeakyRelu"](%/waveform_decoder/resblocks.8/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.8/convs2.0/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.8/convs2.0/Conv"](%/waveform_decoder/resblocks.8/LeakyRelu_output_0, %onnx::Conv_10189, %waveform_decoder.resblocks.8.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.8/Add_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.8/Add"](%/waveform_decoder/resblocks.8/convs2.0/Conv_output_0, %/waveform_decoder/ups.2/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.8/LeakyRelu_1_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.8/LeakyRelu_1"](%/waveform_decoder/resblocks.8/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.8/convs1.1/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[11], pads=[15, 15], strides=[1], onnx_name="/waveform_decoder/resblocks.8/convs1.1/Conv"](%/waveform_decoder/resblocks.8/LeakyRelu_1_output_0, %onnx::Conv_10192, %waveform_decoder.resblocks.8.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.8/LeakyRelu_2_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.8/LeakyRelu_2"](%/waveform_decoder/resblocks.8/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.8/convs2.1/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.8/convs2.1/Conv"](%/waveform_decoder/resblocks.8/LeakyRelu_2_output_0, %onnx::Conv_10195, %waveform_decoder.resblocks.8.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.8/Add_1_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.8/Add_1"](%/waveform_decoder/resblocks.8/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.8/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.8/LeakyRelu_3_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.8/LeakyRelu_3"](%/waveform_decoder/resblocks.8/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.8/convs1.2/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[11], pads=[25, 25], strides=[1], onnx_name="/waveform_decoder/resblocks.8/convs1.2/Conv"](%/waveform_decoder/resblocks.8/LeakyRelu_3_output_0, %onnx::Conv_10198, %waveform_decoder.resblocks.8.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.8/LeakyRelu_4_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.8/LeakyRelu_4"](%/waveform_decoder/resblocks.8/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.8/convs2.2/Conv_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.8/convs2.2/Conv"](%/waveform_decoder/resblocks.8/LeakyRelu_4_output_0, %onnx::Conv_10201, %waveform_decoder.resblocks.8.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.8/Add_2_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.8/Add_2"](%/waveform_decoder/resblocks.8/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.8/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.8 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/Add_6_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/Add_6"](%/waveform_decoder/Add_5_output_0, %/waveform_decoder/resblocks.8/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:260:0
  %/waveform_decoder/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/waveform_decoder/Constant_2"](), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:261:0
  %/waveform_decoder/Div_2_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/waveform_decoder/Div_2"](%/waveform_decoder/Add_6_output_0, %/waveform_decoder/Constant_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:261:0
  %/waveform_decoder/LeakyRelu_3_output_0 : Float(*, 64, *, strides=[1474560, 23040, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/LeakyRelu_3"](%/waveform_decoder/Div_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/ups.3/ConvTranspose_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::ConvTranspose[dilations=[1], group=1, kernel_shape=[4], pads=[1, 1], strides=[2], onnx_name="/waveform_decoder/ups.3/ConvTranspose"](%/waveform_decoder/LeakyRelu_3_output_0, %onnx::ConvTranspose_10204, %waveform_decoder.ups.3.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/torch.nn.utils.parametrize.ParametrizedConvTranspose1d::ups.3 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:793:0
  %/waveform_decoder/resblocks.9/LeakyRelu_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.9/LeakyRelu"](%/waveform_decoder/ups.3/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.9/convs1.0/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.9/convs1.0/Conv"](%/waveform_decoder/resblocks.9/LeakyRelu_output_0, %onnx::Conv_10207, %waveform_decoder.resblocks.9.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.9/LeakyRelu_1_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.9/LeakyRelu_1"](%/waveform_decoder/resblocks.9/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.9/convs2.0/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.9/convs2.0/Conv"](%/waveform_decoder/resblocks.9/LeakyRelu_1_output_0, %onnx::Conv_10210, %waveform_decoder.resblocks.9.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.9/Add_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.9/Add"](%/waveform_decoder/resblocks.9/convs2.0/Conv_output_0, %/waveform_decoder/ups.3/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.9/LeakyRelu_2_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.9/LeakyRelu_2"](%/waveform_decoder/resblocks.9/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.9/convs1.1/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[3], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.9/convs1.1/Conv"](%/waveform_decoder/resblocks.9/LeakyRelu_2_output_0, %onnx::Conv_10213, %waveform_decoder.resblocks.9.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.9/LeakyRelu_3_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.9/LeakyRelu_3"](%/waveform_decoder/resblocks.9/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.9/convs2.1/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.9/convs2.1/Conv"](%/waveform_decoder/resblocks.9/LeakyRelu_3_output_0, %onnx::Conv_10216, %waveform_decoder.resblocks.9.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.9/Add_1_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.9/Add_1"](%/waveform_decoder/resblocks.9/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.9/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.9/LeakyRelu_4_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.9/LeakyRelu_4"](%/waveform_decoder/resblocks.9/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.9/convs1.2/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[3], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.9/convs1.2/Conv"](%/waveform_decoder/resblocks.9/LeakyRelu_4_output_0, %onnx::Conv_10219, %waveform_decoder.resblocks.9.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.9/LeakyRelu_5_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.9/LeakyRelu_5"](%/waveform_decoder/resblocks.9/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.9/convs2.2/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[3], pads=[1, 1], strides=[1], onnx_name="/waveform_decoder/resblocks.9/convs2.2/Conv"](%/waveform_decoder/resblocks.9/LeakyRelu_5_output_0, %onnx::Conv_10222, %waveform_decoder.resblocks.9.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.9/Add_2_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.9/Add_2"](%/waveform_decoder/resblocks.9/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.9/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.9 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.10/convs1.0/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.10/convs1.0/Conv"](%/waveform_decoder/resblocks.9/LeakyRelu_output_0, %onnx::Conv_10225, %waveform_decoder.resblocks.10.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.10/LeakyRelu_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.10/LeakyRelu"](%/waveform_decoder/resblocks.10/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.10/convs2.0/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.10/convs2.0/Conv"](%/waveform_decoder/resblocks.10/LeakyRelu_output_0, %onnx::Conv_10228, %waveform_decoder.resblocks.10.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.10/Add_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.10/Add"](%/waveform_decoder/resblocks.10/convs2.0/Conv_output_0, %/waveform_decoder/ups.3/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.10/LeakyRelu_1_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.10/LeakyRelu_1"](%/waveform_decoder/resblocks.10/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.10/convs1.1/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[7], pads=[9, 9], strides=[1], onnx_name="/waveform_decoder/resblocks.10/convs1.1/Conv"](%/waveform_decoder/resblocks.10/LeakyRelu_1_output_0, %onnx::Conv_10231, %waveform_decoder.resblocks.10.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.10/LeakyRelu_2_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.10/LeakyRelu_2"](%/waveform_decoder/resblocks.10/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.10/convs2.1/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.10/convs2.1/Conv"](%/waveform_decoder/resblocks.10/LeakyRelu_2_output_0, %onnx::Conv_10234, %waveform_decoder.resblocks.10.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.10/Add_1_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.10/Add_1"](%/waveform_decoder/resblocks.10/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.10/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.10/LeakyRelu_3_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.10/LeakyRelu_3"](%/waveform_decoder/resblocks.10/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.10/convs1.2/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[7], pads=[15, 15], strides=[1], onnx_name="/waveform_decoder/resblocks.10/convs1.2/Conv"](%/waveform_decoder/resblocks.10/LeakyRelu_3_output_0, %onnx::Conv_10237, %waveform_decoder.resblocks.10.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.10/LeakyRelu_4_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.10/LeakyRelu_4"](%/waveform_decoder/resblocks.10/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.10/convs2.2/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/resblocks.10/convs2.2/Conv"](%/waveform_decoder/resblocks.10/LeakyRelu_4_output_0, %onnx::Conv_10240, %waveform_decoder.resblocks.10.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.10/Add_2_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.10/Add_2"](%/waveform_decoder/resblocks.10/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.10/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.10 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/Add_7_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/Add_7"](%/waveform_decoder/resblocks.9/Add_2_output_0, %/waveform_decoder/resblocks.10/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:260:0
  %/waveform_decoder/resblocks.11/convs1.0/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.11/convs1.0/Conv"](%/waveform_decoder/resblocks.9/LeakyRelu_output_0, %onnx::Conv_10243, %waveform_decoder.resblocks.11.convs1.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.11/LeakyRelu_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.11/LeakyRelu"](%/waveform_decoder/resblocks.11/convs1.0/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.11/convs2.0/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.11/convs2.0/Conv"](%/waveform_decoder/resblocks.11/LeakyRelu_output_0, %onnx::Conv_10246, %waveform_decoder.resblocks.11.convs2.0.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.0 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.11/Add_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.11/Add"](%/waveform_decoder/resblocks.11/convs2.0/Conv_output_0, %/waveform_decoder/ups.3/ConvTranspose_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.11/LeakyRelu_1_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.11/LeakyRelu_1"](%/waveform_decoder/resblocks.11/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.11/convs1.1/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[3], group=1, kernel_shape=[11], pads=[15, 15], strides=[1], onnx_name="/waveform_decoder/resblocks.11/convs1.1/Conv"](%/waveform_decoder/resblocks.11/LeakyRelu_1_output_0, %onnx::Conv_10249, %waveform_decoder.resblocks.11.convs1.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.11/LeakyRelu_2_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.11/LeakyRelu_2"](%/waveform_decoder/resblocks.11/convs1.1/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.11/convs2.1/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.11/convs2.1/Conv"](%/waveform_decoder/resblocks.11/LeakyRelu_2_output_0, %onnx::Conv_10252, %waveform_decoder.resblocks.11.convs2.1.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.1 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.11/Add_1_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.11/Add_1"](%/waveform_decoder/resblocks.11/convs2.1/Conv_output_0, %/waveform_decoder/resblocks.11/Add_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/resblocks.11/LeakyRelu_3_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.11/LeakyRelu_3"](%/waveform_decoder/resblocks.11/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.11/convs1.2/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[5], group=1, kernel_shape=[11], pads=[25, 25], strides=[1], onnx_name="/waveform_decoder/resblocks.11/convs1.2/Conv"](%/waveform_decoder/resblocks.11/LeakyRelu_3_output_0, %onnx::Conv_10255, %waveform_decoder.resblocks.11.convs1.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11/torch.nn.utils.parametrize.ParametrizedConv1d::convs1.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.11/LeakyRelu_4_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.10000000000000001, onnx_name="/waveform_decoder/resblocks.11/LeakyRelu_4"](%/waveform_decoder/resblocks.11/convs1.2/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11 # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/resblocks.11/convs2.2/Conv_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[11], pads=[5, 5], strides=[1], onnx_name="/waveform_decoder/resblocks.11/convs2.2/Conv"](%/waveform_decoder/resblocks.11/LeakyRelu_4_output_0, %onnx::Conv_10258, %waveform_decoder.resblocks.11.convs2.2.bias), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11/torch.nn.utils.parametrize.ParametrizedConv1d::convs2.2 # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %/waveform_decoder/resblocks.11/Add_2_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/resblocks.11/Add_2"](%/waveform_decoder/resblocks.11/convs2.2/Conv_output_0, %/waveform_decoder/resblocks.11/Add_1_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/TTS.vocoder.models.hifigan_generator.ResBlock1::resblocks.11 # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:98:0
  %/waveform_decoder/Add_8_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Add[onnx_name="/waveform_decoder/Add_8"](%/waveform_decoder/Add_7_output_0, %/waveform_decoder/resblocks.11/Add_2_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:260:0
  %/waveform_decoder/Constant_3_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}, onnx_name="/waveform_decoder/Constant_3"](), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:261:0
  %/waveform_decoder/Div_3_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::Div[onnx_name="/waveform_decoder/Div_3"](%/waveform_decoder/Add_8_output_0, %/waveform_decoder/Constant_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:261:0
  %/waveform_decoder/LeakyRelu_4_output_0 : Float(*, 32, *, strides=[1474560, 46080, 1], requires_grad=0, device=cpu) = onnx::LeakyRelu[alpha=0.01, onnx_name="/waveform_decoder/LeakyRelu_4"](%/waveform_decoder/Div_3_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /usr/local/lib64/python3.11/site-packages/torch/nn/functional.py:1677:0
  %/waveform_decoder/conv_post/Conv_output_0 : Float(*, 1, *, strides=[46080, 46080, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[3, 3], strides=[1], onnx_name="/waveform_decoder/conv_post/Conv"](%/waveform_decoder/LeakyRelu_4_output_0, %waveform_decoder.conv_post.weight), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder/torch.nn.modules.conv.Conv1d::conv_post # /usr/local/lib64/python3.11/site-packages/torch/nn/modules/conv.py:304:0
  %output : Float(*, 1, *, strides=[46080, 46080, 1], requires_grad=0, device=cpu) = onnx::Tanh[onnx_name="/waveform_decoder/Tanh"](%/waveform_decoder/conv_post/Conv_output_0), scope: TTS.tts.models.vits.Vits::/TTS.vocoder.models.hifigan_generator.HifiganGenerator::waveform_decoder # /root/coastcao/HelloTorch//TTS/TTS/vocoder/models/hifigan_generator.py:264:0
  return (%output)

 > Setting up Audio Processor...
 | > sample_rate:22050
 | > resample:False
 | > num_mels:80
 | > log_func:np.log10
 | > min_level_db:0
 | > frame_shift_ms:None
 | > frame_length_ms:None
 | > ref_level_db:None
 | > fft_size:1024
 | > power:None
 | > preemphasis:0.0
 | > griffin_lim_iters:None
 | > signal_norm:None
 | > symmetric_norm:None
 | > mel_fmin:0
 | > mel_fmax:None
 | > pitch_fmin:None
 | > pitch_fmax:None
 | > spec_gain:20.0
 | > stft_pad_mode:reflect
 | > max_norm:1.0
 | > clip_norm:True
 | > do_trim_silence:False
 | > trim_db:60
 | > do_sound_norm:False
 | > do_amp_to_db_linear:True
 | > do_amp_to_db_mel:True
 | > do_rms_norm:False
 | > db_level:None
 | > stats_path:None
 | > base:10
 | > hop_length:256
 | > win_length:1024
 > initialization of speaker-embedding layers.
